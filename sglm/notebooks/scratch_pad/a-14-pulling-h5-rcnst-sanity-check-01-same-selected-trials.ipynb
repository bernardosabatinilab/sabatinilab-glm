{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.helpers import filehelpers as fh, dfhelpers as dfh\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_keys = list({\n",
    "                'gACH':(0,0),\n",
    "                'rDA':(0,0),\n",
    "                'gDA':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),\n",
    "                'photometrySideInIndexnr':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                }.keys())\n",
    "shortened_keys = [dfh.shorten_col_name(_) for _ in base_keys]\n",
    "\n",
    "all_alignment_cols = [\n",
    "                        'SIAA', 'SIaA', 'SIAB', 'SIaB',\n",
    "    \n",
    "                        'SIAa', 'SIaa', 'SIAb', 'SIab',\n",
    "#                         'SIr', 'SInr', \n",
    "                     ]\n",
    "# base_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_list(event_srs, keep_srs):\n",
    "    \n",
    "    keep_eg_lst = []\n",
    "    delta_keep_eg_lst = []\n",
    "\n",
    "    rdc = []\n",
    "    entry_num = np.arange(len(event_srs))\n",
    "    event = np.where(event_srs.values == 1)\n",
    "    assert len(event) == 1\n",
    "    event = event[0]\n",
    "    \n",
    "    for iev, ev in enumerate(event):\n",
    "        delta = entry_num - ev\n",
    "        keep_eg = (delta >= -40)&(delta <= 100)&keep_srs\n",
    "        delta_keep_eg = delta[keep_eg]\n",
    "        keep_eg_lst.append(keep_eg)\n",
    "        delta_keep_eg_lst.append(delta_keep_eg)\n",
    "\n",
    "    return keep_eg_lst, delta_keep_eg_lst\n",
    "\n",
    "# full_df = h5_lst[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig_folder ('Figure_1_2', 'f1*-ft')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c344beb0847a4241abeec1eeea03a0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "SIr: 12716\n",
      "SInr: 5572\n",
      "---------------------------\n",
      "Pulling delta list\n",
      "SIAA -- Prc: 0.755 - Num: 9602\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIaA -- Prc: 0.102 - Num: 1296\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIAB -- Prc: 0.014 - Num: 175\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIaB -- Prc: 0.129 - Num: 1643\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIAa -- Prc: 0.373 - Num: 2076\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIaa -- Prc: 0.346 - Num: 1927\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIAb -- Prc: 0.155 - Num: 862\n",
      "True\n",
      "True\n",
      "Pulling delta list\n",
      "SIab -- Prc: 0.127 - Num: 707\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# base_location = Path(r'/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/outputs')\n",
    "base_location = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs')\n",
    "\n",
    "# fig_folder_lst = [('Figure_1_2', 'f1*-ft'),\n",
    "#                   ('Figure_3',   'f3*-ft'),\n",
    "#                   ('Figure_4_g1',   'f4*-ft'),\n",
    "#                   ('Figure_4_g2',   'f4*-ft'),\n",
    "#                   ('Figure_5_g1',   'f5*-ft'),\n",
    "#                   ('Figure_5_g2',   'f5*-ft'),\n",
    "#                   ('Figure_5_g5',   'f5*-ft'),\n",
    "#                  ]\n",
    "fig_folder_lst = [('Figure_1_2', 'f1*-ft'),\n",
    "                  ('Figure_3',   'f3*-ft'),\n",
    "                  ('Figure_4_g1',   'f4*-ft'),\n",
    "                  ('Figure_4_g2',   'f4*-ft'),\n",
    "                  ('Figure_5_g1',   'f5*-ft'),\n",
    "                  ('Figure_5_g2',   'f5*-ft'),\n",
    "                  ('Figure_5_g5',   'f5*-ft'),\n",
    "                 ]\n",
    "\n",
    "for fig_folder in fig_folder_lst:\n",
    "    print('fig_folder', fig_folder)\n",
    "    \n",
    "    load_folder = base_location / Path(fig_folder[0])\n",
    "    # load_folder = base_location / Path(r'tmp')\n",
    "    h5_recons_locations = str((load_folder / Path('all') / Path(fig_folder[1]) / Path(r'reconstructs\\best_resids_*.h5')).resolve())\n",
    "    \n",
    "#     print(h5_recons_locations)\n",
    "    \n",
    "#     load_folder = base_location / Path(r'Figure_1_2')\n",
    "#     # load_folder = base_location / Path(r'tmp')\n",
    "#     h5_recons_locations = str((load_folder / Path(r'all\\f1*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # h5_recons_locations = str((load_folder / Path(r'all/f1*-ft/reconstructs/best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_3')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f3*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_4_g1')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_4_g2')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g1')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g2')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g5')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "\n",
    "    out_folder = base_location / Path(r'final_outputs')\n",
    "\n",
    "    out_loc = str((out_folder).resolve())\n",
    "    h5_recons_locations = glob.glob(h5_recons_locations)\n",
    "\n",
    "\n",
    "    h5_lst = defaultdict(dict)\n",
    "#     run_id_dct = defaultdict(dict)\n",
    "\n",
    "\n",
    "    for ih5, h5_coef_fn in enumerate(h5_recons_locations):\n",
    "        h5f = pd.HDFStore(h5_coef_fn)\n",
    "        h5fk = h5f.keys()\n",
    "        for ik, key in enumerate(h5fk):\n",
    "            key = key.replace('/', '')\n",
    "            resp = key.split('_')[0]\n",
    "            model_version = '_'.join(key.split('_')[3:]).split('_run_num')[0]\n",
    "            \n",
    "\n",
    "            if 'run_num' in key and 'run_num__0' not in key: #and 'run_num__1' not in key:\n",
    "                continue\n",
    "            if 'base_simple' not in model_version and 'base_words' not in model_version and '_to_' not in model_version and 'basis' not in key:\n",
    "                continue\n",
    "            \n",
    "#             print('model_version', model_version)\n",
    "            \n",
    "#             print(key, model_version)\n",
    "#             print(f'ih5, ik, model_version, key, h5_coef_fn - {ih5}, {ik}, {model_version}, {key}, {h5_coef_fn}')\n",
    "\n",
    "            y_col = key.split('_')[0].replace(r'/', r'')\n",
    "            \n",
    "            h5_df = pd.read_hdf(h5f, key)\n",
    "\n",
    "            h5_df.columns = [dfh.shorten_col_name(_) for _ in h5_df.columns]\n",
    "\n",
    "            if 'dfrel_basis' != key.replace('/', ''):\n",
    "                h5_df.columns = [_.split('_')[0] for _ in h5_df.columns]\n",
    "                h5_df['true'] = h5_lst[ih5]['dfrel'][y_col]\n",
    "\n",
    "                h5_df['file_num'] = h5_lst[ih5]['dfrel']['file_num']\n",
    "\n",
    "                h5_df['dupe'] = h5_lst[ih5]['dfrel']['dupe']\n",
    "                h5_df['wi_trial_keep'] = h5_lst[ih5]['dfrel']['wi_trial_keep']\n",
    "\n",
    "                h5_lst[ih5][key] = h5_df\n",
    "            else:\n",
    "                h5_lst[ih5]['dfrel'] = h5_df\n",
    "\n",
    "#     for k in h5_lst:\n",
    "#         for kk in h5_lst[k]:\n",
    "#             print(k, kk)\n",
    "\n",
    "\n",
    "\n",
    "    for ih5 in h5_lst:\n",
    "#     for y_col in ['gACH', 'rDA', 'gDA']:\n",
    "#             fig,axes = plt.subplots(5,2,figsize=(10,30))\n",
    "\n",
    "        dupe = h5_lst[ih5]['dfrel']['dupe']\n",
    "        dfrel_basis = h5_lst[ih5]['dfrel'].loc[~dupe]\n",
    "        \n",
    "        dupe = h5_lst[ih5]['dfrel']['dupe']\n",
    "        dfrel_basis = h5_lst[ih5]['dfrel'].loc[~dupe]\n",
    "\n",
    "        for key in tqdm(h5_lst[ih5]):\n",
    "#         for y_col in ['gACH', 'rDA', 'gDA']:\n",
    "#         for ih5 in h5_lst:\n",
    "            if key == 'dfrel':\n",
    "                continue\n",
    "            \n",
    "\n",
    "            dfrel_basis_run = h5_lst[ih5][key].loc[~dupe]\n",
    "            \n",
    "            keep_rows_r, assoc_deltas_r = get_delta_list(dfrel_basis['SIr'], ((dfrel_basis_run['holdout']==1)).astype(bool))\n",
    "            krr = ([tuple(_.index[_]) for _ in keep_rows_r])\n",
    "            keep_rows_nr, assoc_deltas_nr = get_delta_list(dfrel_basis['SInr'], ((dfrel_basis_run['holdout']==1)).astype(bool))\n",
    "            krnr = ([tuple(_.index[_]) for _ in keep_rows_nr])\n",
    "            \n",
    "            krr_len = len(keep_rows_r)\n",
    "            krnr_len = len(keep_rows_nr)\n",
    "            \n",
    "            print('---------------------------')\n",
    "            print('SIr:', krr_len)\n",
    "            print('SInr:', krnr_len)\n",
    "            print('---------------------------')\n",
    "            \n",
    "            ac_krs = {}\n",
    "            \n",
    "            combo_rdc = {}\n",
    "            for iac, alignment_col in enumerate(all_alignment_cols):\n",
    "    #                 ic, ir = iac%2, iac//2\n",
    "    #                 ax = axes[ir, ic]\n",
    "    \n",
    "\n",
    "                \n",
    "                resp = key.split('_')[0].replace('/', '')\n",
    "                model_version = '_'.join(key.split('_')[3:]).split('_run_num')[0]\n",
    "                y_col = key.split('_')[0].replace(r'/', r'')\n",
    "                \n",
    "                print('Pulling delta list')\n",
    "                keep_rows, assoc_deltas = get_delta_list(dfrel_basis[alignment_col], ((dfrel_basis_run['holdout']==1)).astype(bool))\n",
    "                \n",
    "                ac_krs[alignment_col] = ([tuple(_.index[_]) for _ in keep_rows])\n",
    "                lnac = len(ac_krs[alignment_col])\n",
    "                \n",
    "                if alignment_col in ['SIAA', 'SIaA', 'SIAB', 'SIaB']:\n",
    "                    print(f'{alignment_col} -- Prc:', np.round(lnac/krr_len,3), '- Num:', lnac)\n",
    "                else:\n",
    "                    print(f'{alignment_col} -- Prc:', np.round(lnac/krnr_len,3), '- Num:', lnac)\n",
    "                \n",
    "#                 rdc_lst = defaultdict(list)\n",
    "#                 for entry_num in trange(len(keep_rows)):\n",
    "#                     keep_row_single = keep_rows[entry_num]\n",
    "#                     deltas = assoc_deltas[entry_num]\n",
    "#                     rdc_df = dfrel_basis_run.loc[keep_row_single].set_index(deltas)\n",
    "\n",
    "#                     if rdc_df['file_num'].nunique() > 1:\n",
    "#                         continue\n",
    "                    \n",
    "# #                     print(keep_rows)\n",
    "                    \n",
    "#                     break\n",
    "#                 print(np.all(dfrel_basis['SIr'] == dfrel_basis['SIAA'] + dfrel_basis['SIaA'] + dfrel_basis['SIAB'] + dfrel_basis['SIaB']))\n",
    "#                 print(np.all(dfrel_basis['SInr'] == dfrel_basis['SIAa'] + dfrel_basis['SIaa'] + dfrel_basis['SIAb'] + dfrel_basis['SIab']))\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "    \n",
    "#                 print('keys', rdc_lst.keys())\n",
    " \n",
    "#                 seed = np.random.randint(1000000000)\n",
    "#                 for bootstrap_col in (rdc_lst):\n",
    "#                     tmp_rdc = pd.concat(rdc_lst[bootstrap_col], axis=1).sort_index()\n",
    "\n",
    "#                     reconstruction_data_list = []\n",
    "#                     for delta in (tmp_rdc.index):\n",
    "#                         row = tmp_rdc.loc[delta].dropna().values\n",
    "#                         bs = scipy.stats.bootstrap((row,), np.mean, n_resamples=9999,\n",
    "#     #                     bs = scipy.stats.bootstrap((row,), np.mean, n_resamples=1000,\n",
    "#                                                    batch=None, vectorized=True, paired=False,\n",
    "#                                                    axis=0, confidence_level=0.95, method='BCa',\n",
    "#                                                    random_state=seed)\n",
    "\n",
    "#                         mn_val = row.mean()\n",
    "#                         rtup = (bootstrap_col, delta, bs.confidence_interval.low, mn_val, bs.confidence_interval.high)\n",
    "\n",
    "#                         reconstruction_data_list.append(rtup)\n",
    "\n",
    "#                     tmp_combo_rdc = pd.DataFrame(reconstruction_data_list, columns=['basis_column', 'delta', 'lb', 'mn', 'ub']).set_index('delta')\n",
    "#                     combo_rdc[f'{alignment_col}_{bootstrap_col}'] = tmp_combo_rdc.drop('basis_column',axis=1)\n",
    "\n",
    "#             combo_rdc = pd.concat(combo_rdc, axis=1)\n",
    "#             combo_rdc.columns = ['_'.join(_).replace('_true_', '_T_').replace('_pred_', '_P_') for _ in combo_rdc.columns]\n",
    "#             combo_rdc.to_csv(str((Path(out_loc) / f'{load_folder.parts[-1]}-reconstruct-{y_col}={model_version}.csv').resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "smr = list(ac_krs['SIAA']) + list(ac_krs['SIAB']) + list(ac_krs['SIaA']) + list(ac_krs['SIaB'])\n",
    "smnr = list(ac_krs['SIAa']) + list(ac_krs['SIAb']) + list(ac_krs['SIaa']) + list(ac_krs['SIab'])\n",
    "# for tup in tqdm(set([tuple(_.index[_]) for _ in ac_krs['SIAA'] + ac_krs['SIAB'] + ac_krs['SIaA'] + ac_krs['SIaB']])):\n",
    "# #     print(tup)\n",
    "#     if tup not in set([tuple(_.index[_]) for _ in keep_rows_r]):\n",
    "#         print('Not Found!')\n",
    "\n",
    "sorted(smr) == sorted(krr), sorted(smnr) == sorted(krnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([tuple(_.index[_]) for _ in ac_krs['SIAA']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_[_] for _ in keep_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_rdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in h5_lst:\n",
    "#     for kk in h5_lst[k]:\n",
    "#         print(k, kk)\n",
    "# #         display(h5_lst[k][kk])\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(h5_lst['dfrel'][_]) for _ in range(len(h5_lst['dfrel']))], [len(h5_lst[y_col][_]) for _ in range(len(h5_lst[y_col]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dupe), len(h5_lst[y_col][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_rdc[[_ for _ in combo_rdc.columns if '_mn' in _]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col, model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id_dct[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base_location = Path(r'/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/outputs')\n",
    "# base_location = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs')\n",
    "\n",
    "# fig_folder_lst = [#('Figure_1_2', 'f1*-ft'),\n",
    "#                   #('Figure_3',   'f3*-ft'),\n",
    "#                   #('Figure_4_g1',   'f4*-ft'),\n",
    "#                   ('Figure_4_g2',   'f4*-ft'),\n",
    "#                   #('Figure_5_g1',   'f5*-ft'),\n",
    "#                   #('Figure_5_g2',   'f5*-ft'),\n",
    "#                   #('Figure_5_g5',   'f5*-ft'),\n",
    "#                  ]\n",
    "\n",
    "# for fig_folder in fig_folder_lst:\n",
    "#     print('fig_folder', fig_folder)\n",
    "    \n",
    "#     load_folder = base_location / Path(fig_folder[0])\n",
    "#     # load_folder = base_location / Path(r'tmp')\n",
    "#     h5_recons_locations = str((load_folder / Path('all') / Path(fig_folder[1]) / Path(r'reconstructs\\best_resids_*.h5')).resolve())\n",
    "    \n",
    "#     print(h5_recons_locations)\n",
    "    \n",
    "# #     load_folder = base_location / Path(r'Figure_1_2')\n",
    "# #     # load_folder = base_location / Path(r'tmp')\n",
    "# #     h5_recons_locations = str((load_folder / Path(r'all\\f1*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "# #     # h5_recons_locations = str((load_folder / Path(r'all/f1*-ft/reconstructs/best_resids_*.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_3')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f3*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_4_g1')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_4_g2')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_5_g1')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_5_g2')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "# #     # load_folder = base_location / Path(r'Figure_5_g5')\n",
    "# #     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "\n",
    "#     out_folder = base_location / Path(r'final_outputs')\n",
    "\n",
    "#     out_loc = str((out_folder).resolve())\n",
    "#     h5_recons_locations = glob.glob(h5_recons_locations)\n",
    "\n",
    "\n",
    "#     h5_lst = defaultdict(list)\n",
    "#     run_id_dct = defaultdict(list)\n",
    "\n",
    "\n",
    "#     for h5_coef_fn in h5_recons_locations:\n",
    "#         h5f = pd.HDFStore(h5_coef_fn)\n",
    "#         h5fk = h5f.keys()\n",
    "#         for key in h5fk:\n",
    "\n",
    "#             resp = key.split('_')[0].replace('/', '')\n",
    "#             model_version = '_'.join(key.split('_')[3:]).split('_run_num')[0]\n",
    "\n",
    "#             if 'run_num' in key and 'run_num__0' not in key: #and 'run_num__1' not in key:\n",
    "#                 continue\n",
    "#             if 'base_simple' not in key and 'base_words' not in key and 'basis' not in key:\n",
    "#                 continue\n",
    "#             print(key, model_version)\n",
    "\n",
    "#             y_col = key.split('_')[0].replace(r'/', r'')\n",
    "#             h5_df = pd.read_hdf(h5f, key)\n",
    "\n",
    "#             h5_df.columns = [dfh.shorten_col_name(_) for _ in h5_df.columns]\n",
    "\n",
    "#             if 'dfrel_basis' != key.replace('/', ''):\n",
    "#                 h5_df.columns = [_.split('_')[0] for _ in h5_df.columns]\n",
    "#                 h5_df['true'] = h5_lst['dfrel'][-1][y_col]\n",
    "#                 h5_df['resid2'] = (h5_df['true'] - h5_df['pred'])**2\n",
    "\n",
    "#                 h5_df['file_num'] = h5_lst['dfrel'][-1]['file_num']\n",
    "\n",
    "#                 h5_df['dupe'] = h5_lst['dfrel'][-1]['dupe']\n",
    "#                 h5_df['wi_trial_keep'] = h5_lst['dfrel'][-1]['wi_trial_keep']\n",
    "\n",
    "#                 h5_lst[y_col].append(h5_df)\n",
    "#                 run_id_dct[y_col].append(model_version)\n",
    "#             else:\n",
    "#                 h5_lst[y_col].append(h5_df)\n",
    "#                 run_id_dct[y_col].append('basis')\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "#     for i in range(2):\n",
    "#         for y_col in ['gACH', 'rDA', 'gDA']:\n",
    "# #             fig,axes = plt.subplots(5,2,figsize=(10,30))\n",
    "\n",
    "#             combo_rdc = {}\n",
    "#             for iac, alignment_col in enumerate(all_alignment_cols):\n",
    "# #                 ic, ir = iac%2, iac//2\n",
    "# #                 ax = axes[ir, ic]\n",
    "\n",
    "#                 dupe = h5_lst['dfrel'][-1]['dupe']\n",
    "#                 dfrel_basis = h5_lst['dfrel'][-1].loc[~dupe]\n",
    "#                 dfrel_basis_run = h5_lst[y_col][i].loc[~dupe]\n",
    "\n",
    "#                 model_version = run_id_dct[y_col][i]\n",
    "\n",
    "#                 print('Pulling delta list')\n",
    "#                 keep_rows, assoc_deltas = get_delta_list(dfrel_basis[alignment_col], alignment_col, ((dfrel_basis_run['holdout']==1)).astype(bool))\n",
    "#                 rdc_lst = defaultdict(list)\n",
    "#                 for entry_num in trange(len(keep_rows)):\n",
    "#                     keep_row_single = keep_rows[entry_num]\n",
    "#                     deltas = assoc_deltas[entry_num]\n",
    "#                     rdc_df = dfrel_basis_run.loc[keep_row_single].set_index(deltas)\n",
    "\n",
    "#                     if rdc_df['file_num'].nunique() > 1:\n",
    "#                         continue\n",
    "\n",
    "#                     reconstruction_data_list = []\n",
    "\n",
    "#                     for bootstrap_col in ['true', 'pred']:\n",
    "#                         rdc_lst[bootstrap_col].append(rdc_df[[bootstrap_col]])\n",
    "\n",
    "#                 print('keys', rdc_lst.keys())\n",
    "\n",
    "#                 seed = np.random.randint(1000000000)\n",
    "#                 for bootstrap_col in (rdc_lst):\n",
    "#                     tmp_rdc = pd.concat(rdc_lst[bootstrap_col], axis=1).sort_index()\n",
    "\n",
    "#                     reconstruction_data_list = []\n",
    "#                     for delta in (tmp_rdc.index):\n",
    "#                         row = tmp_rdc.loc[delta].dropna().values\n",
    "#                         bs = scipy.stats.bootstrap((row,), np.mean, n_resamples=9999,\n",
    "#     #                     bs = scipy.stats.bootstrap((row,), np.mean, n_resamples=1000,\n",
    "#                                                    batch=None, vectorized=True, paired=False,\n",
    "#                                                    axis=0, confidence_level=0.95, method='BCa',\n",
    "#                                                    random_state=seed)\n",
    "\n",
    "#                         mn_val = row.mean()\n",
    "#                         rtup = (bootstrap_col, delta, bs.confidence_interval.low, mn_val, bs.confidence_interval.high)\n",
    "\n",
    "#                         reconstruction_data_list.append(rtup)\n",
    "\n",
    "#                     tmp_combo_rdc = pd.DataFrame(reconstruction_data_list, columns=['basis_column', 'delta', 'lb', 'mn', 'ub']).set_index('delta')\n",
    "#                     combo_rdc[f'{alignment_col}_{bootstrap_col}'] = tmp_combo_rdc.drop('basis_column',axis=1)\n",
    "\n",
    "#             combo_rdc = pd.concat(combo_rdc, axis=1)\n",
    "#             combo_rdc.columns = ['_'.join(_).replace('_true_', '_T_').replace('_pred_', '_P_') for _ in combo_rdc.columns]\n",
    "#             combo_rdc.to_csv(str((Path(out_loc) / f'{load_folder.parts[-1]}-reconstruct-{y_col}={model_version}.csv').resolve()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(h5_lst['dfrel'][0].dropna() == h5_lst['dfrel'][1].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5_lst['dfrel'][0]['rDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_lst.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
