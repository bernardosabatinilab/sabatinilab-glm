{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87edd2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "from sglm.models import sglm_cv\n",
    "import itertools\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import setup_model_fit as smf\n",
    "from sglm.models import sglm_cv\n",
    "from sglm import models\n",
    "from sglm.visualization import visualize\n",
    "from sglm.models import train_model\n",
    "from sglm.models import eval\n",
    "from sglm import features\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import traceback\n",
    "import warnings\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e93da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From stack overflow\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ffb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_multifiles(wt_used, signal_files, widest_orders, shift_spacer='_sft_', ignore_missing=True):\n",
    "    # needed info\n",
    "    # Params: wt_used, signal_files, widest_orders, multifile_fit\n",
    "    # Returns: mouse_names, combo_dfs, combo_fns, X_cols_sftd\n",
    "    \n",
    "    \n",
    "    if ignore_missing:\n",
    "        dropped_files = [_ for _ in signal_files if not Path(_).exists()]\n",
    "        signal_files = [_ for _ in signal_files if _ not in dropped_files]\n",
    "        display(f'Dropped files:', dropped_files)\n",
    "        display(f'Signal files:', signal_files)\n",
    "    \n",
    "    file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "    print('file_ids', file_ids)\n",
    "    combo_dfs, X_cols_sftd, _ = smf.multi_file_analysis_prep(signal_files, widest_orders, file_ids, shift_spacer='_sft_', keep_unshifted=True)\n",
    "#     combo_dfs, X_cols_sftd, _ = smf.multi_file_analysis_prep_nosft(signal_files, widest_orders, file_ids)\n",
    "    combo_fns = ['_'.join(wt_used).replace('WT', '').replace('S', '')]\n",
    "    mouse_names = combo_fns\n",
    "\n",
    "    return mouse_names, combo_dfs, combo_fns, X_cols_sftd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f53021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dict_to_json(source_dict, json_path):\n",
    "    with open(str((json_path).resolve()), 'w') as json_file:\n",
    "        json.dump(source_dict, json_file)\n",
    "\n",
    "def read_json(json_path):\n",
    "    with open(str((json_path).resolve()), 'r') as json_file:\n",
    "        read_json = json.load(json_file)\n",
    "    return read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9fd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_rows_with_all_cols(dfrel_basis,\n",
    "                          X_y_pairings,\n",
    "                          X_cols_sftd, \n",
    "                          drop_cols_basis = ['nTrial', 'nTrial_filenum',\n",
    "                                             'cpn', 'cpx', 'spnnr', 'spxnr', 'spnr', 'spxr',\n",
    "                                             \n",
    "                                             'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "                                             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                                             'photometrySideOutIndex', 'spnnrOff',\n",
    "                                             \n",
    "                                             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                                             'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "                                             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                                             'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "#                                              'sl',\n",
    "#                                              'slOff'\n",
    "                                            ]):\n",
    "    full_drop_basis = []\n",
    "    y_col_lst = []\n",
    "    for X_y_dct in X_y_pairings:\n",
    "        full_drop_basis += bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd)\n",
    "        y_col_lst += [X_y_dct['y_col']]\n",
    "    y_col_drop_basis = sorted(list(set(y_col_lst)))\n",
    "    full_drop_basis = sorted(list(set(drop_cols_basis + full_drop_basis + y_col_drop_basis)))\n",
    "\n",
    "    num_cols_na = (dfrel_basis[full_drop_basis].isna().sum(axis=1))\n",
    "    num_y_0 = (dfrel_basis[y_col_drop_basis] == 0).sum(axis=1)\n",
    "    has_all_cols = (num_cols_na == 0)&(num_y_0 == 0)\n",
    "\n",
    "    return has_all_cols\n",
    "\n",
    "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "\n",
    "    log = file if hasattr(file,'write') else sys.stderr\n",
    "    traceback.print_stack(file=log)\n",
    "    log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "\n",
    "warnings.showwarning = warn_with_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81538750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holdout_and_cv_idx(df_available, pholdout, folds, pgss, filter_series, id_cols=['nTrial_filenum']):\n",
    "    holdout_series = models.split_data.holdout_split_by_trial_id(df_available,\n",
    "                                                                id_cols=id_cols,\n",
    "                                                                perc_holdout=pholdout)\n",
    "    cv_idx_lst = models.split_data.cv_idx_by_trial_id(dfrel_basis_has_all_cols[(~holdout_series)&(filter_series)],\n",
    "                                                             trial_id_columns=id_cols,\n",
    "                                                             num_folds=folds,\n",
    "                                                             test_size=pgss)\n",
    "    return holdout_series, cv_idx_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5757a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698abfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ad488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b8e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3bdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50a613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1\n",
    "param_set_json_name = 'full_model_param_set.json'\n",
    "\n",
    "# source_data_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\interim')\n",
    "# output_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs_clean')\n",
    "\n",
    "# source_data_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/data/interim_check')\n",
    "# output_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/outputs_check')\n",
    "\n",
    "# source_data_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/data/mike-GLM_8020-interim')\n",
    "# output_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/outputs-mike-GLM_8020')\n",
    "\n",
    "\n",
    "# source_data_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/data/lynne-sanity-interim')\n",
    "# output_path = Path(r'/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/outputs_lynne-sanity')\n",
    "\n",
    "# source_data_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\mike-GLM_7030-interim')\n",
    "# output_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs_mike-GLM_7030')\n",
    "\n",
    "source_data_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\mike-GLM_8020-interim')\n",
    "output_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs_mike-GLM_8020')\n",
    "\n",
    "# source_data_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\mike-GLM_9010-interim')\n",
    "# output_path = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs_mike-GLM_9010')\n",
    "\n",
    "preproc_params_name = r'preproc_params.json'\n",
    "basis_name = r'_basis.csv'\n",
    "# figname = 'fig_8020'\n",
    "# groupid = 'g1'\n",
    "figname = 'fig'\n",
    "groupid = 'g'\n",
    "# param_set_id = '-20_+20_rwd_wco_fixedfilelist'\n",
    "param_set_id = '-5_+5_rerun'\n",
    "neg_order = -5\n",
    "pos_order = 5\n",
    "fix_training = True\n",
    "num_runs = 3\n",
    "# num_runs = 10\n",
    "folds = 10\n",
    "pholdout = 0.5\n",
    "pgss = 0.2\n",
    "score_method = 'mse'\n",
    "val_test_inx_sel_method = 'irun'\n",
    "\n",
    "X_y_pairings_lst = []\n",
    "# X_y_pairings_lst += [[\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "#                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndex':(0,0),\n",
    "#                 'photometrySideInIndexr':(0,0),                \n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gDA',\n",
    "# #      'y_col': 'gGLUr',\n",
    "# #      'y_col': 'GCAMP',\n",
    "#      'name': 'base_simple'\n",
    "#      },\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "#                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndexAA':(0,0),\n",
    "#                 'photometrySideInIndexAa':(0,0),\n",
    "#                 'photometrySideInIndexaA':(0,0),\n",
    "#                 'photometrySideInIndexaa':(0,0),\n",
    "#                 'photometrySideInIndexAB':(0,0),\n",
    "#                 'photometrySideInIndexAb':(0,0),\n",
    "#                 'photometrySideInIndexaB':(0,0),\n",
    "#                 'photometrySideInIndexab':(0,0),\n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gDA',\n",
    "# #      'y_col': 'gGLUr',\n",
    "# #      'y_col': 'GCAMP',\n",
    "#      'name': 'base_words'},\n",
    "\n",
    "# ]]\n",
    "X_y_pairings_lst += [[\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndexLt':(0,0),\n",
    "                'photometryCenterOutIndexRt':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),\n",
    "                'photometrySideOutIndexLt':(0,0),\n",
    "                'photometrySideOutIndexRt':(0,0),\n",
    "               },\n",
    "     'y_col': 'GCAMP',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "\n",
    "]]\n",
    "\n",
    "# Select hyper parameters for GLM to use for model selection\n",
    "# Step 1: Create a dictionary of lists for these relevant keywords...\n",
    "kwargs_iterations = {\n",
    "    # 'alpha': [0],\n",
    "    # 'l1_ratio': [0],\n",
    "\n",
    "#     'alpha': [0.0, 0.01, 0.1, 1.0],\n",
    "#     'l1_ratio': [0.0, 0.01, 0.1, 1.0],\n",
    "#     'alpha': [0.0, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0],\n",
    "    'alpha': [0.0],\n",
    "    'l1_ratio': [0.0],\n",
    "}\n",
    "\n",
    "# Step 2: Create a dictionary for the fixed keyword arguments that do not require iteration...\n",
    "kwargs_fixed = {\n",
    "    'max_iter': 10000,\n",
    "    'fit_intercept': False\n",
    "}\n",
    "\n",
    "dfrr_cols = ['signal_file', 'file_num', 'nTrial', 'nTrial_filenum', 'nEndTrial', 'wi_trial_keep',\n",
    "#              'nTrial_hard', 'nEndTrial_hard', 'diffTrialNums_hard', 'wi_trial_keep_hard',\n",
    "             'has_all_cols',\n",
    "#              'gDA',\n",
    "#              'gGLUr',\n",
    "#              'gDA', 'gACH', 'rDA', 'gGLUr', 'gGLUl',\n",
    "             'GCAMP',\n",
    "             'diffTrialNums', 'dupe',\n",
    "             'photometryCenterInIndex',\n",
    "             'photometryCenterOutIndexLt', 'photometryCenterOutIndexRt',\n",
    "             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "             'photometrySideOutIndex',\n",
    "             'photometrySideOutIndexLt', 'photometrySideOutIndexRt',\n",
    "#              'spnnrOff',\n",
    "#              'sl',\n",
    "\n",
    "             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "             'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "             'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "]\n",
    "\n",
    "\n",
    "count_event_names = {\n",
    "    'photometrySideInIndex': 'total_events',\n",
    "\n",
    "    'photometrySideInIndexr': 'r',\n",
    "    'photometrySideInIndexnr': 'nr',\n",
    "\n",
    "    'photometrySideInIndexLt': 'lt',\n",
    "    'photometrySideInIndexRt': 'rt',\n",
    "\n",
    "    'photometrySideInIndexAA': 'AA',\n",
    "    'photometrySideInIndexAa': 'Aa',\n",
    "    'photometrySideInIndexAB': 'AB',\n",
    "    'photometrySideInIndexAb': 'Ab',\n",
    "\n",
    "    'photometrySideInIndexaA': 'aA',\n",
    "    'photometrySideInIndexaa': 'aa',\n",
    "    'photometrySideInIndexaB': 'aB',\n",
    "    'photometrySideInIndexab': 'ab',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec00fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate iterable list of keyword sets for possible combinations\n",
    "glm_kwarg_lst = sglm_cv.generate_mult_params(kwargs_iterations, kwargs_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e77a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8283e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Part 1\n",
    "data_path = (source_data_path / figname / groupid)\n",
    "\n",
    "param_set_output_path = output_path / Path(figname) / Path(groupid) / Path(param_set_id)\n",
    "param_set_output_path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "interim_preproc_errors_path = data_path / 'interim_preproc_errors.csv'\n",
    "interim_preproc_errors_df = pd.read_csv(str(interim_preproc_errors_path.resolve()))\n",
    "error_file_list = interim_preproc_errors_df['out_file_errors'].to_list()\n",
    "\n",
    "preproc_params = read_json(source_data_path / preproc_params_name)\n",
    "dump_dict_to_json(preproc_params, param_set_output_path / preproc_params_name)\n",
    "\n",
    "param_set_dct = {\n",
    "    'source_data_path': str((source_data_path).resolve()),\n",
    "    'output_path': str((output_path).resolve()),\n",
    "    'basis_name': basis_name,\n",
    "    'figname': figname,\n",
    "    'groupid': groupid,\n",
    "    'param_set_id': param_set_id,\n",
    "    'neg_order': neg_order,\n",
    "    'pos_order': pos_order,\n",
    "    'fix_training': fix_training,\n",
    "    'num_runs': num_runs,\n",
    "    'folds': folds,\n",
    "    'pholdout': pholdout,\n",
    "    'pgss': pgss,\n",
    "    'score_method': score_method,\n",
    "    'val_test_inx_sel_method': val_test_inx_sel_method,\n",
    "    'X_y_pairings_lst': X_y_pairings_lst,\n",
    "    'kwargs_iterations': kwargs_iterations,\n",
    "    'kwargs_fixed': kwargs_fixed,\n",
    "    'dfrr_cols': dfrr_cols,\n",
    "    'count_event_names': count_event_names,\n",
    "}\n",
    "dump_dict_to_json(param_set_dct, param_set_output_path / param_set_json_name)\n",
    "\n",
    "basis = pd.read_csv(source_data_path / basis_name, index_col=0)\n",
    "basis['mouseid'] = basis['mouseid'].astype(str)\n",
    "relevant_basis = basis[(basis['figname'] == figname)&(basis['groupid'] == groupid)]\n",
    "wt_used = relevant_basis['mouseid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b58a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing error found for file: GLM_SIGNALS_INTERIM_sstflp26_03232021.txt\n",
      "Preprocessing error found for file: GLM_SIGNALS_INTERIM_sstflp15_07242019.txt\n"
     ]
    }
   ],
   "source": [
    "# Load Signal Data\n",
    "signal_files = []\n",
    "mouse_names = []\n",
    "for inx, basis_row in relevant_basis.iterrows():\n",
    "    signal_file_out = basis_row['signal_file_out']\n",
    "    \n",
    "    if signal_file_out in error_file_list:\n",
    "        print(f'Preprocessing error found for file: {signal_file_out}')\n",
    "        continue\n",
    "    \n",
    "    signal_path = data_path / signal_file_out\n",
    "    signal_files.append(str(signal_path.resolve()))\n",
    "    mouse_names.append(basis_row['mouseid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a231001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Part 2: Generate base files to use by all runs and create folders for each run\n",
    "\n",
    "# max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "# multi_start = time.time()\n",
    "# for iXyp, X_y_pairings in enumerate(X_y_pairings_lst):\n",
    "\n",
    "#     widest_orders = smf.xy_pairs_to_widest_orders([{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "#                                                     'y_col': _['y_col']} for _ in X_y_pairings])\n",
    "#     max_cols_len = max_cols_len_lst[iXyp]\n",
    "# #     mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders)\n",
    "    \n",
    "#     file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "#     signal_df, signal_df_unsft = smf.multi_file_analysis_prep(signal_files, widest_orders, file_ids)\n",
    "#     combo_fns = ['_'.join(wt_used).replace('WT', '').replace('S', '')]\n",
    "#     mouse_names = combo_fns\n",
    "    \n",
    "#     break\n",
    "\n",
    "# whr = np.where(signal_df.fillna(-1) != signal_df_unsft.fillna(-1))\n",
    "# signal_df.iloc[whr[0][:10],whr[1][:10]]\n",
    "\n",
    "# signal_df_unsft.iloc[whr[0][:10],whr[1][:10]]\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a898e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808a6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a64ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_width = 2\n",
    "# plot_rows_lst = [_//plot_width + (_%plot_width > 0)*1 for _ in max_cols_len_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae58e800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dropped files:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Signal files:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_04062021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_04022021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03312021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03292021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03192021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03172021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_04072021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_04052021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03302021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03262021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03222021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03182021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_04062021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03252021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03232021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03192021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03172021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03162021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03112021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03052021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03012021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_03242021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_04022021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03312021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03292021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03052021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp26_03252021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp25_04012021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03112021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03092021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp24_03012021.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_12132019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_12052019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_11182019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_11052019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_10102019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_09302019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_09232019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_09112019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_08282019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_08232019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp15_08012019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_12102019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_11142019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp17_11082019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_10042019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_09052019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp16_08202019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp15_08122019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp15_08072019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp15_07032019.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\mike-GLM_8020-interim\\\\fig\\\\g\\\\GLM_SIGNALS_INTERIM_sstflp15_06282019.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_ids ['GLM_SIGNALS_INTERIM_sstflp26_04062021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_04022021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03312021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03292021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03192021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03172021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_04072021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_04052021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03302021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03262021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03222021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03182021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_04062021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03252021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03232021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03192021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03172021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03162021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03112021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03052021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03012021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_03242021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_04022021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03312021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03292021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03052021.txt', 'GLM_SIGNALS_INTERIM_sstflp26_03252021.txt', 'GLM_SIGNALS_INTERIM_sstflp25_04012021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03112021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03092021.txt', 'GLM_SIGNALS_INTERIM_sstflp24_03012021.txt', 'GLM_SIGNALS_INTERIM_sstflp17_12132019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_12052019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_11182019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_11052019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_10102019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_09302019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_09232019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_09112019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_08282019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_08232019.txt', 'GLM_SIGNALS_INTERIM_sstflp15_08012019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_12102019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_11142019.txt', 'GLM_SIGNALS_INTERIM_sstflp17_11082019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_10042019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_09052019.txt', 'GLM_SIGNALS_INTERIM_sstflp16_08202019.txt', 'GLM_SIGNALS_INTERIM_sstflp15_08122019.txt', 'GLM_SIGNALS_INTERIM_sstflp15_08072019.txt', 'GLM_SIGNALS_INTERIM_sstflp15_07032019.txt', 'GLM_SIGNALS_INTERIM_sstflp15_06282019.txt']\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Generate base files to use by all runs and create folders for each run\n",
    "\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "for iXyp, X_y_pairings in enumerate(X_y_pairings_lst):\n",
    "    \n",
    "    Xyp_path = param_set_output_path / Path(f'iXyp_{iXyp}')\n",
    "    Xyp_path.mkdir(parents=True, exist_ok=False)\n",
    "    dump_dict_to_json(X_y_pairings, Xyp_path / Path('X_y_pairings.json'))\n",
    "    \n",
    "    \n",
    "    widest_orders = smf.xy_pairs_to_widest_orders([{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "                                                    'y_col': _['y_col']} for _ in X_y_pairings])\n",
    "    max_cols_len = max_cols_len_lst[iXyp]\n",
    "    mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders, shift_spacer='_sft_')\n",
    "    \n",
    "    start = time.time()\n",
    "    results_dict = {}\n",
    "    \n",
    "    dfrel_basis = combo_dfs[0].reset_index(drop=False).copy()\n",
    "    \n",
    "#     fn = Path(combo_fns[file_num].split('.')[0]).parts[-1]\n",
    "    \n",
    "    mouse_id = mouse_names[0]\n",
    "    dfresids_cols = np.copy(dfrr_cols).tolist()\n",
    "#     run_id = f'{fn}_{iXyp}'         \n",
    "    has_all_cols = id_rows_with_all_cols(dfrel_basis, X_y_pairings, X_cols_sftd)\n",
    "    if has_all_cols.sum() == 0:\n",
    "        print(f'No datapoints found for non-NaN dropcols & non-zero ycols for fixed_training: {prefix}_{fn}')\n",
    "        continue\n",
    "\n",
    "    dfrel_basis['has_all_cols'] = has_all_cols    \n",
    "    basis_column_indices = {\n",
    "        'basis_cols': list(dfrel_basis.columns),\n",
    "        'basis_index': list(dfrel_basis.index),\n",
    "    }\n",
    "    dump_dict_to_json(basis_column_indices, Xyp_path / Path('basis_column_indices.json'))\n",
    "    \n",
    "    \n",
    "#     dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_hdf(str((Xyp_path / Path(f'combo_df.h5')).resolve()), key='combo', index=True,)\n",
    "#     dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_csv(str((Xyp_path / Path(f'combo_df.csv')).resolve()), index=True)\n",
    "    dfrel_basis[[_ for _ in dfrel_basis.columns if '_sft_' not in _]].to_csv(str((Xyp_path / Path(f'combo_df.csv')).resolve()), index=True)\n",
    "#     dfrel_basis.to_hdf(str((Xyp_path / Path(f'combo_df.hd5')).resolve()), key='holdout', index=True)\n",
    "    \n",
    "#     dfrel_basis_reload = pd.read_csv(str((Xyp_path / Path(f'combo_df.csv')).resolve()), index_col=0)\n",
    "#     dfrel_basis_reload, X_cols_sftd_reload = smf.timeshift_vals_by_dict(dfrel_basis_reload, widest_orders, keep_nans=True,\n",
    "#                                                                         groupby_cols=['file_num'], shift_spacer='_sft_')\n",
    "    \n",
    "    dfrel_basis_has_all_cols = dfrel_basis[dfrel_basis['has_all_cols']]\n",
    "    cv_holdout_idx_params = dict(df_available=dfrel_basis_has_all_cols,\n",
    "                                 pholdout=pholdout,\n",
    "                                 folds=folds,\n",
    "                                 pgss=pgss,\n",
    "                                 filter_series=dfrel_basis_has_all_cols['wi_trial_keep'],\n",
    "                                 id_cols=['nTrial_filenum'])\n",
    "    \n",
    "    for irun in range(num_runs):\n",
    "        holdout_irun, cv_idx_irun = get_holdout_and_cv_idx(**cv_holdout_idx_params)\n",
    "        \n",
    "        for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "            holdout_iXyd, cv_idx_iXyd = get_holdout_and_cv_idx(**cv_holdout_idx_params)\n",
    "            \n",
    "            for igkwargs, glm_kwargs in enumerate(glm_kwarg_lst):\n",
    "                holdout_igkwargs, cv_idx_igkwargs = get_holdout_and_cv_idx(**cv_holdout_idx_params)\n",
    "                \n",
    "                run_path = Xyp_path / Path(f'iXyd_{iXyd}-ikwargs_{igkwargs}') / Path(f'irun_{irun}')\n",
    "                run_path.mkdir(parents=True, exist_ok=False)\n",
    "                \n",
    "                specific_model_params = {\n",
    "                    'mouse_id': mouse_id,\n",
    "                    'irun': irun,\n",
    "                    'iXyd': iXyd,\n",
    "                    'igkwargs': igkwargs,\n",
    "                    'X_y_dct': X_y_dct,\n",
    "                    'X_cols': bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd, shift_spacer='_sft_'),\n",
    "                    'y_col': X_y_dct['y_col'],\n",
    "                    'name': X_y_dct['name'],\n",
    "                    'glm_kwargs': glm_kwargs,\n",
    "                }\n",
    "                \n",
    "                dump_dict_to_json(specific_model_params, run_path / Path('specific_model_params.json'))\n",
    "                dump_dict_to_json(param_set_dct, run_path / param_set_json_name)\n",
    "                \n",
    "                holdout_options_df = pd.DataFrame({'holdout_irun': holdout_irun,\n",
    "                                           'holdout_iXyd':holdout_iXyd,\n",
    "                                           'holdout_igkwargs':holdout_igkwargs},\n",
    "                                          index=dfrel_basis_has_all_cols.index)\n",
    "                \n",
    "#                 holdout_df.to_hdf(str((run_path / 'holdout_options.hd5').resolve()), key='holdout')\n",
    "                \n",
    "                cv_options_dct = {\n",
    "                    'cv_idx_irun':cv_idx_irun,\n",
    "                    'cv_idx_iXyd':cv_idx_iXyd,\n",
    "                    'cv_idx_igkwargs':cv_idx_igkwargs,\n",
    "                }\n",
    "#                 np.save(str((run_path/'cv_options.npy').resolve()), np.array(cv_options_dct, dtype='object'))\n",
    "                \n",
    "                kfold_cv_idx = cv_options_dct[f'cv_idx_{val_test_inx_sel_method}']\n",
    "                holdout_srs = holdout_options_df[f'holdout_{val_test_inx_sel_method}']\n",
    "                \n",
    "                np.save(str((run_path/'kfold_cv_idx.npy').resolve()), np.array(kfold_cv_idx, dtype='object'))\n",
    "                \n",
    "#                 holdout_srs.to_hdf(str((run_path / 'holdout.hd5').resolve()), key='holdout')\n",
    "                holdout_srs.to_csv(str((run_path / 'holdout.csv').resolve()), index=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                #### JZ TODO: MOVE TO SEPARATE FILE FOR PARALLELIZATION OVER DEEPEST FOLDERS... ####\n",
    "                #### JZ TODO: MOVE TO SEPARATE FILE FOR PARALLELIZATION OVER DEEPEST FOLDERS... ####\n",
    "                #### JZ TODO: MOVE TO SEPARATE FILE FOR PARALLELIZATION OVER DEEPEST FOLDERS... ####\n",
    "                #### JZ TODO: MOVE TO SEPARATE FILE FOR PARALLELIZATION OVER DEEPEST FOLDERS... ####\n",
    "                #### JZ TODO: MOVE TO SEPARATE FILE FOR PARALLELIZATION OVER DEEPEST FOLDERS... ####\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                ####################################################################################\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "858134b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [_ for _ in glob.glob('/Users/josh/Documents/github_repos/sabatinilab-glm/sglm/data/mike-GLM_8020-interim/fig_8020/g1/*') if '03232021' in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da7db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d697beb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: -1.0320958213136178\n",
      "> cv_R2_score: 0.01513542028024284\n",
      "> cv_mean_score: -1.0338572237353798\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "======\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: -1.02016652394039\n",
      "> cv_R2_score: 0.014242862430771774\n",
      "> cv_mean_score: -1.02574617277417\n",
      "Running multi\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "for iXyp, _ in enumerate(X_y_pairings_lst):\n",
    "    for irun in range(num_runs):\n",
    "        for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "            for igkwargs, glm_kwargs in enumerate(glm_kwarg_lst):                \n",
    "                run_start = time.time()\n",
    "                \n",
    "                Xyp_path = param_set_output_path / Path(f'iXyp_{iXyp}')\n",
    "                X_y_pairings = read_json(Xyp_path / Path('X_y_pairings.json'))\n",
    "                widest_orders = smf.xy_pairs_to_widest_orders([{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "                                                                'y_col': _['y_col']} for _ in X_y_pairings])\n",
    "                max_cols_len = max_cols_len_lst[iXyp]\n",
    "                \n",
    "                run_path = Xyp_path / Path(f'iXyd_{iXyd}-ikwargs_{igkwargs}') / Path(f'irun_{irun}')\n",
    "                specific_model_params = read_json(run_path / Path('specific_model_params.json'))\n",
    "                param_set_dct = read_json(run_path / param_set_json_name)\n",
    "                \n",
    "                X_cols = specific_model_params['X_cols']\n",
    "                y_col = specific_model_params['y_col']\n",
    "                name = specific_model_params['name']\n",
    "                \n",
    "                kfold_cv_idx = np.load(str((run_path / 'kfold_cv_idx.npy').resolve()), allow_pickle=True)\n",
    "                holdout_srs = pd.read_csv(str((run_path / 'holdout.csv').resolve()), index_col=0).iloc[:,0]\n",
    "                \n",
    "                basis_column_indices = read_json(Xyp_path / Path('basis_column_indices.json'))\n",
    "#                 print(f'basis_column_indices: index: {len(basis_column_indices[\"basis_index\"])}, columns: {len(basis_column_indices[\"basis_cols\"])}')\n",
    "                dfrel_basis_load = pd.read_csv(str((Xyp_path / Path(f'combo_df.csv')).resolve()))\n",
    "#                 print('A: dfrel_basis_load.shape',dfrel_basis_load.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dfrel_basis_load, X_cols_sftd_load = smf.timeshift_vals_by_dict(dfrel_basis_load, widest_orders, keep_nans=True, groupby_cols=['file_num'], shift_spacer='_sft_',)\n",
    "#                 print('B: dfrel_basis_load.shape',dfrel_basis_load.shape)\n",
    "                \n",
    "                X_cols_sftd_load = [_ for _ in basis_column_indices if _ in X_cols_sftd_load]\n",
    "                dfrel_basis = dfrel_basis_load.loc[basis_column_indices['basis_index'], basis_column_indices['basis_cols']]\n",
    "                dfrel_basis = dfrel_basis.copy()\n",
    "                \n",
    "#                 print('X_cols', X_cols)\n",
    "#                 print('X_cols_sftd_load', X_cols_sftd_load)\n",
    "                \n",
    "                dfrel_basis['holdout'] = holdout_srs\n",
    "                dfrel_basis_has_all_cols = dfrel_basis[dfrel_basis['has_all_cols']]\n",
    "                \n",
    "                df_train = dfrel_basis_has_all_cols[(~holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "                df_holdout = dfrel_basis_has_all_cols[(holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "                X_train, y_train, X_holdout, y_holdout = df_train[X_cols], df_train[y_col], df_holdout[X_cols], df_holdout[y_col]\n",
    "                \n",
    "#                 print('Pre-CV:', df_train.shape, '|', X_train.shape, y_train.shape, X_holdout.shape, y_holdout.shape)\n",
    "                best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_train, y_train, kfold_cv_idx, [glm_kwargs], model_type='Normal',\n",
    "                                                                                                            verbose=0, score_method=score_method)\n",
    "#                 print('Pre-Fit:', df_train.shape, '|', X_train.shape, y_train.shape, X_holdout.shape, y_holdout.shape)\n",
    "                glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, glm_kwargs)\n",
    "                \n",
    "                run_end = time.time()\n",
    "                \n",
    "                event_counts_train = {count_event_names[key]: df_train[key].sum() for key in count_event_names}\n",
    "                event_counts_holdout = {count_event_names[key]: df_holdout[key].sum() for key in count_event_names}\n",
    "                \n",
    "                fitted_glm = {\n",
    "                    'model': {\n",
    "                        'intercept_': glm.intercept_,\n",
    "                        'coef_': list(glm.coef_),\n",
    "                        'X_names_': X_cols,\n",
    "                        'y_name_': y_col,\n",
    "                    },\n",
    "                    'score': {\n",
    "                        'mse_tr': -glm.neg_mse_score(X_train, y_train),\n",
    "                        'mse_cv': cv_results['full_cv_results'][0]['cv_mse_score'],\n",
    "                        'mse_te': -glm.neg_mse_score(X_holdout, y_holdout),\n",
    "                        \n",
    "                        'r2_tr': glm.r2_score(X_train, y_train),\n",
    "                        'r2_cv': cv_results['full_cv_results'][0]['cv_R2_score'],\n",
    "                        'r2_te': glm.r2_score(X_holdout, y_holdout),\n",
    "                    },\n",
    "                    'fit_details': {\n",
    "                        'time_passed': str(run_end - run_start) + ' s',\n",
    "                        'train_event_counts': event_counts_train,\n",
    "                        'holdout_event_counts': event_counts_holdout,\n",
    "                    },\n",
    "                }\n",
    "                dump_dict_to_json(fitted_glm, run_path / 'fitted_glm.json')\n",
    "                \n",
    "                assert len(cv_results['full_cv_results']) == 1\n",
    "                assert holdout_neg_mse_score == glm.neg_mse_score(X_holdout, y_holdout)\n",
    "                \n",
    "                dfrel_basis['pred_'+y_col] = pd.Series(glm.predict(dfrel_basis_has_all_cols[X_cols]), index=dfrel_basis_has_all_cols.index)\n",
    "                nonnan_X = (dfrel_basis[X_cols].isna().sum(axis=1) == 0)\n",
    "                dfrel_basis['predALL_'+y_col] = pd.Series(glm.predict(dfrel_basis[X_cols][nonnan_X]), index=dfrel_basis.index[nonnan_X])\n",
    "                dfrel_basis[dfresids_cols + ['holdout', y_col, 'pred_'+y_col, 'predALL_'+y_col]].to_csv(str((run_path / 'preds.csv').resolve()))\n",
    "                \n",
    "                print('======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639abeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d5765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "for iXyp, _ in enumerate(X_y_pairings_lst):\n",
    "    for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "        for igkwargs, glm_kwargs in enumerate(glm_kwarg_lst):\n",
    "            agg_coefs_lst = []\n",
    "            for irun in range(num_runs):\n",
    "                run_start = time.time()\n",
    "                \n",
    "                Xyp_path = param_set_output_path / Path(f'iXyp_{iXyp}')\n",
    "                run_path = Xyp_path / Path(f'iXyd_{iXyd}-ikwargs_{igkwargs}') / Path(f'irun_{irun}')\n",
    "                fitted_glm = read_json(run_path / 'fitted_glm.json')\n",
    "                \n",
    "                coefs = pd.DataFrame(list(zip(fitted_glm['model']['X_names_'], fitted_glm['model']['coef_'])), columns=['name', 'coef'])\n",
    "                coefs['name_lst'] = coefs['name'].str.split('_sft_')\n",
    "                coefs['col'] = coefs['name_lst'].apply(lambda x: x[0])\n",
    "                coefs['sft'] = coefs['name_lst'].apply(lambda x: x[1]).astype('int')\n",
    "                \n",
    "                agg_coefs_lst.append(coefs)\n",
    "            \n",
    "            agg_coefs = pd.concat(agg_coefs_lst)\n",
    "\n",
    "            gb_coefs = agg_coefs.groupby(['col', 'sft'])['coef'].agg([np.mean, np.std, np.size])\n",
    "            gb_coefs['lb'] = gb_coefs['mean'] - gb_coefs['std']/np.sqrt(gb_coefs['size'])*1.96\n",
    "            gb_coefs['ub'] = gb_coefs['mean'] + gb_coefs['std']/np.sqrt(gb_coefs['size'])*1.96\n",
    "\n",
    "            gb_coefs = gb_coefs.reset_index()\n",
    "            fig,axes = plt.subplots(gb_coefs['col'].nunique()//3,3,figsize=(10,10))\n",
    "\n",
    "            min_y = gb_coefs['lb'].min()-0.01\n",
    "            max_y = gb_coefs['ub'].max()+0.01\n",
    "            i = 0\n",
    "            for gc, gc_df in gb_coefs.groupby('col'):\n",
    "                axes[i//3,i%3].set_title(gc.replace('Index','').replace('photometry','').replace('enter','').replace('ut','_').replace('ide','').replace('In','I'))\n",
    "                axes[i//3,i%3].plot(gc_df['sft'], gc_df['mean'])\n",
    "                axes[i//3,i%3].fill_between(gc_df['sft'], gc_df['lb'], gc_df['ub'], alpha=0.2)\n",
    "                axes[i//3,i%3].grid(True)\n",
    "                i += 1\n",
    "\n",
    "            i = 0\n",
    "            for gc, gc_df in gb_coefs.groupby('col'):\n",
    "                axes[i//3,i%3].set_ylim((min_y, max_y))\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f88a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887b41a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "for iXyp, _ in enumerate(X_y_pairings_lst):\n",
    "    for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "        for igkwargs, glm_kwargs in enumerate(glm_kwarg_lst):\n",
    "            irun = 0\n",
    "            \n",
    "            run_start = time.time()\n",
    "            Xyp_path = param_set_output_path / Path(f'iXyp_{iXyp}')\n",
    "            run_path = Xyp_path / Path(f'iXyd_{iXyd}-ikwargs_{igkwargs}') / Path(f'irun_{irun}')\n",
    "            preds_df = pd.read_csv(run_path / 'preds.csv')\n",
    "            preds_df = preds_df[preds_df['has_all_cols']]\n",
    "            \n",
    "            assert preds_df['holdout'].isna().sum() == 0\n",
    "            preds_df['holdout'] = preds_df['holdout'].astype(bool)\n",
    "\n",
    "            y_col = X_y_dct['y_col']\n",
    "            preds_df['resids'] = preds_df[y_col] - preds_df['pred_'+y_col]\n",
    "            preds_df['residsALL'] = preds_df[y_col] - preds_df['predALL_'+y_col]\n",
    "            \n",
    "            preds_df_train = preds_df[(~preds_df['holdout'])&preds_df[['wi_trial_keep']]]\n",
    "            preds_df_holdout = preds_df[(preds_df['holdout'])&preds_df[['wi_trial_keep']]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38040b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.columns[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2835d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f49036",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list(smf.timeshift_vals_by_dict(dfrel_basis, widest_orders, keep_nans=True, groupby_cols=['file_num'], shift_spacer='_sft_')[0].columns)\n",
    "# list(dfrel_basis.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216ef4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = list(df_train.columns)\n",
    "basis = list(set(setup))\n",
    "dupe = setup\n",
    "for b in basis:\n",
    "    cnt = dupe.count(b)\n",
    "    if cnt > 1:\n",
    "        print(b, cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3dc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ad27d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "specific_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a700799",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['photometryCenterInIndex_sft_-20', 'photometryCenterInIndex_sft_-19', 'photometryCenterInIndex_sft_-18', 'photometryCenterInIndex_sft_-17', 'photometryCenterInIndex_sft_-16', 'photometryCenterInIndex_sft_-15', 'photometryCenterInIndex_sft_-14', 'photometryCenterInIndex_sft_-13', 'photometryCenterInIndex_sft_-12', 'photometryCenterInIndex_sft_-11', 'photometryCenterInIndex_sft_-10', 'photometryCenterInIndex_sft_-9', 'photometryCenterInIndex_sft_-8', 'photometryCenterInIndex_sft_-7', 'photometryCenterInIndex_sft_-6', 'photometryCenterInIndex_sft_-5', 'photometryCenterInIndex_sft_-4', 'photometryCenterInIndex_sft_-3', 'photometryCenterInIndex_sft_-2', 'photometryCenterInIndex_sft_-1', 'photometryCenterInIndex_sft_0', 'photometryCenterInIndex_sft_1', 'photometryCenterInIndex_sft_2', 'photometryCenterInIndex_sft_3', 'photometryCenterInIndex_sft_4', 'photometryCenterInIndex_sft_5', 'photometryCenterInIndex_sft_6', 'photometryCenterInIndex_sft_7', 'photometryCenterInIndex_sft_8', 'photometryCenterInIndex_sft_9', 'photometryCenterInIndex_sft_10', 'photometryCenterInIndex_sft_11', 'photometryCenterInIndex_sft_12', 'photometryCenterInIndex_sft_13', 'photometryCenterInIndex_sft_14', 'photometryCenterInIndex_sft_15', 'photometryCenterInIndex_sft_16', 'photometryCenterInIndex_sft_17', 'photometryCenterInIndex_sft_18', 'photometryCenterInIndex_sft_19', 'photometryCenterInIndex_sft_20', 'photometrySideInIndex_sft_-20', 'photometrySideInIndex_sft_-19', 'photometrySideInIndex_sft_-18', 'photometrySideInIndex_sft_-17', 'photometrySideInIndex_sft_-16', 'photometrySideInIndex_sft_-15', 'photometrySideInIndex_sft_-14', 'photometrySideInIndex_sft_-13', 'photometrySideInIndex_sft_-12', 'photometrySideInIndex_sft_-11', 'photometrySideInIndex_sft_-10', 'photometrySideInIndex_sft_-9', 'photometrySideInIndex_sft_-8', 'photometrySideInIndex_sft_-7', 'photometrySideInIndex_sft_-6', 'photometrySideInIndex_sft_-5', 'photometrySideInIndex_sft_-4', 'photometrySideInIndex_sft_-3', 'photometrySideInIndex_sft_-2', 'photometrySideInIndex_sft_-1', 'photometrySideInIndex_sft_0', 'photometrySideInIndex_sft_1', 'photometrySideInIndex_sft_2', 'photometrySideInIndex_sft_3', 'photometrySideInIndex_sft_4', 'photometrySideInIndex_sft_5', 'photometrySideInIndex_sft_6', 'photometrySideInIndex_sft_7', 'photometrySideInIndex_sft_8', 'photometrySideInIndex_sft_9', 'photometrySideInIndex_sft_10', 'photometrySideInIndex_sft_11', 'photometrySideInIndex_sft_12', 'photometrySideInIndex_sft_13', 'photometrySideInIndex_sft_14', 'photometrySideInIndex_sft_15', 'photometrySideInIndex_sft_16', 'photometrySideInIndex_sft_17', 'photometrySideInIndex_sft_18', 'photometrySideInIndex_sft_19', 'photometrySideInIndex_sft_20', 'photometrySideInIndexr_sft_-20', 'photometrySideInIndexr_sft_-19', 'photometrySideInIndexr_sft_-18', 'photometrySideInIndexr_sft_-17', 'photometrySideInIndexr_sft_-16', 'photometrySideInIndexr_sft_-15', 'photometrySideInIndexr_sft_-14', 'photometrySideInIndexr_sft_-13', 'photometrySideInIndexr_sft_-12', 'photometrySideInIndexr_sft_-11', 'photometrySideInIndexr_sft_-10', 'photometrySideInIndexr_sft_-9', 'photometrySideInIndexr_sft_-8', 'photometrySideInIndexr_sft_-7', 'photometrySideInIndexr_sft_-6', 'photometrySideInIndexr_sft_-5', 'photometrySideInIndexr_sft_-4', 'photometrySideInIndexr_sft_-3', 'photometrySideInIndexr_sft_-2', 'photometrySideInIndexr_sft_-1', 'photometrySideInIndexr_sft_0', 'photometrySideInIndexr_sft_1', 'photometrySideInIndexr_sft_2', 'photometrySideInIndexr_sft_3', 'photometrySideInIndexr_sft_4', 'photometrySideInIndexr_sft_5', 'photometrySideInIndexr_sft_6', 'photometrySideInIndexr_sft_7', 'photometrySideInIndexr_sft_8', 'photometrySideInIndexr_sft_9', 'photometrySideInIndexr_sft_10', 'photometrySideInIndexr_sft_11', 'photometrySideInIndexr_sft_12', 'photometrySideInIndexr_sft_13', 'photometrySideInIndexr_sft_14', 'photometrySideInIndexr_sft_15', 'photometrySideInIndexr_sft_16', 'photometrySideInIndexr_sft_17', 'photometrySideInIndexr_sft_18', 'photometrySideInIndexr_sft_19', 'photometrySideInIndexr_sft_20', 'photometrySideOutIndex_sft_-20', 'photometrySideOutIndex_sft_-19', 'photometrySideOutIndex_sft_-18', 'photometrySideOutIndex_sft_-17', 'photometrySideOutIndex_sft_-16', 'photometrySideOutIndex_sft_-15', 'photometrySideOutIndex_sft_-14', 'photometrySideOutIndex_sft_-13', 'photometrySideOutIndex_sft_-12', 'photometrySideOutIndex_sft_-11', 'photometrySideOutIndex_sft_-10', 'photometrySideOutIndex_sft_-9', 'photometrySideOutIndex_sft_-8', 'photometrySideOutIndex_sft_-7', 'photometrySideOutIndex_sft_-6', 'photometrySideOutIndex_sft_-5', 'photometrySideOutIndex_sft_-4', 'photometrySideOutIndex_sft_-3', 'photometrySideOutIndex_sft_-2', 'photometrySideOutIndex_sft_-1', 'photometrySideOutIndex_sft_0', 'photometrySideOutIndex_sft_1', 'photometrySideOutIndex_sft_2', 'photometrySideOutIndex_sft_3', 'photometrySideOutIndex_sft_4', 'photometrySideOutIndex_sft_5', 'photometrySideOutIndex_sft_6', 'photometrySideOutIndex_sft_7', 'photometrySideOutIndex_sft_8', 'photometrySideOutIndex_sft_9', 'photometrySideOutIndex_sft_10', 'photometrySideOutIndex_sft_11', 'photometrySideOutIndex_sft_12', 'photometrySideOutIndex_sft_13', 'photometrySideOutIndex_sft_14', 'photometrySideOutIndex_sft_15', 'photometrySideOutIndex_sft_16', 'photometrySideOutIndex_sft_17', 'photometrySideOutIndex_sft_18', 'photometrySideOutIndex_sft_19', 'photometrySideOutIndex_sft_20', 'sl_sft_-20', 'sl_sft_-19', 'sl_sft_-18', 'sl_sft_-17', 'sl_sft_-16', 'sl_sft_-15', 'sl_sft_-14', 'sl_sft_-13', 'sl_sft_-12', 'sl_sft_-11', 'sl_sft_-10', 'sl_sft_-9', 'sl_sft_-8', 'sl_sft_-7', 'sl_sft_-6', 'sl_sft_-5', 'sl_sft_-4', 'sl_sft_-3', 'sl_sft_-2', 'sl_sft_-1', 'sl_sft_0', 'sl_sft_1', 'sl_sft_2', 'sl_sft_3', 'sl_sft_4', 'sl_sft_5', 'sl_sft_6', 'sl_sft_7', 'sl_sft_8', 'sl_sft_9', 'sl_sft_10', 'sl_sft_11', 'sl_sft_12', 'sl_sft_13', 'sl_sft_14', 'sl_sft_15', 'sl_sft_16', 'sl_sft_17', 'sl_sft_18', 'sl_sft_19', 'sl_sft_20', 'spnnrOff_sft_-20', 'spnnrOff_sft_-19', 'spnnrOff_sft_-18', 'spnnrOff_sft_-17', 'spnnrOff_sft_-16', 'spnnrOff_sft_-15', 'spnnrOff_sft_-14', 'spnnrOff_sft_-13', 'spnnrOff_sft_-12', 'spnnrOff_sft_-11', 'spnnrOff_sft_-10', 'spnnrOff_sft_-9', 'spnnrOff_sft_-8', 'spnnrOff_sft_-7', 'spnnrOff_sft_-6', 'spnnrOff_sft_-5', 'spnnrOff_sft_-4', 'spnnrOff_sft_-3', 'spnnrOff_sft_-2', 'spnnrOff_sft_-1', 'spnnrOff_sft_0', 'spnnrOff_sft_1', 'spnnrOff_sft_2', 'spnnrOff_sft_3', 'spnnrOff_sft_4', 'spnnrOff_sft_5', 'spnnrOff_sft_6', 'spnnrOff_sft_7', 'spnnrOff_sft_8', 'spnnrOff_sft_9', 'spnnrOff_sft_10', 'spnnrOff_sft_11', 'spnnrOff_sft_12', 'spnnrOff_sft_13', 'spnnrOff_sft_14', 'spnnrOff_sft_15', 'spnnrOff_sft_16', 'spnnrOff_sft_17', 'spnnrOff_sft_18', 'spnnrOff_sft_19', 'spnnrOff_sft_20']\n",
    "b = ['photometryCenterInIndex_sft_-20', 'photometryCenterInIndex_sft_-19', 'photometryCenterInIndex_sft_-18', 'photometryCenterInIndex_sft_-17', 'photometryCenterInIndex_sft_-16', 'photometryCenterInIndex_sft_-15', 'photometryCenterInIndex_sft_-14', 'photometryCenterInIndex_sft_-13', 'photometryCenterInIndex_sft_-12', 'photometryCenterInIndex_sft_-11', 'photometryCenterInIndex_sft_-10', 'photometryCenterInIndex_sft_-9', 'photometryCenterInIndex_sft_-8', 'photometryCenterInIndex_sft_-7', 'photometryCenterInIndex_sft_-6', 'photometryCenterInIndex_sft_-5', 'photometryCenterInIndex_sft_-4', 'photometryCenterInIndex_sft_-3', 'photometryCenterInIndex_sft_-2', 'photometryCenterInIndex_sft_-1', 'photometryCenterInIndex_sft_0', 'photometryCenterInIndex_sft_1', 'photometryCenterInIndex_sft_2', 'photometryCenterInIndex_sft_3', 'photometryCenterInIndex_sft_4', 'photometryCenterInIndex_sft_5', 'photometryCenterInIndex_sft_6', 'photometryCenterInIndex_sft_7', 'photometryCenterInIndex_sft_8', 'photometryCenterInIndex_sft_9', 'photometryCenterInIndex_sft_10', 'photometryCenterInIndex_sft_11', 'photometryCenterInIndex_sft_12', 'photometryCenterInIndex_sft_13', 'photometryCenterInIndex_sft_14', 'photometryCenterInIndex_sft_15', 'photometryCenterInIndex_sft_16', 'photometryCenterInIndex_sft_17', 'photometryCenterInIndex_sft_18', 'photometryCenterInIndex_sft_19', 'photometryCenterInIndex_sft_20', 'photometrySideInIndex_sft_-20', 'photometrySideInIndex_sft_-19', 'photometrySideInIndex_sft_-18', 'photometrySideInIndex_sft_-17', 'photometrySideInIndex_sft_-16', 'photometrySideInIndex_sft_-15', 'photometrySideInIndex_sft_-14', 'photometrySideInIndex_sft_-13', 'photometrySideInIndex_sft_-12', 'photometrySideInIndex_sft_-11', 'photometrySideInIndex_sft_-10', 'photometrySideInIndex_sft_-9', 'photometrySideInIndex_sft_-8', 'photometrySideInIndex_sft_-7', 'photometrySideInIndex_sft_-6', 'photometrySideInIndex_sft_-5', 'photometrySideInIndex_sft_-4', 'photometrySideInIndex_sft_-3', 'photometrySideInIndex_sft_-2', 'photometrySideInIndex_sft_-1', 'photometrySideInIndex_sft_0', 'photometrySideInIndex_sft_1', 'photometrySideInIndex_sft_2', 'photometrySideInIndex_sft_3', 'photometrySideInIndex_sft_4', 'photometrySideInIndex_sft_5', 'photometrySideInIndex_sft_6', 'photometrySideInIndex_sft_7', 'photometrySideInIndex_sft_8', 'photometrySideInIndex_sft_9', 'photometrySideInIndex_sft_10', 'photometrySideInIndex_sft_11', 'photometrySideInIndex_sft_12', 'photometrySideInIndex_sft_13', 'photometrySideInIndex_sft_14', 'photometrySideInIndex_sft_15', 'photometrySideInIndex_sft_16', 'photometrySideInIndex_sft_17', 'photometrySideInIndex_sft_18', 'photometrySideInIndex_sft_19', 'photometrySideInIndex_sft_20', 'photometrySideInIndexr_sft_-20', 'photometrySideInIndexr_sft_-19', 'photometrySideInIndexr_sft_-18', 'photometrySideInIndexr_sft_-17', 'photometrySideInIndexr_sft_-16', 'photometrySideInIndexr_sft_-15', 'photometrySideInIndexr_sft_-14', 'photometrySideInIndexr_sft_-13', 'photometrySideInIndexr_sft_-12', 'photometrySideInIndexr_sft_-11', 'photometrySideInIndexr_sft_-10', 'photometrySideInIndexr_sft_-9', 'photometrySideInIndexr_sft_-8', 'photometrySideInIndexr_sft_-7', 'photometrySideInIndexr_sft_-6', 'photometrySideInIndexr_sft_-5', 'photometrySideInIndexr_sft_-4', 'photometrySideInIndexr_sft_-3', 'photometrySideInIndexr_sft_-2', 'photometrySideInIndexr_sft_-1', 'photometrySideInIndexr_sft_0', 'photometrySideInIndexr_sft_1', 'photometrySideInIndexr_sft_2', 'photometrySideInIndexr_sft_3', 'photometrySideInIndexr_sft_4', 'photometrySideInIndexr_sft_5', 'photometrySideInIndexr_sft_6', 'photometrySideInIndexr_sft_7', 'photometrySideInIndexr_sft_8', 'photometrySideInIndexr_sft_9', 'photometrySideInIndexr_sft_10', 'photometrySideInIndexr_sft_11', 'photometrySideInIndexr_sft_12', 'photometrySideInIndexr_sft_13', 'photometrySideInIndexr_sft_14', 'photometrySideInIndexr_sft_15', 'photometrySideInIndexr_sft_16', 'photometrySideInIndexr_sft_17', 'photometrySideInIndexr_sft_18', 'photometrySideInIndexr_sft_19', 'photometrySideInIndexr_sft_20', 'photometrySideOutIndex_sft_-20', 'photometrySideOutIndex_sft_-19', 'photometrySideOutIndex_sft_-18', 'photometrySideOutIndex_sft_-17', 'photometrySideOutIndex_sft_-16', 'photometrySideOutIndex_sft_-15', 'photometrySideOutIndex_sft_-14', 'photometrySideOutIndex_sft_-13', 'photometrySideOutIndex_sft_-12', 'photometrySideOutIndex_sft_-11', 'photometrySideOutIndex_sft_-10', 'photometrySideOutIndex_sft_-9', 'photometrySideOutIndex_sft_-8', 'photometrySideOutIndex_sft_-7', 'photometrySideOutIndex_sft_-6', 'photometrySideOutIndex_sft_-5', 'photometrySideOutIndex_sft_-4', 'photometrySideOutIndex_sft_-3', 'photometrySideOutIndex_sft_-2', 'photometrySideOutIndex_sft_-1', 'photometrySideOutIndex_sft_0', 'photometrySideOutIndex_sft_1', 'photometrySideOutIndex_sft_2', 'photometrySideOutIndex_sft_3', 'photometrySideOutIndex_sft_4', 'photometrySideOutIndex_sft_5', 'photometrySideOutIndex_sft_6', 'photometrySideOutIndex_sft_7', 'photometrySideOutIndex_sft_8', 'photometrySideOutIndex_sft_9', 'photometrySideOutIndex_sft_10', 'photometrySideOutIndex_sft_11', 'photometrySideOutIndex_sft_12', 'photometrySideOutIndex_sft_13', 'photometrySideOutIndex_sft_14', 'photometrySideOutIndex_sft_15', 'photometrySideOutIndex_sft_16', 'photometrySideOutIndex_sft_17', 'photometrySideOutIndex_sft_18', 'photometrySideOutIndex_sft_19', 'photometrySideOutIndex_sft_20', 'sl_sft_-20', 'sl_sft_-19', 'sl_sft_-18', 'sl_sft_-17', 'sl_sft_-16', 'sl_sft_-15', 'sl_sft_-14', 'sl_sft_-13', 'sl_sft_-12', 'sl_sft_-11', 'sl_sft_-10', 'sl_sft_-9', 'sl_sft_-8', 'sl_sft_-7', 'sl_sft_-6', 'sl_sft_-5', 'sl_sft_-4', 'sl_sft_-3', 'sl_sft_-2', 'sl_sft_-1', 'sl_sft_0', 'sl_sft_1', 'sl_sft_2', 'sl_sft_3', 'sl_sft_4', 'sl_sft_5', 'sl_sft_6', 'sl_sft_7', 'sl_sft_8', 'sl_sft_9', 'sl_sft_10', 'sl_sft_11', 'sl_sft_12', 'sl_sft_13', 'sl_sft_14', 'sl_sft_15', 'sl_sft_16', 'sl_sft_17', 'sl_sft_18', 'sl_sft_19', 'sl_sft_20', 'spnnrOff_sft_-20', 'spnnrOff_sft_-19', 'spnnrOff_sft_-18', 'spnnrOff_sft_-17', 'spnnrOff_sft_-16', 'spnnrOff_sft_-15', 'spnnrOff_sft_-14', 'spnnrOff_sft_-13', 'spnnrOff_sft_-12', 'spnnrOff_sft_-11', 'spnnrOff_sft_-10', 'spnnrOff_sft_-9', 'spnnrOff_sft_-8', 'spnnrOff_sft_-7', 'spnnrOff_sft_-6', 'spnnrOff_sft_-5', 'spnnrOff_sft_-4', 'spnnrOff_sft_-3', 'spnnrOff_sft_-2', 'spnnrOff_sft_-1', 'spnnrOff_sft_0', 'spnnrOff_sft_1', 'spnnrOff_sft_2', 'spnnrOff_sft_3', 'spnnrOff_sft_4', 'spnnrOff_sft_5', 'spnnrOff_sft_6', 'spnnrOff_sft_7', 'spnnrOff_sft_8', 'spnnrOff_sft_9', 'spnnrOff_sft_10', 'spnnrOff_sft_11', 'spnnrOff_sft_12', 'spnnrOff_sft_13', 'spnnrOff_sft_14', 'spnnrOff_sft_15', 'spnnrOff_sft_16', 'spnnrOff_sft_17', 'spnnrOff_sft_18', 'spnnrOff_sft_19', 'spnnrOff_sft_20']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fa726",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a), len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506872fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50127166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(dfrel_basis_has_all_cols.shape, holdout_srs.shape, dfrel_basis_has_all_cols.isna().sum(axis=0), holdout_srs.isna().sum(axis=0))\n",
    "\n",
    "# df_train = dfrel_basis_has_all_cols[(~holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "# df_holdout = dfrel_basis_has_all_cols[(holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "# X_train, y_train, X_holdout, y_holdout = df_train[X_cols], df_train[y_col], df_holdout[X_cols], df_holdout[y_col]\n",
    "\n",
    "# print('8:', time.time() - multi_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e43aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# basis_column_indices = read_json(Xyp_path / Path('basis_column_indices.json'))\n",
    "# dfrel_basis_load = pd.read_csv(str((Xyp_path / Path(f'combo_df.csv')).resolve()))\n",
    "# dfrel_basis_load, X_cols_sftd_load = smf.timeshift_vals_by_dict(dfrel_basis, widest_orders, keep_nans=True, groupby_cols=['file_num'], shift_spacer='_sft_')\n",
    "\n",
    "# X_cols_sftd = [_ for _ in basis_column_indices if _ in X_cols_sftd_load]\n",
    "# dfrel_basis = dfrel_basis_load.loc[basis_column_indices['basis_index'], basis_column_indices['basis_cols']]\n",
    "\n",
    "# dfrel_basis['holdout'] = holdout_srs\n",
    "# dfrel_basis_has_all_cols = dfrel_basis[dfrel_basis['has_all_cols']]\n",
    "\n",
    "\n",
    "\n",
    "# df_train = dfrel_basis_has_all_cols[(~holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "# df_holdout = dfrel_basis_has_all_cols[(holdout_srs)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "# X_train, y_train, X_holdout, y_holdout = df_train[X_cols], df_train[y_col], df_holdout[X_cols], df_holdout[y_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb7000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103ef18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf = pd.read_csv(str((run_path / '..' / '..' / 'combo_df.csv' ).resolve()))\n",
    "# preds = pd.read_csv(str((run_path / 'preds.csv').resolve()))\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26907e3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [_ for _ in cdf.columns if _ not in preds.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499cfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50107c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfrel_basis.columns, dfrel_basis_reload.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(dfrel_basis.fillna(-1) == dfrel_basis_reload.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403da5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0775ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
