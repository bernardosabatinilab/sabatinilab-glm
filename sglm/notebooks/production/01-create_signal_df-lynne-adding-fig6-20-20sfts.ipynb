{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sglm.models import sglm\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "\n",
    "import itertools\n",
    "\n",
    "num_sft = (-20, 20)\n",
    "channel_definitions = {}\n",
    "signal_files = []\n",
    "out_files = {}\n",
    "ignore_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_col_lst_all = ['gACH', 'rDA', 'gDA', 'gGLU', 'rGLU',\n",
    "                 'gACH_flx_drd', 'rDA_flx_drd', 'gDA_flx_drd',\n",
    "                 'gACH_flx_cht', 'rDA_flx_cht', 'gDA_flx_cht',\n",
    "                 'gACH_flx_drdcht', 'rDA_flx_drdcht', 'gDA_flx_drdcht',\n",
    "                 'Ch5', 'Ch6', 'GP_1', 'GP_2', 'GP_5', 'GP_6', 'SGP_1', 'SGP_2', 'SGP_5', 'SGP_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from logging.config import _RootLoggerConfiguration\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_folder_if_not_exists(dr):\n",
    "    dr = Path(dr)\n",
    "    constructed_dir = str(Path('/').resolve())\n",
    "    made = False\n",
    "    \n",
    "    # print('constructed_dir', constructed_dir)\n",
    "    for fold in dr.parts:\n",
    "        if len(fold) == 0:\n",
    "            continue\n",
    "        constructed_dir = str((Path(constructed_dir) / fold).resolve())\n",
    "#         print('constructed_dir', constructed_dir)\n",
    "        if os.path.isdir(constructed_dir):\n",
    "            # print(f'Directory already exists:', constructed_dir)\n",
    "            pass\n",
    "        else:\n",
    "            # print(f'Creating directory:', constructed_dir)\n",
    "            os.mkdir(constructed_dir)\n",
    "            made = True\n",
    "    if made:\n",
    "        print(f'Created directory:', constructed_dir)\n",
    "    return\n",
    "\n",
    "# create_folder_if_not_exists((Path.home() / 'Desktop/nada/folder2').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Figure 1: Single side recording\n",
    "# figure = 'Figure_1_2'\n",
    "\n",
    "# # # Load Signal Data\n",
    "\n",
    "# # signal_files = glob.glob(f'../../data/raw-new/GLM_SIGNALS_WT61_*')\n",
    "# # signal_files += glob.glob(f'../../data/raw-new/GLM_SIGNALS_WT63_*')\n",
    "# # signal_files += glob.glob(f'../../data/raw-new/GLM_SIGNALS_WT64_*')\n",
    "\n",
    "# ignore_files += [\n",
    "#                 'WT61_10152021',\n",
    "#                 'WT61_10082021'\n",
    "#                 ]\n",
    "# # for ign in ignore_files:\n",
    "# #     signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "# # table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "# # channel_definitions = {\n",
    "# #         ('WT61',): {'Ch1': 'gACH', 'Ch2': 'rDA'},\n",
    "# #         ('WT64',): {'Ch1': 'gACH', 'Ch2': 'empty'},\n",
    "# #         ('WT63',): {'Ch1': 'gDA', 'Ch2': 'empty'},\n",
    "# #     }\n",
    "\n",
    "# group_1_mice = ['WT63', 'WT64', 'WT65']\n",
    "# # group_1_sess = ['11082021', '11102021', '11122021', '11182021']\n",
    "# group_1_sess = ['11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# group_2_mice = ['WT66', 'WT67', 'WT68', 'WT69']\n",
    "# group_2_sess = ['12132021', '12152021', '12172021', '12192021']\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# group_3_mice = ['WT58', 'WT60', 'WT61']\n",
    "# group_3_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# group_4_mice = ['WT53', 'WT54', 'WT55', 'WT56']\n",
    "# group_4_sess = ['09012021', '09032021', '09062021']\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = ['WT57', 'WT59']\n",
    "# group_5_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = []#['WT62']\n",
    "# group_6_sess = []#['11082021', '11102021', '11122021', '11182021']\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA', 'Ch5': 'gACH'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_4_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH'} for file_combo in group_5_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig_1_signal_files_setup = []#group_1_combo + group_2_combo + group_3_combo + group_4_combo + group_5_combo + group_6_combo\n",
    "\n",
    "# for f in fig_1_signal_files_setup:\n",
    "#     glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "#     if len(glob_file) != 1:\n",
    "#         print('Missing file!!! ', f)\n",
    "#     signal_files += glob_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 3: Dual side recording\n",
    "# figure = 'Figure_3'\n",
    "\n",
    "# # 'WT61', 'WT63', 'WT64', '', 'WT44', 'WT51' # Excluding 'WT43\n",
    "\n",
    "# # ['03162021','03192021','03232021','03262021','07282021','07302021','08012021', '08042021', '08062021', '08102021', '10042021',\n",
    "# # '10082021', '10112021', '10132021', '10182021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "\n",
    "# group_1_mice = ['WT63', 'WT64', 'WT44', 'WT51']\n",
    "# group_1_sess = ['03162021','03192021','03232021','03262021','07282021','07302021','08012021', '08042021', '08062021', '08102021', '10042021',\n",
    "#                 '10082021', '10112021', '10132021', '10182021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# group_2_mice = ['WT61']\n",
    "# group_2_sess = ['03162021','03192021','03232021','03262021','07282021','07302021','08012021', '08042021', '08062021', '08102021', '10042021',\n",
    "#                 '10082021', '10112021', '10132021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# # group_3_mice = ['WT58', 'WT60', 'WT61']\n",
    "# # group_3_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# # group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# # group_4_mice = ['WT53', 'WT54', 'WT55', 'WT56']\n",
    "# # group_4_sess = ['09012021', '09032021', '09062021']\n",
    "# # group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# # group_5_mice = ['WT61']\n",
    "# # group_5_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# # group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = ['WT43']\n",
    "# group_6_sess = []\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# # channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_2_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_3_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_4_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "# fig_3_signal_files_setup = []#group_1_combo + group_2_combo #+ group_3_combo + group_4_combo + group_5_combo + group_6_combo\n",
    "# for f in fig_3_signal_files_setup:\n",
    "#     glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "#     if len(glob_file) != 1:\n",
    "#         print('Missing file!!! ', f)\n",
    "#     signal_files += glob_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 3 dualhem\n",
    "# figure = 'Figure3-dualhem'\n",
    "\n",
    "# group_1_mice = ['WT62', 'WT63', 'WT64', 'WT65']\n",
    "# group_1_sess = ['10042021', '10082021', '10112021', '10132021',\n",
    "#                 '10182021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# group_2_mice = []\n",
    "# group_2_sess = []\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# group_3_mice = []\n",
    "# group_3_sess = []\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# group_4_mice = []\n",
    "# group_4_sess = []\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = []\n",
    "# group_5_sess = []\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = []\n",
    "# group_6_sess = []\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# # channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_4_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "# fig_3dh_signal_files_setup = [] #[group_1_combo, group_2_combo, group_3_combo, group_4_combo, group_5_combo, group_6_combo]\n",
    "# for g_num in range(0, len(fig_3dh_signal_files_setup)):\n",
    "#     fig_3dh_basis = fig_3dh_signal_files_setup[g_num]\n",
    "#     for f in fig_3dh_basis:\n",
    "#         glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "#         if len(glob_file) != 1:\n",
    "#             print('Missing file!!! ', f)\n",
    "#         else:\n",
    "#             signal_files += glob_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 5: Flox Mice\n",
    "# figure = 'Figure_5'\n",
    "\n",
    "# # all_session_nums = [\n",
    "# #                     '03172022', '03212022', '03232022', '03252022', '03292022', '03312022', '04032022', '04052022',\n",
    "# #                     '04072022', '04082022', '04112022', '04132022', '04152022', '04202022', '04222022', '05022022',\n",
    "# #                     '05102022', '05162022', '05182022', '05222022', '05232022', '05242022', '05252022', '05262022',\n",
    "# #                     '05272022', '05292022', '05302022', '05312022',\n",
    "# #                     ]\n",
    "# all_session_nums = [\n",
    "#                     '03172022', '03212022', '03232022', '03252022', '03282022',\n",
    "#                     '03292022', '03302022', '03312022', '04012022', '04032022',\n",
    "#                     '04052022', '04072022', '04082022', '04112022', '04132022',\n",
    "#                     '04152022', '04202022', '04222022', '05022022', '05102022',\n",
    "#                     '05162022', '05182022', '05222022', '05232022', '05242022',\n",
    "#                     '05252022', '05262022', '05272022', '05292022', '05302022',\n",
    "#                     '05312022', '06022022', '06062022', '06082022', '06102022',\n",
    "#                     '06132022', '06152022', '06182022', '07072022', '07082022',\n",
    "#                     '07092022', '07112022', '07122022', '07132022', '07142022',\n",
    "#                     '07152022', '07162022', '07172022', '07182022', '07192022'\n",
    "#                    ]\n",
    "\n",
    "# # Drd2f/f control: S1417, 1419, 1421\n",
    "# # group_1_mice = ['S1417', 'S1419', 'S1421']\n",
    "# group_1_mice = ['S1417', 'S1419', 'S1421', 'S1460', 'S1462', 'S1473', 'S1474']\n",
    "# group_1_sess = all_session_nums\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# # Chat Cre X Drd2f/f: S1416, 1418, 1420, 1422\n",
    "# # group_2_mice = ['S1416', 'S1418', 'S1420', 'S1422']\n",
    "# group_2_mice = ['S1416', 'S1418', 'S1420', 'S1459', 'S1461', 'S1470', 'S1471', 'S1472'] # 'S1422', \n",
    "# group_2_sess = all_session_nums\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# # Chat Cre control: S1355-1358, S1376\n",
    "# # group_3_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376']\n",
    "# group_3_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1376',\n",
    "#                 'S1448', 'S1449', 'S1450', 'S1451']\n",
    "# group_3_sess = all_session_nums\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# # Chat Cre control: S1399-1401\n",
    "# group_4_mice = ['S1399', 'S1400', 'S1401']\n",
    "# group_4_sess = all_session_nums\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# # group_5_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "# #                'S1448', 'S1449', 'S1450', 'S1451'\n",
    "# #                'S1399', 'S1400', 'S1401']\n",
    "# group_5_mice = []\n",
    "# group_5_sess = all_session_nums\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = []\n",
    "# group_6_sess = []\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# # channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_4_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "# out_files = {}\n",
    "\n",
    "# fig_5_signal_files_setup = [group_1_combo, group_2_combo, group_3_combo, group_4_combo, group_5_combo, group_6_combo]\n",
    "# for g_num in range(0, len(fig_5_signal_files_setup)):\n",
    "#     fig_5_basis = fig_5_signal_files_setup[g_num]\n",
    "#     for f in fig_5_basis:\n",
    "#         glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "#         if len(glob_file) != 1:\n",
    "#             print('Missing file!!! ', f)\n",
    "#         else:\n",
    "#             signal_files += glob_file\n",
    "#             out_files[glob_file[0]] = (figure, figure + '/g' + str(g_num+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 5: Flox Mice\n",
    "# figure = 'fig5'\n",
    "\n",
    "# # all_session_nums = [\n",
    "# #                     '03172022', '03212022', '03232022', '03252022', '03292022', '03312022', '04032022', '04052022',\n",
    "# #                     '04072022', '04082022', '04112022', '04132022', '04152022', '04202022', '04222022', '05022022',\n",
    "# #                     '05102022', '05162022', '05182022', '05222022', '05232022', '05242022', '05252022', '05262022',\n",
    "# #                     '05272022', '05292022', '05302022', '05312022',\n",
    "# #                     ]\n",
    "# all_session_nums = [\n",
    "#                     '03172022', '03212022', '03232022', '03252022', '03282022',\n",
    "#                     '03292022', '03302022', '03312022', '04012022', '04032022',\n",
    "#                     '04052022', '04072022', '04082022', '04112022', '04132022',\n",
    "#                     '04152022', '04202022', '04222022', '05022022', '05102022',\n",
    "#                     '05162022', '05182022', '05222022', '05232022', '05242022',\n",
    "#                     '05252022', '05262022', '05272022', '05292022', '05302022',\n",
    "#                     '05312022', '06022022', '06062022', '06082022', '06102022',\n",
    "#                     '06132022', '06152022', '06182022', '07072022', '07082022',\n",
    "#                     '07092022', '07112022', '07122022', '07132022', '07142022',\n",
    "#                     '07152022', '07162022', '07172022', '07182022', '07192022'\n",
    "#                    ]\n",
    "\n",
    "# # Drd2f/f control: S1417, 1419, 1421\n",
    "# # group_1_mice = ['S1417', 'S1419', 'S1421']\n",
    "# group_1_mice = ['S1417', 'S1419', 'S1421', 'S1460', 'S1462', 'S1473', 'S1474']\n",
    "# group_1_sess = all_session_nums\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# # Chat Cre X Drd2f/f: S1416, 1418, 1420, 1422\n",
    "# # group_2_mice = ['S1416', 'S1418', 'S1420', 'S1422']\n",
    "# group_2_mice = ['S1416', 'S1418', 'S1420', 'S1459', 'S1461', 'S1470', 'S1471', 'S1472'] # 'S1422', \n",
    "# group_2_sess = all_session_nums\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# # Chat Cre control: S1355-1358, S1374, S1376\n",
    "# # group_3_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376']\n",
    "# group_3_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "#                 'S1448', 'S1449', 'S1450', 'S1451']\n",
    "# group_3_sess = all_session_nums\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# # Chat Cre control: S1399-1401\n",
    "# group_4_mice = ['S1399', 'S1400', 'S1401']\n",
    "# group_4_sess = all_session_nums\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "#                'S1448', 'S1449', 'S1450', 'S1451'\n",
    "#                'S1399', 'S1400', 'S1401']\n",
    "# group_5_sess = all_session_nums\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = []\n",
    "# group_6_sess = []\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_4_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "# out_files = {}\n",
    "\n",
    "# fig_5_signal_files_setup = [group_1_combo, group_2_combo, group_3_combo, group_4_combo, group_5_combo, group_6_combo]\n",
    "# for g_num in range(0, len(fig_5_signal_files_setup)):\n",
    "#     fig_5_basis = fig_5_signal_files_setup[g_num]\n",
    "#     for f in fig_5_basis:\n",
    "#         glob_file = glob.glob(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*')\n",
    "#         if len(glob_file) != 1:\n",
    "#             print('Missing file!!! ', f)\n",
    "#         else:\n",
    "#             signal_files += glob_file\n",
    "#             out_files[glob_file[0]] = (figure, figure + '/g' + str(g_num+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 4: Tetanus Mice\n",
    "# figure = 'Figure_4'\n",
    "\n",
    "# # all_session_nums = [\n",
    "# #                     '03172022', '03212022', '03232022', '03252022', '03292022', '03312022', '04032022', '04052022',\n",
    "# #                     '04072022', '04082022', '04112022', '04132022', '04152022', '04202022', '04222022', '05022022',\n",
    "# #                     '05102022', '05162022', '05182022', '05222022', '05232022', '05242022', '05252022', '05262022',\n",
    "# #                     '05272022', '05292022', '05302022', '05312022',\n",
    "# #                     ]\n",
    "# all_session_nums = ['08312021', '09022021', '09062021', '09082021', '09102021', '09132021',\n",
    "#                     '09152021', '09172021', '09202021', '10052021', '10072021', '10122021',\n",
    "#                     '10142021', '10192021', '10212021', '10252021', '10272021', '11302021',\n",
    "#                     '12022021', '12032021', '12062021', '12072021', '12082021', '12092021',\n",
    "#                     '12102021', '12132021', '12142021']\n",
    "\n",
    "# # Control\n",
    "# group_1_mice = ['S1233', 'S1234', 'S1260', 'S1246', 'S1248']\n",
    "# group_1_sess = all_session_nums\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# # Tetanus\n",
    "# group_2_mice = ['S1194', 'S1195', 'S1214', 'S1258', 'S1259']\n",
    "# group_2_sess = all_session_nums\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# group_3_mice = []\n",
    "# group_3_sess = all_session_nums\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# group_4_mice = []\n",
    "# group_4_sess = all_session_nums\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = []\n",
    "# group_5_sess = all_session_nums\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = []\n",
    "# group_6_sess = []\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# # channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gDA'} for file_combo in group_2_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA', 'Ch1':'gDA'} for file_combo in group_3_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_4_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# # channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "# fig_4_signal_files_setup = []#[group_1_combo, group_2_combo, group_3_combo, group_4_combo, group_5_combo, group_6_combo]\n",
    "# for g_num in range(0, len(fig_4_signal_files_setup)):\n",
    "#     fig_4_basis = fig_4_signal_files_setup[g_num]\n",
    "#     for f in fig_4_basis:\n",
    "#         glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "#         if len(glob_file) != 1:\n",
    "#             print('Missing file!!! ', f)\n",
    "#         else:\n",
    "#             signal_files += glob_file\n",
    "#             out_files[glob_file[0]] = (figure, figure + '/g' + str(g_num+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file!!!  S1299_01312022\n",
      "Missing file!!!  S1300_01312022\n",
      "Missing file!!!  S1301_02072022\n",
      "Missing file!!!  S1302_02072022\n"
     ]
    }
   ],
   "source": [
    "### Figure 6: Glutamate Mice\n",
    "figure = 'Figure_6'\n",
    "\n",
    "# all_session_nums = [\n",
    "#                     '03172022', '03212022', '03232022', '03252022', '03292022', '03312022', '04032022', '04052022',\n",
    "#                     '04072022', '04082022', '04112022', '04132022', '04152022', '04202022', '04222022', '05022022',\n",
    "#                     '05102022', '05162022', '05182022', '05222022', '05232022', '05242022', '05252022', '05262022',\n",
    "#                     '05272022', '05292022', '05302022', '05312022',\n",
    "#                     ]\n",
    "all_session_nums = [\n",
    "                    '01312022', '02022022', '02072022'\n",
    "                   ]\n",
    "\n",
    "# Glutamate\n",
    "group_1_mice = ['S1299', 'S1300', 'S1301', 'S1302']\n",
    "group_1_sess = all_session_nums\n",
    "group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "group_2_mice = []\n",
    "group_2_sess = all_session_nums\n",
    "group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "group_3_mice = []\n",
    "group_3_sess = all_session_nums\n",
    "group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "group_4_mice = []\n",
    "group_4_sess = all_session_nums\n",
    "group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "group_5_mice = []\n",
    "group_5_sess = all_session_nums\n",
    "group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "group_6_mice = []\n",
    "group_6_sess = []\n",
    "group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# channel_definitions = {}\n",
    "# channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gGLUl', 'Ch1':'gGLUr'} for file_combo in group_1_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gGLUl', 'Ch1':'gGLUr'} for file_combo in group_2_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gGLUl', 'Ch1':'gGLUr'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_4_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "fig_6_signal_files_setup = [group_1_combo, group_2_combo, group_3_combo, group_4_combo, group_5_combo, group_6_combo]\n",
    "for g_num in range(0, len(fig_6_signal_files_setup)):\n",
    "    fig_6_basis = fig_6_signal_files_setup[g_num]\n",
    "    for f in fig_6_basis:\n",
    "        glob_file = glob.glob(str(Path(f'../../data/raw-new/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "        if len(glob_file) != 1:\n",
    "            print('Missing file!!! ', f)\n",
    "        else:\n",
    "            signal_files += glob_file\n",
    "            str_num_sft = '_'.join([str(_) for _ in num_sft])\n",
    "            out_files[glob_file[0]] = (figure, figure + f'/g{g_num+1}-{str_num_sft}sft')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# figure = 'fig3-dualhem'\n",
    "# print(sorted(list(set([_.split('_')[-1].replace('.txt', '') for _ in glob.glob(f'../../data/raw-new/{figure}/GLM_SIGNALS_*') if 'WT6' in _]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure = 'fig5'\n",
    "# print(sorted(list(set([_.split('_')[-1].replace('.txt', '') for _ in glob.glob(f'../../data/raw-new/{figure}/GLM_SIGNALS_*')]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_files = ['/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_SIGNALS_S1449_06022022.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1299_02022022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1299_02072022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1300_02022022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1300_02072022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1301_01312022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1301_02022022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1302_01312022.txt',\n",
       " 'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\data\\\\raw-new\\\\Figure_6\\\\GLM_SIGNALS_S1302_02022022.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('S1299_01312022',)\n",
      "('S1299_02022022',)\n",
      "> GLM_SIGNALS_S1299_02022022.txt\n",
      "('S1299_02072022',)\n",
      "> GLM_SIGNALS_S1299_02072022.txt\n",
      "('S1300_01312022',)\n",
      "('S1300_02022022',)\n",
      "> GLM_SIGNALS_S1300_02022022.txt\n",
      "('S1300_02072022',)\n",
      "> GLM_SIGNALS_S1300_02072022.txt\n",
      "('S1301_01312022',)\n",
      "> GLM_SIGNALS_S1301_01312022.txt\n",
      "('S1301_02022022',)\n",
      "> GLM_SIGNALS_S1301_02022022.txt\n",
      "('S1301_02072022',)\n",
      "('S1302_01312022',)\n",
      "> GLM_SIGNALS_S1302_01312022.txt\n",
      "('S1302_02022022',)\n",
      "> GLM_SIGNALS_S1302_02022022.txt\n",
      "('S1302_02072022',)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4bc204d7fa413291eef273441e329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\interim-new\\Figure_6\\g1--20_20sft\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1299_02022022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1299_02072022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1300_02022022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1300_02072022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1301_01312022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1301_02022022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1302_01312022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\data\\raw-new\\Figure_6\\GLM_SIGNALS_S1302_02022022.txt\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n"
     ]
    }
   ],
   "source": [
    "for ign in ignore_files:\n",
    "    signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "\n",
    "channel_assignments = bf.get_rename_columns_by_file(signal_files, channel_definitions)\n",
    "\n",
    "for file_num in trange(len(signal_files)):\n",
    "\n",
    "    ## Load Table Data\n",
    "    # signal_fn = signal_files[0]\n",
    "    # table_fn = table_files[0]\n",
    "\n",
    "    signal_path = signal_files[file_num]\n",
    "    table_path = table_files[file_num]\n",
    "\n",
    "    signal_fn = Path(signal_files[file_num]).parts[-1]\n",
    "    table_fn = Path(table_files[file_num]).parts[-1]\n",
    "\n",
    "    signal_filename_out = signal_fn.replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_filename_out = table_fn.replace('GLM_TABLE', 'GLM_TABLE_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "    # signal_path_out = f'../../data/interim2/{signal_filename_out}'\n",
    "    # table_path_out = f'../../data/interim2/{table_filename_out}'\n",
    "\n",
    "    signal_path_out = signal_path.replace(r'raw', r'interim').replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_path_out = table_path.replace(r'raw', r'interim').replace('GLM_TABLE', 'GLM_TABLE_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "    \n",
    "    if out_files is not None and signal_path in out_files:\n",
    "        signal_path_out = signal_path_out.replace(*out_files[signal_path])\n",
    "        table_path_out = table_path_out.replace(*out_files[signal_path])\n",
    "\n",
    "    create_folder_if_not_exists(str(Path('/'.join(Path(signal_path_out).parts[:-1])).resolve()))\n",
    "    create_folder_if_not_exists(str(Path('/'.join(Path(table_path_out).parts[:-1])).resolve()))\n",
    "    \n",
    "    signal_df = pd.read_csv(signal_path)\n",
    "    table_df = pd.read_csv(table_path)\n",
    "\n",
    "    # Check for multiple copies of the same sideIn\n",
    "    eq = table_df['photometrySideInIndex'].dropna()\n",
    "    eq = eq[eq != 0]\n",
    "    if len(eq) != eq.nunique():\n",
    "        print(len(eq))\n",
    "        print(eq.nunique())\n",
    "        display(eq)\n",
    "        print(f'Error: Multiple side ins with the same timestamp detected for {signal_path}. Continuing...')\n",
    "        continue\n",
    "\n",
    "    print(signal_path)\n",
    "    signal_df, table_df = gsd.generate_signal_df(signal_path,\n",
    "                                            table_path,\n",
    "                                            # signal_filename_out=f'../../data/interim2/{signal_filename_out}',\n",
    "                                            # table_filename_out=f'../../data/interim2/{table_filename_out}',\n",
    "#                                             trial_bounds_before_center_in = -50,\n",
    "#                                             trial_bounds_after_side_out = 50,\n",
    "                                                 \n",
    "                                            trial_bounds_before_center_in = num_sft[0],\n",
    "                                            trial_bounds_after_side_out = num_sft[1],\n",
    "                                            )\n",
    "\n",
    "    signal_df = signal_df[signal_df['nTrial'] > 0].fillna(0)\n",
    "\n",
    "    # Break down Preprocess Lynne into component parts\n",
    "\n",
    "    # Rename Columns\n",
    "    signal_df = bf.rename_consistent_columns(signal_df)\n",
    "    \n",
    "    # print(channel_assignments.keys())\n",
    "    # print(signal_fn)\n",
    "    if signal_fn in channel_assignments:\n",
    "        signal_df = signal_df.rename(channel_assignments[signal_fn], axis=1)\n",
    "\n",
    "    for y_col in y_col_lst_all:\n",
    "        if y_col not in signal_df.columns:\n",
    "            signal_df[y_col] = np.nan\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    ## Set Full Trial Reward Flags\n",
    "    signal_df['r_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexr'].transform(np.sum) > 0) * 1.0\n",
    "    signal_df['nr_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexnr'].transform(np.sum) > 0) * 1.0\n",
    "\n",
    "    ## Define Side Rewarded / Unrewarded Flags\n",
    "    signal_df = bf.set_port_entry_exit_rewarded_unrewarded_indicators(signal_df)\n",
    "\n",
    "    ## Define Side Agnostic Events\n",
    "    signal_df = bf.define_side_agnostic_events(signal_df)\n",
    "\n",
    "    # print('Percent of Data in ITI:', (df['nTrial'] == df['nEndTrial']).mean())\n",
    "\n",
    "    signal_df['spnrOff'] = ((signal_df['spnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    signal_df['spxrOff'] = ((signal_df['spxr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "    spnnrOff_a = ((signal_df['spnnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    spxnrOff_a = ((signal_df['spxnr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "\n",
    "    # If we have something listed as a rewarded \"off\" side entry labeled in the table as a side exit... it means it was a fast \"out-in\".\n",
    "    # The latter \"in\" should be considered an unrewarded side port \"off\" entry.\n",
    "    dualism_exen = ((signal_df['spnrOff'] == 1)&(signal_df['photometrySideOutIndex'] == 1)).astype(int)\n",
    "\n",
    "    # Unrewarded side port entries should be the combination of those simply identified by checking spnnr & the table labels +\n",
    "    # the dualism defined immediately prior. Then those dualism examples should be remoed from the \"off\" rewarded entries.\n",
    "    signal_df['spnnrOff'] = spnnrOff_a + dualism_exen\n",
    "    signal_df['spnrOff'] = signal_df['spnrOff'] - dualism_exen\n",
    "\n",
    "    signal_df['spxnrOff'] = spxnrOff_a\n",
    "\n",
    "    \n",
    "\n",
    "    signal_df['slOff'] = signal_df['sl'] * signal_df['nr_trial']\n",
    "    signal_df['slOn'] = signal_df['sl'] - signal_df['slOff']\n",
    "\n",
    "\n",
    "    \n",
    "    signal_df['cpnOff'] = ((signal_df['cpn'] == 1)&(signal_df['photometryCenterInIndex'] != 1)).astype(int)\n",
    "    signal_df['cpxOff'] = ((signal_df['cpx'] == 1)&(signal_df['photometryCenterOutIndex'] != 1)).astype(int)\n",
    "    # spnnrOff_a = ((signal_df['cpnOff'] == 1)&(signal_df['photometryCenterInIndex'] != 1)).astype(int)\n",
    "    # spxnrOff_a = ((signal_df['cpxOff'] == 1)&(signal_df['photometryCenterOutIndex'] != 1)).astype(int)\n",
    "\n",
    "    # # If we have something listed as a rewarded \"off\" side entry labeled in the table as a side exit... it means it was a fast \"out-in\".\n",
    "    # # The latter \"in\" should be considered an unrewarded side port \"off\" entry.\n",
    "    # dualism_exen = ((signal_df['cpnOff'] == 1)&(signal_df['photometryCenterOutIndex'] == 1)).astype(int)\n",
    "\n",
    "    # # Unrewarded side port entries should be the combination of those simply identified by checking spnnr & the table labels +\n",
    "    # # the dualism defined immediately prior. Then those dualism examples should be remoed from the \"off\" rewarded entries.\n",
    "    # signal_df['spnnrOff'] = spnnrOff_a + dualism_exen\n",
    "    # signal_df['spnrOff'] = signal_df['spnrOff'] - dualism_exen\n",
    "\n",
    "    # signal_df['spxnrOff'] = spxnrOff_a\n",
    "\n",
    "    if signal_path_out:\n",
    "        signal_df.to_csv(signal_path_out, index_label='index')\n",
    "    if table_path_out:\n",
    "        table_df.to_csv(table_path_out, index_label='index')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gGLUr</th>\n",
       "      <th>Ch2</th>\n",
       "      <th>gGLUl</th>\n",
       "      <th>Ch6</th>\n",
       "      <th>cpo</th>\n",
       "      <th>cpn</th>\n",
       "      <th>cpx</th>\n",
       "      <th>rpo</th>\n",
       "      <th>rpn</th>\n",
       "      <th>rpx</th>\n",
       "      <th>...</th>\n",
       "      <th>spxnr</th>\n",
       "      <th>sl</th>\n",
       "      <th>spnrOff</th>\n",
       "      <th>spxrOff</th>\n",
       "      <th>spnnrOff</th>\n",
       "      <th>spxnrOff</th>\n",
       "      <th>slOff</th>\n",
       "      <th>slOn</th>\n",
       "      <th>cpnOff</th>\n",
       "      <th>cpxOff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gGLUr, Ch2, gGLUl, Ch6, cpo, cpn, cpx, rpo, rpn, rpx, rl, lpo, lpn, lpx, ll, r, nr, photometryCenterInIndex, photometryCenterInIndexr, photometryCenterInIndexnr, photometryCenterOutIndex, photometryCenterOutIndexr, photometryCenterOutIndexnr, photometrySideInIndex, photometrySideInIndexr, photometrySideInIndexnr, photometrySideInIndexAA, photometrySideInIndexAa, photometrySideInIndexaA, photometrySideInIndexaa, photometrySideInIndexAB, photometrySideInIndexAb, photometrySideInIndexaB, photometrySideInIndexab, photometrySideOutIndex, photometrySideOutIndexr, photometrySideOutIndexnr, photometrySideOutIndexAA, photometrySideOutIndexAa, photometrySideOutIndexaA, photometrySideOutIndexaa, photometrySideOutIndexAB, photometrySideOutIndexAb, photometrySideOutIndexaB, photometrySideOutIndexab, photometryFirstLickIndex, photometryFirstLickIndexr, photometryFirstLickIndexnr, nTrial, nEndTrial, diffTrialNums, dupe, wi_trial_keep, gACH, rDA, gDA, gGLU, rGLU, gACH_flx_drd, rDA_flx_drd, gDA_flx_drd, gACH_flx_cht, rDA_flx_cht, gDA_flx_cht, gACH_flx_drdcht, rDA_flx_drdcht, gDA_flx_drdcht, Ch5, GP_1, GP_2, GP_5, GP_6, SGP_1, SGP_2, SGP_5, SGP_6, r_trial, nr_trial, rpxr, rpxnr, lpxr, lpxnr, rpnr, rpnnr, lpnr, lpnnr, spn, spx, spnr, spnnr, spxr, spxnr, sl, spnrOff, spxrOff, spnnrOff, spxnrOff, slOff, slOn, cpnOff, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 101 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal_df[['sl', 'r_trial', 'nr_trial', 'slOff', ]].iloc[1000:2000].plot()\n",
    "signal_df[signal_df['r_trial'] == signal_df['nr_trial']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = signal_df.groupby('nTrial')['slOff'].sum()\n",
    "# a[a > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['spnnr'] = ((df['spnnr'] == 1)&(df['photometrySideInIndex'] != 1)).astype(int)\n",
    "# # df['spxnr'] = ((df['spxnr'] == 1)&(df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "\n",
    "# X_cols = [_ for _ in X_cols_all if _ not in left_out]\n",
    "\n",
    "# if len(leave_one_out_list) > 1:\n",
    "#     run_id = f'{prefix}_{fn}_{y_col}_drop={\"_\".join(left_out)}'\n",
    "# else:\n",
    "#     run_id = f'{prefix}_{fn}_{y_col}'\n",
    "\n",
    "# dfrel = df.copy()\n",
    "\n",
    "# dfrel, X_cols_sftd = lpp.timeshift_vals(dfrel, X_cols, neg_order=neg_order, pos_order=pos_order)\n",
    "\n",
    "# dfrel_setup, dfrel_holdout = holdout_splits(dfrel,\n",
    "#                                             id_cols=['nTrial'],\n",
    "#                                             perc_holdout=pholdout)\n",
    "# dfrel_setup, dfrel_holdout = dfrel_setup.copy(), dfrel_holdout.copy()\n",
    "\n",
    "# kfold_cv_idx = sglm_ez.cv_idx_by_trial_id(dfrel_setup,\n",
    "#                                           trial_id_columns=['nTrial'],\n",
    "#                                           num_folds=folds,\n",
    "#                                           test_size=pgss)\n",
    "\n",
    "# prediction_X_cols = [_ for _ in X_cols if _ not in ['nTrial']]\n",
    "# prediction_X_cols_sftd = [_ for _ in X_cols_sftd if _ not in ['nTrial']]\n",
    "\n",
    "# X_setup = get_x(dfrel_setup, prediction_X_cols_sftd, keep_rows=None)\n",
    "# y_setup = get_y(dfrel_setup, y_col, keep_rows=None)\n",
    "# X_setup_noiti = get_x(dfrel_setup, prediction_X_cols_sftd, keep_rows=dfrel_setup['wi_trial_keep'])\n",
    "# y_setup_noiti = get_y(dfrel_setup, y_col, keep_rows=dfrel_setup['wi_trial_keep'])\n",
    "# best_score, best_score_std, best_params, best_model, cv_results = sglm_ez.simple_cv_fit(X_setup, y_setup, kfold_cv_idx, glm_kwarg_lst, model_type='Normal', verbose=0, score_method=score_method)\n",
    "\n",
    "# sglm_ez.print_best_model_info(X_setup, best_score, best_params, best_model, start)\n",
    "\n",
    "# X_holdout_witi = get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=None)\n",
    "# y_holdout_witi = get_y(dfrel_holdout, y_col, keep_rows=None)\n",
    "# X_holdout_noiti = get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=dfrel_holdout['wi_trial_keep'])\n",
    "# y_holdout_noiti = get_y(dfrel_holdout, y_col, keep_rows=dfrel_holdout['wi_trial_keep'])\n",
    "# glm, holdout_score, holdout_neg_mse_score = sglm_ez.training_fit_holdout_score(X_setup, y_setup, X_holdout_noiti, y_holdout_noiti, best_params)\n",
    "\n",
    "# dfrel['pred'] = glm.predict(dfrel[prediction_X_cols_sftd])\n",
    "# dfrel_setup['pred'] = glm.predict(dfrel_setup[prediction_X_cols_sftd])\n",
    "# dfrel_holdout['pred'] = glm.predict(dfrel_holdout[prediction_X_cols_sftd])\n",
    "\n",
    "# # Collect\n",
    "# results_dict[f'{run_id}'] = {'holdout_score':holdout_score,\n",
    "#                             'holdout_neg_mse_score':holdout_neg_mse_score,\n",
    "#                             'best_score':best_score,\n",
    "#                             'best_params':best_params,\n",
    "#                             'all_models':sorted([(_['cv_R2_score'],\n",
    "#                                                     _['cv_mse_score'],\n",
    "#                                                     sglm_ez.calc_l1(_['cv_coefs']),\n",
    "#                                                     sglm_ez.calc_l2(_['cv_coefs']),\n",
    "#                                                     _['glm_kwargs']) for _ in cv_results['full_cv_results']], key=lambda x: -x[0])\n",
    "#                             }\n",
    "\n",
    "# X_cols_plot = prediction_X_cols\n",
    "# X_cols_sftd_plot = prediction_X_cols_sftd\n",
    "\n",
    "# # print('X_setup.columns', list(X_setup.columns), len(list(X_setup.columns)))\n",
    "# # print('X_setup_noiti.columns', list(X_setup_noiti.columns), len(list(X_setup_noiti.columns)))\n",
    "# # print('X_holdout_witi.columns', list(X_holdout_witi.columns), len(list(X_holdout_witi.columns)))\n",
    "# # print('X_holdout_noiti.columns', list(X_holdout_noiti.columns), len(list(X_holdout_noiti.columns)))\n",
    "\n",
    "\n",
    "# holdout_score_rnd = np.round(holdout_score, 4)\n",
    "# best_beta_fn = f'{best_coeffs_folder}/{run_id}_best_{all_betas_basename}_R2_{holdout_score_rnd}.png'\n",
    "# splt.plot_all_beta_coefs(glm.coef_, X_cols_plot,\n",
    "#                                 X_cols_sftd_plot,\n",
    "#                                 plot_width=4,\n",
    "#                                 # plot_width=2,\n",
    "#                                 y_lims=(-2.5, 2.5),\n",
    "#                                 # filename=f'{fn}_coeffs.png',\n",
    "#                                 binsize=54,\n",
    "#                                 filename=best_beta_fn,\n",
    "#                                 plot_name=f'Best Coeffs - {run_id} — {best_params}'\n",
    "#                                 )\n",
    "\n",
    "# best_beta_fn = f'{best_reconstruct_folder}/{run_id}_best_{avg_reconstruct_basename}_R2_{holdout_score_rnd}.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# splt.plot_avg_reconstructions_v2(dfrel_holdout,\n",
    "# # splt.plot_avg_reconstructions_v2(dfrel,\n",
    "#                             channel=y_col,\n",
    "#                             binsize = 54,\n",
    "#                             plot_width=4,\n",
    "#                             min_time = -20,\n",
    "#                             max_time = 30,\n",
    "#                             min_signal = -3.0,\n",
    "#                             max_signal = 3.0,\n",
    "#                             file_name=best_beta_fn,\n",
    "#                             title=f'Best Average Reconstruction - {run_id} — {best_params}'\n",
    "#                             )\n",
    "\n",
    "# for fitted_model_dict in (cv_results['full_cv_results']):\n",
    "#     fitted_model = fitted_model_dict['model']\n",
    "#     kwarg_info = \"_\".join([f\"{_k}_{fitted_model_dict['glm_kwargs'][_k]}\" for _k in fitted_model_dict[\"glm_kwargs\"]])\n",
    "\n",
    "#     model_coef = fitted_model.coef_\n",
    "#     model_intercept = fitted_model.intercept_\n",
    "\n",
    "#     std_name = f'{run_id}_{kwarg_info}'\n",
    "#     np.save(f'{all_models_folder}/coeffs/{std_name}_{model_c_basename}.npy', model_coef)\n",
    "#     np.save(f'{all_models_folder}/intercepts/{std_name}_{model_i_basename}.npy', model_intercept)\n",
    "    \n",
    "#     tmp_holdout_score = fitted_model.r2_score(X_holdout_noiti, y_holdout_noiti)\n",
    "\n",
    "#     glmsave.append_fit_results(y_col, fitted_model_dict[\"glm_kwargs\"], glm_model=fitted_model, dropped_cols=left_out,\n",
    "#                             scores={\n",
    "#                                 'tr_witi':fitted_model.r2_score(X_setup, y_setup),\n",
    "#                                 'tr_noiti':fitted_model.r2_score(X_setup_noiti, y_setup_noiti),\n",
    "#                                 'gss_witi':fitted_model_dict['cv_R2_score'],\n",
    "#                                 'gss_noiti':None,\n",
    "#                                 'holdout_witi':fitted_model.r2_score(X_holdout_witi, y_holdout_witi),\n",
    "#                                 'holdout_noiti':fitted_model.r2_score(X_holdout_noiti, y_holdout_noiti)\n",
    "#                             },\n",
    "#                             gssids=kfold_cv_idx)\n",
    "\n",
    "#     tmp = dfrel_holdout.set_index('nTrial').copy()\n",
    "#     tmp['pred'] = fitted_model.predict(get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=None))\n",
    "#     tmp = lpp.get_first_entry_time(tmp)\n",
    "#     tmp_y = get_y(dfrel_holdout, y_col, keep_rows=None).copy()\n",
    "#     tmp_y.index = tmp.index\n",
    "#     tmp[y_holdout_noiti.name] = tmp_y\n",
    "\n",
    "#     tmp.to_csv(f'{all_data_folder}/{std_name}_{tmp_data_basename}.csv')\n",
    "\n",
    "#     holdout_score_rnd = np.round(tmp_holdout_score, 4)\n",
    "\n",
    "\n",
    "#     splt.plot_all_beta_coefs(fitted_model.coef_, X_cols_plot,\n",
    "#                                     X_cols_sftd_plot,\n",
    "#                                     plot_width=4,\n",
    "#                                     y_lims=(-3.0, 3.0),\n",
    "#                                     # filename=f'{fn}_coeffs.png',\n",
    "#                                     binsize=54,\n",
    "#                                     filename=f'{all_coeffs_folder}/{std_name}_{all_betas_basename}_R2_{holdout_score_rnd}.png',\n",
    "#                                     plot_name=f'Coeffs by Timeshift - {run_id} — {kwarg_info}'\n",
    "#                                     # plot_name=f'{fn} — {y_col} — {kwarg_info}'\n",
    "#                                     )\n",
    "    \n",
    "#     plt.close('all')\n",
    "# plt.close('all')\n",
    "\n",
    "\n",
    "# glmsave.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = df[['nTrial', 'r_trial', 'nr_trial', 'photometrySideInIndexr', 'photometrySideInIndexnr', 'photometryCenterInIndex']]\n",
    "# t.loc[2295:2345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(list(set([_.split('_')[-1].split('.')[0] for _ in glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig3/*')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_fn = signal_files[file_num].split('/')[-1]\n",
    "table_fn = table_files[file_num].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "g1 = sorted(glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim2/*/*.csv'))\n",
    "g1 = [_ for _ in g1 if '-bu/' not in _]\n",
    "g2 = sorted(glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim2/*/*/*.csv'))\n",
    "g2 = [_ for _ in g2 if '-bu/' not in _]\n",
    "for tf in g1:\n",
    "    tmptf = '/'.join(tf.split('/')[-2:]).replace('.csv', '')\n",
    "    tmptf = '/'.join(tmptf.split('/')[-2:]).replace('GLM_TABLE_', '')\n",
    "    tmptf = '/'.join(tmptf.split('/')[-2:]).replace('GLM_SIGNALS_', '')\n",
    "    tmptf = tmptf.replace('INTERIM_','')\n",
    "    print(tmptf)\n",
    "\n",
    "for tf in g2:\n",
    "    tmptf = '/'.join(tf.split('/')[-3:]).replace('.csv', '')\n",
    "    tmptf = '/'.join(tmptf.split('/')[-3:]).replace('GLM_TABLE_', '')\n",
    "    tmptf = '/'.join(tmptf.split('/')[-3:]).replace('GLM_SIGNALS_', '')\n",
    "    tmptf = tmptf.replace('INTERIM_','')\n",
    "    print(tmptf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "app = []\n",
    "for tf in sorted(glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig4/*.txt')):\n",
    "    app.append(tf.split('/')[-1].replace('.txt', '').split('_')[-1])\n",
    "\n",
    "print(sorted(list(set(app))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_SIGNALS_S1449_06022022.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_SIGNALS_S1449_06022022.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tmp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_SIGNALS_S1449_06022022.txt'"
     ]
    }
   ],
   "source": [
    "tmp = pd.read_csv('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_SIGNALS_S1449_06022022.txt')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw-new/fig5/GLM_TABLE_S1449_06022022.txt').drop('word',axis=1).astype(float)\n",
    "# tmp[(tmp == 19821).sum(axis=1) >= 1]\n",
    "tmp[(tmp[['photometrySideInIndex']] <= 20000).sum(axis=1) >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
