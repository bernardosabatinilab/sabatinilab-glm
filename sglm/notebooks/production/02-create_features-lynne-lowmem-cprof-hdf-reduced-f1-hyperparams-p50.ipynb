{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sglm.models import sglm_cv\n",
    "import itertools\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import setup_model_fit as smf\n",
    "from sglm.models import sglm_cv\n",
    "from sglm import models\n",
    "from sglm.visualization import visualize\n",
    "from sglm.models import train_model\n",
    "from sglm.models import eval\n",
    "from sglm import features\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dfrel_to_ho_set():\n",
    "#     return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from logging.config import _RootLoggerConfiguration\n",
    "\n",
    "def create_folder_if_not_exists(dr):\n",
    "    dr = Path(dr)\n",
    "    constructed_dir = str(Path('/').resolve())\n",
    "    made = False\n",
    "    \n",
    "#     print('constructed_dir', constructed_dir)\n",
    "    for fold in dr.parts:\n",
    "        if len(fold) == 0:\n",
    "            continue\n",
    "        constructed_dir = str((Path(constructed_dir) / fold).resolve())\n",
    "#         print('constructed_dir', constructed_dir)\n",
    "        if os.path.isdir(constructed_dir):\n",
    "            # print(f'Directory already exists:', constructed_dir)\n",
    "            pass\n",
    "        else:\n",
    "            # print(f'Creating directory:', constructed_dir)\n",
    "            os.mkdir(constructed_dir)\n",
    "            made = True\n",
    "    if made:\n",
    "        print(f'Created directory:', constructed_dir)\n",
    "    return\n",
    "\n",
    "# create_folder_if_not_exists((Path.home() / 'Desktop/nada/folder2').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_folders(base_folder, prefix, *args):\n",
    "    for folder in args:\n",
    "        create_folder_if_not_exists(str(Path(base_folder/prefix/folder).resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# From stack overflow\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit)\n",
    "\n",
    "def extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit):\n",
    "    # needed info\n",
    "    # Params: wt_used, signal_files, widest_orders, multifile_fit\n",
    "    # Returns: mouse_names, combo_dfs, combo_fns, X_cols_sftd\n",
    "    \n",
    "    if multifile_fit == 'all':\n",
    "        file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "        print('file_ids', file_ids)\n",
    "        combo_dfs, X_cols_sftd, _ = smf.multi_file_analysis_prep(signal_files, widest_orders, file_ids)\n",
    "        combo_fns = ['_'.join(wt_used).replace('WT', '').replace('S', '')]\n",
    "        mouse_names = combo_fns\n",
    "    elif multifile_fit == 'by_mouse':\n",
    "        combo_dfs = []\n",
    "        X_cols_sftd_lst = []\n",
    "        combo_fns = []\n",
    "        mouse_names_2 = []\n",
    "        for mouse_id in wt_used:\n",
    "            mouse_id_files = [_ for _ in signal_files if mouse_id in _]\n",
    "            file_ids = [Path(_).parts[-1] for _ in mouse_id_files]\n",
    "            mouse_names_2 += [mouse_id]\n",
    "            combo_dfs_tmp, X_cols_sftd_tmp, _ = smf.multi_file_analysis_prep(mouse_id_files, widest_orders, file_ids)\n",
    "            combo_dfs += combo_dfs_tmp\n",
    "            X_cols_sftd_lst.append(X_cols_sftd_tmp)\n",
    "            combo_fns.append(mouse_id)\n",
    "\n",
    "        for xcsl in X_cols_sftd_lst:\n",
    "            if xcsl != X_cols_sftd_lst[0]:\n",
    "                raise ValueError('X_cols_sftd_lst should contain the same elements for every entry')\n",
    "        mouse_names = mouse_names_2\n",
    "\n",
    "        X_cols_sftd = X_cols_sftd_lst[0]\n",
    "\n",
    "    elif multifile_fit == 'single':\n",
    "        file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "        combo_dfs, X_cols_sftd, combo_fns = smf.single_file_analysis_prep(signal_files, widest_orders, file_ids)\n",
    "        mouse_names = combo_fns\n",
    "    else:\n",
    "        raise ValueError('multifile_fit must be \"all\", \"single\", or \"by_mouse\"')\n",
    "\n",
    "    return mouse_names, combo_dfs, combo_fns, X_cols_sftd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_rows_with_all_cols(dfrel_basis,\n",
    "                          X_y_pairings,\n",
    "                          X_cols_sftd, \n",
    "                          drop_cols_basis = ['nTrial', 'nTrial_filenum', 'cpn', 'cpx', 'spnnr', 'spxnr', 'spnr', 'spxr',\n",
    "                                             \n",
    "                                             'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "                                             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                                             'photometrySideOutIndex', 'spnnrOff',\n",
    "                                             \n",
    "                                             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                                             'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "                                             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                                             'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "                                             'sl', 'slOff'\n",
    "                                            ]):\n",
    "    full_drop_basis = []\n",
    "    y_col_lst = []\n",
    "    for X_y_dct in X_y_pairings:\n",
    "        full_drop_basis += bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd)\n",
    "        y_col_lst += [X_y_dct['y_col']]\n",
    "    y_col_drop_basis = sorted(list(set(y_col_lst)))\n",
    "    full_drop_basis = sorted(list(set(drop_cols_basis + full_drop_basis + y_col_drop_basis)))\n",
    "\n",
    "    num_cols_na = (dfrel_basis[full_drop_basis].isna().sum(axis=1))\n",
    "    num_y_0 = (dfrel_basis[y_col_drop_basis] == 0).sum(axis=1)\n",
    "    has_all_cols = (num_cols_na == 0)&(num_y_0 == 0)\n",
    "\n",
    "    return has_all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc_words(signal_df, betas_df, total_col='photometrySideInIndex', words_prefix='photometrySideInIndex', words=['AA', 'Aa', 'aA', 'aa', 'AB', 'Ab', 'aB', 'ab'], perc_suffix='_cnt_tr'):\n",
    "    \n",
    "    tot_trials = signal_df[total_col].sum()\n",
    "    \n",
    "    betas_df[perc_suffix] = tot_trials\n",
    "    betas_df[f'AA{perc_suffix}'] = signal_df[f'{words_prefix}AA'].sum()/tot_trials\n",
    "    betas_df[f'Aa{perc_suffix}'] = signal_df[f'{words_prefix}Aa'].sum()/tot_trials\n",
    "    betas_df[f'aA{perc_suffix}'] = signal_df[f'{words_prefix}aA'].sum()/tot_trials\n",
    "    betas_df[f'aa{perc_suffix}'] = signal_df[f'{words_prefix}aa'].sum()/tot_trials\n",
    "    betas_df[f'AB{perc_suffix}'] = signal_df[f'{words_prefix}AB'].sum()/tot_trials\n",
    "    betas_df[f'Ab{perc_suffix}'] = signal_df[f'{words_prefix}Ab'].sum()/tot_trials\n",
    "    betas_df[f'aB{perc_suffix}'] = signal_df[f'{words_prefix}aB'].sum()/tot_trials\n",
    "    betas_df[f'ab{perc_suffix}'] = signal_df[f'{words_prefix}ab'].sum()/tot_trials\n",
    "    \n",
    "    return betas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = lambda x: str(Path(x).resolve())\n",
    "ps = lambda x: str(Path(x))\n",
    "\n",
    "# base_folder = '/home/josh/github-repos/sabatinilab-glm/sglm/outputs'\n",
    "base_folder = (Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs').resolve())\n",
    "# base_folder = '/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/outputs2'\n",
    "base_folder = (Path(base_folder).resolve())\n",
    "\n",
    "all_reconstruct_folder = ps('reconstructs')\n",
    "best_reconstruct_folder = ps('reconstructs')\n",
    "all_coefs_folder = ps('coefs')\n",
    "best_coefs_folder = ps('coefs')\n",
    "mses_folder = ps('mses')\n",
    "\n",
    "neg_order = -20\n",
    "pos_order = 20\n",
    "\n",
    "# data_folder = 'test'\n",
    "data_folder = 'Figure_1_2'\n",
    "# data_folder = 'Figure_3'\n",
    "# data_folder = 'Figure_3-dualhem'\n",
    "# data_folder = 'Figure_4/g1'\n",
    "# data_folder = 'Figure_4/g2'\n",
    "# data_folder = 'Figure_5/g1'\n",
    "# data_folder = 'Figure_5/g2'\n",
    "# data_folder = 'Figure_5/g3'\n",
    "# data_folder = 'Figure_5/g4'\n",
    "# data_folder = 'Figure_5/g5'\n",
    "\n",
    "fix_training = True #False\n",
    "\n",
    "# multifile_fit_list = ['single']\n",
    "# multifile_fit_list = ['by_mouse']\n",
    "multifile_fit_list = ['all']\n",
    "# multifile_fit_list = ['by_mouse', 'all']\n",
    "\n",
    "# base_prefix = f'oall-testhdf-4'\n",
    "# base_prefix = f'oall-testhdf-5-shortkern'\n",
    "# base_prefix = f'new-CO'\n",
    "# base_prefix = f'new-CO-50pholdout'\n",
    "base_prefix = f'f1-hyp-psweep-ph50-rr2'\n",
    "\n",
    "num_runs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "\n",
    "    log = file if hasattr(file,'write') else sys.stderr\n",
    "    traceback.print_stack(file=log)\n",
    "    log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "\n",
    "warnings.showwarning = warn_with_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs\\Figure_1_2\\all\\f1-hyp-psweep-ph50-rr2_0-ft\\reconstructs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs\\Figure_1_2\\all\\f1-hyp-psweep-ph50-rr2_0-ft\\coefs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs\\Figure_1_2\\all\\f1-hyp-psweep-ph50-rr2_0-ft\\mses\n",
      "file_ids ['GLM_SIGNALS_INTERIM_WT63_11102021.csv', 'GLM_SIGNALS_INTERIM_WT63_11122021.csv', 'GLM_SIGNALS_INTERIM_WT63_11162021.csv', 'GLM_SIGNALS_INTERIM_WT63_11182021.csv', 'GLM_SIGNALS_INTERIM_WT64_11082021.csv', 'GLM_SIGNALS_INTERIM_WT64_11102021.csv', 'GLM_SIGNALS_INTERIM_WT64_11122021.csv', 'GLM_SIGNALS_INTERIM_WT64_11162021.csv', 'GLM_SIGNALS_INTERIM_WT64_11182021.csv', 'GLM_SIGNALS_INTERIM_WT65_11082021.csv', 'GLM_SIGNALS_INTERIM_WT65_11102021.csv', 'GLM_SIGNALS_INTERIM_WT65_11122021.csv', 'GLM_SIGNALS_INTERIM_WT65_11162021.csv', 'GLM_SIGNALS_INTERIM_WT65_11182021.csv', 'GLM_SIGNALS_INTERIM_WT66_12132021.csv', 'GLM_SIGNALS_INTERIM_WT66_12152021.csv', 'GLM_SIGNALS_INTERIM_WT66_12172021.csv', 'GLM_SIGNALS_INTERIM_WT66_12192021.csv', 'GLM_SIGNALS_INTERIM_WT67_12132021.csv', 'GLM_SIGNALS_INTERIM_WT67_12152021.csv', 'GLM_SIGNALS_INTERIM_WT67_12172021.csv', 'GLM_SIGNALS_INTERIM_WT67_12192021.csv', 'GLM_SIGNALS_INTERIM_WT68_12132021.csv', 'GLM_SIGNALS_INTERIM_WT68_12152021.csv', 'GLM_SIGNALS_INTERIM_WT68_12172021.csv', 'GLM_SIGNALS_INTERIM_WT68_12192021.csv', 'GLM_SIGNALS_INTERIM_WT69_12132021.csv', 'GLM_SIGNALS_INTERIM_WT69_12152021.csv', 'GLM_SIGNALS_INTERIM_WT69_12172021.csv', 'GLM_SIGNALS_INTERIM_WT69_12192021.csv', 'GLM_SIGNALS_INTERIM_WT57_10042021.csv', 'GLM_SIGNALS_INTERIM_WT57_10062021.csv', 'GLM_SIGNALS_INTERIM_WT57_10082021.csv', 'GLM_SIGNALS_INTERIM_WT57_10112021.csv', 'GLM_SIGNALS_INTERIM_WT57_10132021.csv', 'GLM_SIGNALS_INTERIM_WT57_10152021.csv', 'GLM_SIGNALS_INTERIM_WT58_10042021.csv', 'GLM_SIGNALS_INTERIM_WT58_10062021.csv', 'GLM_SIGNALS_INTERIM_WT58_10082021.csv', 'GLM_SIGNALS_INTERIM_WT58_10112021.csv', 'GLM_SIGNALS_INTERIM_WT58_10132021.csv', 'GLM_SIGNALS_INTERIM_WT58_10152021.csv', 'GLM_SIGNALS_INTERIM_WT59_10042021.csv', 'GLM_SIGNALS_INTERIM_WT59_10082021.csv', 'GLM_SIGNALS_INTERIM_WT59_10112021.csv', 'GLM_SIGNALS_INTERIM_WT59_10132021.csv', 'GLM_SIGNALS_INTERIM_WT59_10152021.csv', 'GLM_SIGNALS_INTERIM_WT60_10042021.csv', 'GLM_SIGNALS_INTERIM_WT60_10062021.csv', 'GLM_SIGNALS_INTERIM_WT60_10112021.csv', 'GLM_SIGNALS_INTERIM_WT60_10132021.csv', 'GLM_SIGNALS_INTERIM_WT60_10152021.csv', 'GLM_SIGNALS_INTERIM_WT61_10042021.csv', 'GLM_SIGNALS_INTERIM_WT61_10062021.csv', 'GLM_SIGNALS_INTERIM_WT61_10112021.csv', 'GLM_SIGNALS_INTERIM_WT61_10132021.csv', 'GLM_SIGNALS_INTERIM_WT53_09012021.csv', 'GLM_SIGNALS_INTERIM_WT53_09032021.csv', 'GLM_SIGNALS_INTERIM_WT53_09062021.csv', 'GLM_SIGNALS_INTERIM_WT55_09012021.csv', 'GLM_SIGNALS_INTERIM_WT55_09032021.csv', 'GLM_SIGNALS_INTERIM_WT55_09062021.csv', 'GLM_SIGNALS_INTERIM_WT56_09012021.csv', 'GLM_SIGNALS_INTERIM_WT56_09032021.csv']\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20886991279172232\n",
      "> cv_R2_score: 0.20800507069104957\n",
      "> cv_mean_score: 0.20799924978538237\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 11.8 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  312.0 B\n",
      "                 dfresids_cols:  304.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0_run_num__0 - Time Passed: 157.22096610069275 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.20885263129581685\n",
      "> cv_R2_score: 0.20811520236734726\n",
      "> cv_mean_score: 0.2081167125205579\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 11.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0001_run_num__0 - Time Passed: 240.31291699409485 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.20840697024089203\n",
      "> cv_R2_score: 0.20982833611064522\n",
      "> cv_mean_score: 0.20982113788810955\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 11.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____001_run_num__0 - Time Passed: 323.33251094818115 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.20861439342754692\n",
      "> cv_R2_score: 0.20905423274956825\n",
      "> cv_mean_score: 0.20905249455376634\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____01_run_num__0 - Time Passed: 406.7779002189636 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+05, tolerance: 4.567e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+05, tolerance: 4.564e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+05, tolerance: 4.582e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.853e+05, tolerance: 4.563e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.855e+05, tolerance: 4.567e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+05, tolerance: 4.549e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+05, tolerance: 4.582e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e+05, tolerance: 4.550e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+05, tolerance: 4.580e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.854e+05, tolerance: 4.562e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.19831680665022278\n",
      "> cv_R2_score: 0.19722050122305512\n",
      "> cv_mean_score: 0.19722286356436874\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0_run_num__0 - Time Passed: 17405.540646076202 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.19846188794017394\n",
      "> cv_R2_score: 0.19710983404944016\n",
      "> cv_mean_score: 0.19710600223631952\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0001_run_num__0 - Time Passed: 18119.96680688858 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.19862846742817566\n",
      "> cv_R2_score: 0.1957689541160228\n",
      "> cv_mean_score: 0.1957698166049553\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____001_run_num__0 - Time Passed: 18708.455547094345 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.19837382456886504\n",
      "> cv_R2_score: 0.19651417639211266\n",
      "> cv_mean_score: 0.19652404735956425\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____01_run_num__0 - Time Passed: 19159.266606092453 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+05, tolerance: 4.549e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e+05, tolerance: 4.554e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+05, tolerance: 4.563e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+05, tolerance: 4.566e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.960e+05, tolerance: 4.560e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+05, tolerance: 4.561e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e+05, tolerance: 4.557e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.959e+05, tolerance: 4.548e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.961e+05, tolerance: 4.556e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+05, tolerance: 4.576e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.1596350866699289\n",
      "> cv_R2_score: 0.1589680722849074\n",
      "> cv_mean_score: 0.15897246359682274\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0_run_num__0 - Time Passed: 36437.86694288254 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.1597675300353944\n",
      "> cv_R2_score: 0.1582084794454337\n",
      "> cv_mean_score: 0.15821582403595494\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0001_run_num__0 - Time Passed: 36695.07762169838 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.15929995205626774\n",
      "> cv_R2_score: 0.15941100784752193\n",
      "> cv_mean_score: 0.15941741797071157\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____001_run_num__0 - Time Passed: 36916.02441120148 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.15788096605666352\n",
      "> cv_R2_score: 0.15848711519670888\n",
      "> cv_mean_score: 0.15848131009379277\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____01_run_num__0 - Time Passed: 37086.98149728775 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+05, tolerance: 4.550e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.126e+05, tolerance: 4.566e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+05, tolerance: 4.575e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.124e+05, tolerance: 4.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+05, tolerance: 4.552e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+05, tolerance: 4.542e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+05, tolerance: 4.558e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+05, tolerance: 4.546e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+05, tolerance: 4.577e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+05, tolerance: 4.572e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.09285807839118362\n",
      "> cv_R2_score: 0.09388897075158653\n",
      "> cv_mean_score: 0.0938913195912455\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.4 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____0_run_num__0 - Time Passed: 54382.48789143562 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.09306234715106601\n",
      "> cv_R2_score: 0.09310664020020709\n",
      "> cv_mean_score: 0.09309677761540909\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.4 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  728.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____0001_run_num__0 - Time Passed: 54487.748831272125 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.09262121551064349\n",
      "> cv_R2_score: 0.09158226347538623\n",
      "> cv_mean_score: 0.09157444097396833\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.5 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  728.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____001_run_num__0 - Time Passed: 54576.28713965416 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.0852596307562695\n",
      "> cv_R2_score: 0.08523624349775083\n",
      "> cv_mean_score: 0.08524084853831518\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.5 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  728.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____01_run_num__0 - Time Passed: 54650.034106731415 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+05, tolerance: 4.568e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+05, tolerance: 4.554e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+05, tolerance: 4.557e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+05, tolerance: 4.555e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+05, tolerance: 4.571e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+05, tolerance: 4.575e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+05, tolerance: 4.546e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+05, tolerance: 4.547e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+05, tolerance: 4.567e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+05, tolerance: 4.569e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.805e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.02179329318078055\n",
      "> cv_R2_score: 0.021546615979751826\n",
      "> cv_mean_score: 0.021543138919603976\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.6 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  728.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.805e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____0_run_num__0 - Time Passed: 71975.51743245125 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.02166196324021431\n",
      "> cv_R2_score: 0.02168416549010488\n",
      "> cv_mean_score: 0.021679099793983702\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.6 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  728.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____0001_run_num__0 - Time Passed: 72031.7579343319 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.019920401289790213\n",
      "> cv_R2_score: 0.019758516117170943\n",
      "> cv_mean_score: 0.01975855436730526\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.7 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____001_run_num__0 - Time Passed: 72084.54809045792 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.008256980113695678\n",
      "> cv_R2_score: 0.008025277197449943\n",
      "> cv_mean_score: 0.008021956445513933\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.7 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____01_run_num__0 - Time Passed: 72138.5923306942 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21766942211328716\n",
      "> cv_R2_score: 0.21465328844936693\n",
      "> cv_mean_score: 0.21465256841295885\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.8 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0_run_num__0 - Time Passed: 72281.00606584549 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.21745012200641384\n",
      "> cv_R2_score: 0.21549534596036124\n",
      "> cv_mean_score: 0.2155003101436615\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.8 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0001_run_num__0 - Time Passed: 72426.38882303238 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.21791970595466054\n",
      "> cv_R2_score: 0.21365167530229956\n",
      "> cv_mean_score: 0.21365116451348146\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____001_run_num__0 - Time Passed: 72568.88920688629 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.21722708415373368\n",
      "> cv_R2_score: 0.216478162126993\n",
      "> cv_mean_score: 0.21647424818079725\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 12.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  856.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____01_run_num__0 - Time Passed: 72712.96385478973 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e+05, tolerance: 4.549e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+05, tolerance: 4.560e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.869e+05, tolerance: 4.556e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e+05, tolerance: 4.559e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e+05, tolerance: 4.574e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+05, tolerance: 4.565e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+05, tolerance: 4.566e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+05, tolerance: 4.574e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+05, tolerance: 4.571e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+05, tolerance: 4.553e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.19403565538444517\n",
      "> cv_R2_score: 0.19295999773253603\n",
      "> cv_mean_score: 0.19297029284052053\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0_run_num__0 - Time Passed: 145906.41037750244 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.19380874856514022\n",
      "> cv_R2_score: 0.1934044909786703\n",
      "> cv_mean_score: 0.19341555475329902\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0001_run_num__0 - Time Passed: 148567.56055736542 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.19370711146512948\n",
      "> cv_R2_score: 0.19344029036435195\n",
      "> cv_mean_score: 0.19342817278338625\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____001_run_num__0 - Time Passed: 150778.46858143806 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.19370483756700668\n",
      "> cv_R2_score: 0.1918723153630313\n",
      "> cv_mean_score: 0.19187759640377175\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____01_run_num__0 - Time Passed: 152464.6137061119 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+05, tolerance: 4.556e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+05, tolerance: 4.547e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+05, tolerance: 4.571e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+05, tolerance: 4.565e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+05, tolerance: 4.561e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+05, tolerance: 4.538e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+05, tolerance: 4.554e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+05, tolerance: 4.537e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+05, tolerance: 4.561e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e+05, tolerance: 4.547e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.1451287458666446\n",
      "> cv_R2_score: 0.14620092387304495\n",
      "> cv_mean_score: 0.146185450687283\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0_run_num__0 - Time Passed: 224536.60046696663 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.1452594806291864\n",
      "> cv_R2_score: 0.145741710155335\n",
      "> cv_mean_score: 0.14573708993600315\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                 dfresids_cols: 1016.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0001_run_num__0 - Time Passed: 225840.9091551304 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.14532522975983989\n",
      "> cv_R2_score: 0.14460300745219645\n",
      "> cv_mean_score: 0.14459984855843983\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____001_run_num__0 - Time Passed: 226329.12342071533 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.14315400135100362\n",
      "> cv_R2_score: 0.14328896243733114\n",
      "> cv_mean_score: 0.14327755273748155\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____01_run_num__0 - Time Passed: 227074.71079730988 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e+05, tolerance: 4.568e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+05, tolerance: 4.564e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+05, tolerance: 4.570e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+05, tolerance: 4.562e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+05, tolerance: 4.584e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+05, tolerance: 4.577e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.141e+05, tolerance: 4.576e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e+05, tolerance: 4.561e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+05, tolerance: 4.562e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e+05, tolerance: 4.565e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.08584453528644416\n",
      "> cv_R2_score: 0.08523779575446344\n",
      "> cv_mean_score: 0.08523997783597015\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.4 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____0_run_num__0 - Time Passed: 296021.11014199257 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.08590748102834601\n",
      "> cv_R2_score: 0.08482186999408659\n",
      "> cv_mean_score: 0.08482546313001561\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.4 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____0001_run_num__0 - Time Passed: 296337.5705111027 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.08490288478355149\n",
      "> cv_R2_score: 0.08444189219194953\n",
      "> cv_mean_score: 0.08444266765467742\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.5 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____001_run_num__0 - Time Passed: 296830.70490312576 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.07833815222909836\n",
      "> cv_R2_score: 0.0785064194134295\n",
      "> cv_mean_score: 0.07850439769802345\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.5 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____0_____1__l1_ratio____0_____01_run_num__0 - Time Passed: 297169.39818525314 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+05, tolerance: 4.570e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+05, tolerance: 4.552e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+05, tolerance: 4.578e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+05, tolerance: 4.599e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+05, tolerance: 4.576e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+05, tolerance: 4.543e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+05, tolerance: 4.566e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+05, tolerance: 4.551e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+05, tolerance: 4.563e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+05, tolerance: 4.572e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.020207829203924423\n",
      "> cv_R2_score: 0.019776373905353584\n",
      "> cv_mean_score: 0.019772355271043707\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.6 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                 dfresids_cols:  1.1 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e+05, tolerance: 5.701e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____0_run_num__0 - Time Passed: 355186.4801058769 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.019803760007682136\n",
      "> cv_R2_score: 0.020151857792075956\n",
      "> cv_mean_score: 0.020152051814833816\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.6 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____0001_run_num__0 - Time Passed: 355286.7620270252 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.018298708124759467\n",
      "> cv_R2_score: 0.018324875779272887\n",
      "> cv_mean_score: 0.0183264790080383\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.7 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____001_run_num__0 - Time Passed: 355367.48742341995 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 1.0, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.008281288197745984\n",
      "> cv_R2_score: 0.007604876858034237\n",
      "> cv_mean_score: 0.007601806079882223\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.7 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                    df_holdout:  3.2 GiB\n",
      "                      df_train:  3.1 GiB\n",
      "                     X_holdout:  2.3 GiB\n",
      "                       X_train:  2.3 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                       y_train:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  4.8 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_1_base_words_max_iter____10000__fit_intercept____False__alpha____1_____0__l1_ratio____0_____01_run_num__0 - Time Passed: 355442.36700057983 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20564916540316996\n",
      "> cv_R2_score: 0.20812945014814332\n",
      "> cv_mean_score: 0.20812990582905747\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.8 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                      betas_df:  6.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0_run_num__1 - Time Passed: 355531.8499510288 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.20632721268013202\n",
      "> cv_R2_score: 0.20544433180573463\n",
      "> cv_mean_score: 0.20544618030605796\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.8 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____0001_run_num__1 - Time Passed: 355616.53059220314 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.20650624204842027\n",
      "> cv_R2_score: 0.20463006366448921\n",
      "> cv_mean_score: 0.20463829344106915\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____001_run_num__1 - Time Passed: 355701.1407227516 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.20615868371126145\n",
      "> cv_R2_score: 0.20604104740346785\n",
      "> cv_mean_score: 0.2060223574469135\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 13.9 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____0__l1_ratio____0_____01_run_num__1 - Time Passed: 355785.5851814747 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+05, tolerance: 4.587e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e+05, tolerance: 4.589e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+05, tolerance: 4.577e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e+05, tolerance: 4.575e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+05, tolerance: 4.577e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+05, tolerance: 4.567e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+05, tolerance: 4.566e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+05, tolerance: 4.565e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+05, tolerance: 4.578e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+05, tolerance: 4.597e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+05, tolerance: 5.722e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.19568258546985334\n",
      "> cv_R2_score: 0.1947735479797288\n",
      "> cv_mean_score: 0.19478196372212633\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.3 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+05, tolerance: 5.722e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0_run_num__1 - Time Passed: 381885.6314573288 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.19521484922510549\n",
      "> cv_R2_score: 0.1965584268100048\n",
      "> cv_mean_score: 0.19657311286818363\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.0 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____0001_run_num__1 - Time Passed: 383310.93877744675 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.19586015807742513\n",
      "> cv_R2_score: 0.1939847420950397\n",
      "> cv_mean_score: 0.1939832377624683\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____001_run_num__1 - Time Passed: 384288.59379053116 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.001, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.19597784832890133\n",
      "> cv_R2_score: 0.19309858484984965\n",
      "> cv_mean_score: 0.19308921347172428\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.1 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____001__l1_ratio____0_____01_run_num__1 - Time Passed: 385104.6913714409 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+05, tolerance: 4.574e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+05, tolerance: 4.578e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e+05, tolerance: 4.558e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+05, tolerance: 4.611e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e+05, tolerance: 4.583e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+05, tolerance: 4.577e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+05, tolerance: 4.579e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+05, tolerance: 4.598e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+05, tolerance: 4.552e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 109, in run_single\n",
      "    glm.fit_set(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 343, in fit_set\n",
      "    self.fit(X, y, *args)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+05, tolerance: 4.582e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 966, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 126, in run_multi\n",
      "    cv_glm_single_params(*args, **kwargs)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm_cv.py\", line 223, in cv_glm_single_params\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+05, tolerance: 5.722e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.1582193369207149\n",
      "> cv_R2_score: 0.1559229154113223\n",
      "> cv_mean_score: 0.15590984333941046\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\3881213025.py\", line 318, in <cell line: 204>\n",
      "    glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\eval.py\", line 63, in training_fit_holdout_score\n",
      "    glm = sglm.fit_GLM(X_setup, y_setup, **best_params)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 482, in fit_GLM\n",
      "    glm.fit(X, y)\n",
      "  File \"c:\\users\\josh\\documents\\github\\sabatinilab-glm\\sglm\\sglm\\models\\sglm.py\", line 252, in fit\n",
      "    self.model.fit(X, y, *args)\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 1054, in fit\n",
      "    _, this_coef, this_dual_gap, this_iter = self.path(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 648, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\warnings.py\", line 109, in _showwarnmsg\n",
      "    sw(msg.message, msg.category, msg.filename, msg.lineno,\n",
      "  File \"C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_21872\\1914403108.py\", line 8, in warn_with_traceback\n",
      "    traceback.print_stack(file=log)\n",
      "C:\\Users\\Josh\\anaconda3\\envs\\sglm\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+05, tolerance: 5.722e+01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0_run_num__1 - Time Passed: 403911.95132017136 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.0001}\n",
      "> cv_mean_score_train: 0.15816678789604166\n",
      "> cv_R2_score: 0.1556313840604845\n",
      "> cv_mean_score: 0.15563373822232682\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.2 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____0001_run_num__1 - Time Passed: 404182.05856752396 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.001}\n",
      "> cv_mean_score_train: 0.1579860070947549\n",
      "> cv_R2_score: 0.1560603527928328\n",
      "> cv_mean_score: 0.1560598661356992\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____001_run_num__1 - Time Passed: 404409.6343026161 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.01, 'l1_ratio': 0.01}\n",
      "> cv_mean_score_train: 0.15654140204383993\n",
      "> cv_R2_score: 0.15563357184196513\n",
      "> cv_mean_score: 0.1556288495872792\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 14.3 GiB\n",
      "      dfrel_basis_has_all_cols:  8.4 GiB\n",
      "                      df_train:  3.2 GiB\n",
      "                    df_holdout:  3.1 GiB\n",
      "                       X_train:  1.2 GiB\n",
      "                     X_holdout:  1.2 GiB\n",
      "                       holdout: 45.4 MiB\n",
      "                       y_train:  8.9 MiB\n",
      "                     y_holdout:  8.8 MiB\n",
      "                  has_all_cols:  2.1 MiB\n",
      "                          _i13: 17.5 KiB\n",
      "                   X_cols_sftd:  4.9 KiB\n",
      "                      betas_df:  4.6 KiB\n",
      "                        X_cols:  2.6 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                 dfresids_cols:  1.6 KiB\n",
      "                           _ii:  1.3 KiB\n",
      "                          _i11:  1.3 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                  signal_files:  632.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "run_id, subrun_id 63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0 gACH_0_0_base_simple_max_iter____10000__fit_intercept____False__alpha____0_____01__l1_ratio____0_____01_run_num__1 - Time Passed: 404586.8483684063 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def func_for_cprofile():\n",
    "ft_str = '-ft' if fix_training else ''\n",
    "\n",
    "if data_folder == 'test':\n",
    "    wt_used = [\n",
    "        'WT63', 'WT64', 'WT53', 'WT69'\n",
    "    ]\n",
    "\n",
    "elif data_folder == 'Figure_1_2':\n",
    "\n",
    "    wt_used = [\n",
    "               'WT63', 'WT64', 'WT65', 'WT66', 'WT67', 'WT68', 'WT69', # DA\n",
    "               'WT57', 'WT58', 'WT59', 'WT60', 'WT61', 'WT53', 'WT55', 'WT56' # ACH\n",
    "               ]\n",
    "\n",
    "elif data_folder == 'Figure_3':\n",
    "    wt_used = ['WT61', 'WT63', 'WT64', 'WT44', 'WT51']\n",
    "elif data_folder == 'Figure_3-dualhem':\n",
    "    wt_used = ['WT63', 'WT64', 'WT65']\n",
    "\n",
    "elif data_folder == 'Figure_4/g1':\n",
    "    wt_used = ['S1233', 'S1234', 'S1260', 'S1246', 'S1248']\n",
    "elif data_folder == 'Figure_4/g2':\n",
    "    wt_used = ['S1194', 'S1195', 'S1214', 'S1258', 'S1259']\n",
    "\n",
    "elif data_folder == 'Figure_5/g1': # Drd2f/f control: S1417, 1419, 1421\n",
    "    # wt_used = ['S1417', 'S1419', 'S1421']\n",
    "    wt_used = ['S1417', 'S1419', 'S1421', 'S1460', 'S1462', 'S1473', 'S1474']\n",
    "elif data_folder == 'Figure_5/g2': # Chat Cre X Drd2f/f : S1416, 1418, 1420, 1422\n",
    "    # wt_used = ['S1416', 'S1418', 'S1420', 'S1422']\n",
    "    wt_used = ['S1416', 'S1418', 'S1420', 'S1459', 'S1461', 'S1470', 'S1471', 'S1472']\n",
    "elif data_folder == 'Figure_5/g3': # Chat Cre control: S1355-1358, S1374, S1376\n",
    "    # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376']\n",
    "    wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "               'S1448', 'S1449', 'S1450', 'S1451']\n",
    "elif data_folder == 'Figure_5/g4': # Chat Cre control: S1399-1401\n",
    "    # wt_used = ['S1399', 'S1400', 'S1401']\n",
    "    wt_used = ['S1399', 'S1400', 'S1401']\n",
    "elif data_folder == 'Figure_5/g5':\n",
    "    # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376', 'S1399', 'S1400', 'S1401']\n",
    "    wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "               'S1448', 'S1449', 'S1450', 'S1451'\n",
    "               'S1399', 'S1400', 'S1401']\n",
    "elif data_folder == 'Figure_5/g6':\n",
    "    wt_used = []\n",
    "else:\n",
    "    raise ValueError('Unimplemented figure values.')\n",
    "\n",
    "data_folder_src = data_folder if data_folder != 'test' else 'Figure_1_2'\n",
    "data_folder_join = '_'.join(Path(data_folder).parts)\n",
    "\n",
    "\n",
    "### Backwards Selection\n",
    "X_y_pairings_lst = []\n",
    "\n",
    "X_y_pairings_lst += [[\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),                \n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gACH',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gACH',\n",
    "     'name': 'base_words'},\n",
    "\n",
    "]]\n",
    "\n",
    "X_y_pairings_lst += [[\n",
    "\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),                \n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'rDA',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'rDA',\n",
    "     'name': 'base_words'},\n",
    "\n",
    "]]\n",
    "\n",
    "X_y_pairings_lst += [[\n",
    "\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),                \n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDA',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                'photometrySideOutIndex':(0,0),\n",
    "                'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDA',\n",
    "     'name': 'base_words'},\n",
    "\n",
    "]]\n",
    "\n",
    "\n",
    "plot_width = 2\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "plot_rows_lst = [_//plot_width + (_%plot_width > 0)*1 for _ in max_cols_len_lst]\n",
    "\n",
    "\n",
    "dfrr_cols = ['signal_file', 'file_num', 'nTrial', 'nTrial_filenum', 'nEndTrial', 'wi_trial_keep',\n",
    "             'nTrial_hard', 'nEndTrial_hard', 'diffTrialNums_hard', 'wi_trial_keep_hard',\n",
    "             'has_all_cols', 'gDA', 'gACH', 'rDA',\n",
    "             'diffTrialNums', 'dupe',\n",
    "             'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "             'photometrySideOutIndex', 'spnnrOff', 'sl',\n",
    "\n",
    "             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "             'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "             'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "]\n",
    "\n",
    "score_method = 'r2'\n",
    "\n",
    "# Select hyper parameters for GLM to use for model selection\n",
    "# Step 1: Create a dictionary of lists for these relevant keywords...\n",
    "kwargs_iterations = {\n",
    "    # 'alpha': [0],\n",
    "    # 'l1_ratio': [0],\n",
    "\n",
    "    'alpha': [0.0, 0.001, 0.01, 0.1, 1.0],\n",
    "    'l1_ratio': [0.0, 0.0001, 0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Step 2: Create a dictionary for the fixed keyword arguments that do not require iteration...\n",
    "kwargs_fixed = {\n",
    "    'max_iter': 10000,\n",
    "    'fit_intercept': False\n",
    "}\n",
    "\n",
    "folds = 10\n",
    "pholdout = 0.5\n",
    "pgss = 0.2\n",
    "\n",
    "# Step 3: Generate iterable list of keyword sets for possible combinations\n",
    "glm_kwarg_lst = sglm_cv.generate_mult_params(kwargs_iterations, kwargs_fixed)\n",
    "\n",
    "\n",
    "multi_start = time.time()\n",
    "for iXyp, X_y_pairings in enumerate(X_y_pairings_lst):\n",
    "\n",
    "    widest_orders = smf.xy_pairs_to_widest_orders([{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "                                                    'y_col': _['y_col']} for _ in X_y_pairings])\n",
    "    max_cols_len = max_cols_len_lst[iXyp]\n",
    "    plot_rows = plot_rows_lst[iXyp]\n",
    "\n",
    "    for multifile_fit in multifile_fit_list:\n",
    "        prefix = f'{data_folder_join}/{multifile_fit}/{base_prefix}_{iXyp}{ft_str}'\n",
    "        create_all_folders(base_folder, prefix,\n",
    "                        all_reconstruct_folder,\n",
    "                        best_reconstruct_folder,\n",
    "                        all_coefs_folder,\n",
    "                        best_coefs_folder,\n",
    "                        mses_folder)\n",
    "\n",
    "        # Load Signal Data\n",
    "        signal_files = []\n",
    "        mouse_names = []\n",
    "        for wt in wt_used:\n",
    "            addl_sig_files = glob.glob(pr(f'../../data/interim-new/{data_folder_src}/GLM_SIGNALS_INTERIM_{wt}_*'))\n",
    "            signal_files += addl_sig_files\n",
    "            mouse_names += [wt] * len(addl_sig_files)\n",
    "\n",
    "        mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit)\n",
    "\n",
    "        start = time.time()\n",
    "        results_dict = {}\n",
    "\n",
    "        for file_num in range(len(combo_fns)):\n",
    "            # Load Table Data\n",
    "            dfrel_basis = combo_dfs[file_num].reset_index(drop=False).copy()\n",
    "            \n",
    "            dfrel_basis['nTrial_hard'] = dfrel_basis.groupby('file_num')['nTrial'].shift(20)\n",
    "            dfrel_basis['nEndTrial_hard'] = dfrel_basis.groupby('file_num')['nEndTrial'].shift(-20)\n",
    "            dfrel_basis['diffTrialNums_hard'] = dfrel_basis['nTrial_hard'] - dfrel_basis['nEndTrial_hard']\n",
    "            dfrel_basis['wi_trial_keep_hard'] = (dfrel_basis['diffTrialNums_hard'] == 1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            fn = Path(combo_fns[file_num].split('.')[0]).parts[-1]\n",
    "            mouse_id = mouse_names[file_num]\n",
    "            dfresids_cols = np.copy(dfrr_cols).tolist()\n",
    "            run_id = f'{fn}_{iXyp}'            \n",
    "\n",
    "            has_all_cols = id_rows_with_all_cols(dfrel_basis, X_y_pairings, X_cols_sftd)\n",
    "            if has_all_cols.sum() == 0:\n",
    "                print(f'No datapoints found for non-NaN dropcols & non-zero ycols for fixed_training: {prefix}_{fn}')\n",
    "                continue\n",
    "            \n",
    "            dfrel_basis['has_all_cols'] = has_all_cols\n",
    "            dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_{run_id}.h5'), key='dfrel_basis', index=True,)\n",
    "            \n",
    "            dfrel_basis_has_all_cols = dfrel_basis[has_all_cols]\n",
    "\n",
    "            for irun in range(num_runs):\n",
    "                holdout = models.split_data.holdout_split_by_trial_id(dfrel_basis_has_all_cols,\n",
    "                                                                    id_cols=['nTrial_filenum'],\n",
    "                                                                    perc_holdout=pholdout)\n",
    "                dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'] = holdout\n",
    "                dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'].astype(float)\n",
    "\n",
    "                for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "\n",
    "                    for glm_kwargs in glm_kwarg_lst:\n",
    "                        print(glm_kwargs)\n",
    "                        hyp_str = '__'.join(['____'.join([str(__) for __ in _]) for _ in glm_kwargs.items()]).replace('.', '_____')\n",
    "                        \n",
    "\n",
    "                        X_cols = bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd)\n",
    "                        y_col = X_y_dct['y_col']\n",
    "                        name = X_y_dct['name']\n",
    "                        \n",
    "                        subrun_id = f'{y_col}_{iXyp}_{iXyd}_{name}_{hyp_str}_run_num__{irun}'\n",
    "    #                     pred_col_name = f'y={y_col}_irun={irun}_iXyd={iXyd}_name={name}'\n",
    "\n",
    "                        pred_col_name = subrun_id\n",
    "\n",
    "\n",
    "                        if not fix_training:\n",
    "                            holdout = models.split_data.holdout_split_by_trial_id(dfrel_basis_has_all_cols, id_cols=['nTrial_filenum'], perc_holdout=pholdout)\n",
    "    #                         dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'] = holdout\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = holdout\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = dfrel_basis[f'holdout_{pred_col_name}'].astype(float)\n",
    "                        else:\n",
    "    #                         dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}']\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'].astype(float)\n",
    "                            \n",
    "                        if (~dfrel_basis[f'holdout_{pred_col_name}'].isna()).sum() == 0:\n",
    "                            print(f'No datapoints found for non-NaN dropcols & non-zero ycols for run id: {run_id}, {subrun_id}.')\n",
    "                            continue\n",
    "\n",
    "                        df_train = dfrel_basis_has_all_cols[(~holdout)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "                        df_holdout = dfrel_basis_has_all_cols[(holdout)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "\n",
    "                        #TODO: JZ - CHANGE BACK TO WI_TRIAL_KEEP    \n",
    "                        # df_train = dfrel_basis_has_all_cols[(~holdout)&(dfrel_basis_has_all_cols['wi_trial_keep_hard'])]\n",
    "                        # df_holdout = dfrel_basis_has_all_cols[(holdout)&(dfrel_basis_has_all_cols['wi_trial_keep_hard'])]\n",
    "                        \n",
    "                        X_train, y_train, X_holdout, y_holdout = df_train[X_cols], df_train[y_col], df_holdout[X_cols], df_holdout[y_col]\n",
    "\n",
    "                        kfold_cv_idx = models.split_data.cv_idx_by_trial_id(df_train, trial_id_columns=['nTrial_filenum'], num_folds=folds, test_size=pgss)\n",
    "                        \n",
    "                        # best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_train, y_train, kfold_cv_idx, glm_kwarg_lst, model_type='Normal',\n",
    "                        #                                                                                             verbose=0, score_method=score_method)\n",
    "                        best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_train, y_train, kfold_cv_idx, [glm_kwargs], model_type='Normal',\n",
    "                                                                                                                    verbose=0, score_method=score_method)\n",
    "                        \n",
    "\n",
    "                        print('Variable Sizes:')\n",
    "                        for vname, size in sorted(((vname, sys.getsizeof(value)) for vname, value in locals().items()),\n",
    "                                                key= lambda x: -x[1])[:30]:\n",
    "                            print(\"{:>30}: {:>8}\".format(vname, sizeof_fmt(size)))\n",
    "\n",
    "                        glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
    "\n",
    "                        betas_df = pd.DataFrame(np.concatenate([np.array([glm.intercept_]), glm.coef_], axis=0).reshape(1,-1),\n",
    "                                    index=[run_id], columns=['int']+X_cols)\n",
    "                        betas_df['mouse_id'] = mouse_id\n",
    "                        betas_df['channel_name'] = f'{y_col}_{iXyd}_run_num={irun}'\n",
    "                        betas_df['name'] = name\n",
    "\n",
    "                        # Only get R^2 values if only a single model fit\n",
    "                        assert len(cv_results['full_cv_results']) == 1\n",
    "                        # TODO: JZ -- IMPLEMENT VERSION FOR MULTIPLE HYPERPARAMETER SWEEPS\n",
    "                        assert holdout_neg_mse_score == glm.neg_mse_score(X_holdout, y_holdout)\n",
    "\n",
    "                        betas_df[['mse_tr', 'mse_cv', 'mse_te']] = [[-glm.neg_mse_score(X_train, y_train), cv_results['full_cv_results'][0]['cv_mse_score'], -glm.neg_mse_score(X_holdout, y_holdout)]]\n",
    "                        betas_df[['r2_tr', 'r2_cv', 'r2_te']] = [[glm.r2_score(X_train, y_train), cv_results['full_cv_results'][0]['cv_R2_score'], glm.r2_score(X_holdout, y_holdout)]]\n",
    "\n",
    "                        multi_end = time.time()\n",
    "                        time_passed = str(multi_end - multi_start) + ' s'\n",
    "                        betas_df['timestamp'] = time_passed\n",
    "                        print('run_id, subrun_id', run_id, subrun_id, f'- Time Passed: {time_passed}')\n",
    "\n",
    "                        betas_df = betas_df.set_index(['mouse_id', 'channel_name', 'name', 'timestamp', 'mse_tr', 'mse_cv', 'mse_te', 'r2_tr', 'r2_cv', 'r2_te'], append=True)\n",
    "\n",
    "                        word_perc_kwargs = dict(total_col='photometrySideInIndex', words_prefix='photometrySideInIndex', words=['AA', 'Aa', 'aA', 'aa', 'AB', 'Ab', 'aB', 'ab'])\n",
    "                        betas_df = get_perc_words(df_train, betas_df, perc_suffix='_cnt_tr',  **word_perc_kwargs)\n",
    "                        betas_df = get_perc_words(df_holdout, betas_df, perc_suffix='_cnt_ho', **word_perc_kwargs)\n",
    "\n",
    "                        betas_df.to_hdf(pr(f'{base_folder}/{prefix}/{best_coefs_folder}/{run_id}_best_coeffs.h5'), key=subrun_id, index=True)\n",
    "\n",
    "                        dfrel_basis['pred_'+pred_col_name] = pd.Series(glm.predict(dfrel_basis_has_all_cols[X_cols]),\n",
    "                                                                                    index=dfrel_basis_has_all_cols.index)\n",
    "                        dfrel_basis['predALL_'+pred_col_name] = glm.predict(dfrel_basis[X_cols])\n",
    "\n",
    "                        subset_dfresids_cols = [f'holdout_{pred_col_name}', 'pred_'+pred_col_name, 'predALL_'+pred_col_name]\n",
    "                        dfresids_cols += subset_dfresids_cols\n",
    "    #                     dfresids_cols += [f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}', 'pred_'+pred_col_name, 'predALL_'+pred_col_name]\n",
    "                        \n",
    "    #                     display(dfrel_basis)\n",
    "                        dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True)[subset_dfresids_cols].to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_{run_id}.h5'), key=subrun_id, index=True,)\n",
    "    #                     break\n",
    "    #             dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_fn={fn}_iXyp={iXyp}_all.h5'), key='df', index=True,)\n",
    "    #                 break\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "    # return\n",
    "\n",
    "    # import cProfile\n",
    "    # cprof = cProfile.run('func_for_cprofile()', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.sum(), (~holdout.isna()).sum() - holdout.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis.columns[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis_backup_og = dfrel_basis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_if_has_val(check_srs, x_srs, y_srs, label='label', ax=None):\n",
    "    if check_srs.abs().sum() > 0:\n",
    "        ax.plot(x_srs, y_srs, label=label)\n",
    "\n",
    "def view_trial(df, nTrial, y_col='gACH', pred_col='pred', holdout_col='holdout', dupe_col='dupe', wi_trial_keep_col='wi_trial_keep_hard'):\n",
    "    if nTrial:\n",
    "        df = df[df['nTrial_filenum'] == nTrial]\n",
    "    \n",
    "    fig,axes = plt.subplots(4,1,figsize=(30,10))\n",
    "    fig.set_facecolor('w')\n",
    "    \n",
    "#     fig.suptitle(f'MSE -- Total: {}')\n",
    "    \n",
    "    tax = axes[0]\n",
    "    tax.grid(True)\n",
    "    bax = axes[1]\n",
    "    bax.grid(True)\n",
    "    bbax = axes[2]\n",
    "    bbax.grid(True)\n",
    "    bbbax = axes[3]\n",
    "    bbbax.grid(True)\n",
    "    \n",
    "    show_if_has_val(df['photometryCenterInIndex'], df.index, df['photometryCenterInIndex']+2, label='CI', ax=tax)\n",
    "    show_if_has_val(df['photometryCenterOutIndex'], df.index, df['photometryCenterOutIndex']+2, label='CO', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndex'], df.index, df['photometrySideInIndex']+2, label='SI', ax=tax)\n",
    "    show_if_has_val(df['photometrySideOutIndex'], df.index, df['photometrySideOutIndex']+2, label='SO', ax=tax)\n",
    "    tax.plot(df.index, df[holdout_col]*1, label='isHoldout')\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexr'], df.index, df['photometrySideInIndexr']*1+4, label='SIr', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexnr'], df.index, df['photometrySideInIndexnr']*1+4, label='SInr', ax=tax)\n",
    "    show_if_has_val(df['spnnrOff'], df.index, df['spnnrOff']*1+4, label='spnnrOff', ax=tax)\n",
    "    show_if_has_val(df['sl'], df.index, df['sl']*1+4, label='SL', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexAA'], df.index, df['photometrySideInIndexAA']*1+6, label='AA', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexAa'], df.index, df['photometrySideInIndexAa']*1+6, label='Aa', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaA'], df.index, df['photometrySideInIndexaA']*1+6, label='aA', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaa'], df.index, df['photometrySideInIndexaa']*1+6, label='aa', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexAB'], df.index, df['photometrySideInIndexAB']*1+6, label='AB', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexAb'], df.index, df['photometrySideInIndexAb']*1+6, label='Ab', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaB'], df.index, df['photometrySideInIndexaB']*1+6, label='aB', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexab'], df.index, df['photometrySideInIndexab']*1+6, label='ab', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df[dupe_col], df.index, df[dupe_col]*1+8, label='isDupe', ax=tax)\n",
    "    show_if_has_val(df[wi_trial_keep_col], df.index, df[wi_trial_keep_col]*1+8, label='isInTrial', ax=tax)\n",
    "    \n",
    "    tax.legend()\n",
    "    \n",
    "    bax.plot(df.index, df[y_col], label=f'True - {y_col}')\n",
    "    bax.plot(df.index, df[pred_col], label=f'Pred - {y_col}')\n",
    "    \n",
    "    bax.legend()\n",
    "    \n",
    "    bbax.plot(df.index, (df[y_col] - df[pred_col])**2, label='Resid^2')\n",
    "    bbax.legend()\n",
    "    \n",
    "    bbbax.plot(df.index, ((df[y_col] - df[pred_col])**2).cumsum(), label='Cumulative Resid^2')\n",
    "    bbbax.plot(df.index, ((df[y_col] - df[pred_col])**2 * df['wi_trial_keep']).cumsum(), label='Cumulative Resid^2 -- Within Trial')\n",
    "    bbbax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lst = []\n",
    "# with pd.HDFStore(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs\\fig1\\all\\oall-testhdf-4_0-ft\\reconstructs\\best\\best_resids_63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0.h5') as hdf:\n",
    "#     print(hdf.keys())\n",
    "#     for key in hdf.keys():\n",
    "#         df_lst.append(pd.read_hdf(hdf, key=key))\n",
    "# #     df_reader = hdf.select('my_table_id', chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfrel_basis = df_lst[-2]\n",
    "# dfrel_basis = dfrel_basis_backup_og.copy()\n",
    "dfrel_basis = dfrel_basis_backup_og[~dfrel_basis_backup_og['dupe']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "# dfrel_basis = dfrel_basis_backup.copy()\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "tot_rns = 50\n",
    "# for run_num in trange(4, 5):\n",
    "for run_num in trange(tot_rns):\n",
    "    # for run_num in range(10):\n",
    "    dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "    dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "    dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "    # dfrel_basis['resid2_wi_trial_short'] = ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "\n",
    "    df_inspect = dfrel_basis\n",
    "    # df_inspect = dfrel_basis[~dfrel_basis['file_num'].isin([16, 10, 17, 15, 3, 13, 12, 7])]\n",
    "    # df_inspect = hdf[hdf['diffTrialNums'] == 1]\n",
    "    # df_inspect = dfrel_basis[dfrel_basis['wi_trial_keep']]\n",
    "\n",
    "    training_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == False')\n",
    "    holdout_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == True')\n",
    "\n",
    "    # print('Num Total', df_inspect.shape[0])\n",
    "    # print('Num Holdout', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].sum())\n",
    "    # print('Num Nan', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].isna().sum())\n",
    "\n",
    "    training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    addl_resids = pd.DataFrame([(training_mean_resids.values<holdout_mean_resids.values)*1],\n",
    "                                index=['correct'],\n",
    "                                columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "    if run_num == 0:\n",
    "        mean_resids = addl_resids\n",
    "    else:\n",
    "        mean_resids += addl_resids\n",
    "    display(addl_resids)\n",
    "display(mean_resids/(run_num+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "# run_num = 50\n",
    "\n",
    "dfrel_basis['wt'] = dfrel_basis['signal_file'].str.split('_').apply(lambda x: x[3])\n",
    "\n",
    "for run_num in trange(tot_rns):\n",
    "    dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "    dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "    dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "    dfrel_basis['prc_tot_resid2'] = (dfrel_basis['resid2']/dfrel_basis['resid2'].sum())\n",
    "    dfrel_basis['prc_tot_resid2_wi_trial'] = (dfrel_basis['resid2_wi_trial']/dfrel_basis['resid2_wi_trial'].sum())\n",
    "\n",
    "    df_inspect = dfrel_basis\n",
    "    df_inspect = dfrel_basis[dfrel_basis['resid2'] < 30]\n",
    "    training_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == False]\n",
    "    holdout_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == True]\n",
    "\n",
    "    training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    mean_resids = pd.DataFrame([training_mean_resids.values,\n",
    "                                holdout_mean_resids.values,\n",
    "                                (training_mean_resids.values<holdout_mean_resids.values)*1\n",
    "                                ],\n",
    "                                index=['training', 'holdout', 'correct'],\n",
    "                                columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "    display(mean_resids)\n",
    "    print('tr', len(training_df), 'ho', len(holdout_df))\n",
    "\n",
    "    # resids = mean_resids['resid2_wi_trial'].to_list()\n",
    "\n",
    "    base_resid2_col = 'resid2_wi_trial'\n",
    "\n",
    "    resid_vals = '_'.join(['='.join([str(__) for __ in _]) for _ in list(zip(mean_resids.index, np.round(mean_resids[base_resid2_col], 3)))])\n",
    "\n",
    "    # tmp_df = training_df.copy()\n",
    "    tr_cc = np.arange((~training_df[base_resid2_col].isna()).sum())+1\n",
    "    ho_cc = np.arange((~holdout_df[base_resid2_col].isna()).sum())+1\n",
    "\n",
    "    h = training_df[base_resid2_col].dropna().sort_values(ascending=False).reset_index(drop=True).cumsum().copy()\n",
    "    h2 = holdout_df[base_resid2_col].dropna().sort_values(ascending=False).reset_index(drop=True).cumsum().copy()\n",
    "\n",
    "    h_cummean = h/tr_cc\n",
    "    h2_cummean = h2/ho_cc\n",
    "\n",
    "\n",
    "    start_loc = 0\n",
    "    num_points = -1\n",
    "\n",
    "    fig,ax=plt.subplots(2,5,figsize=(40,10))\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    fig.suptitle(resid_vals)\n",
    "    g1.plot(ax=ax[0,0], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,0], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,0], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,0], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = 0\n",
    "    num_points = 100\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,1], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,1], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,1], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,1], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = min(len(h_cummean), len(h2_cummean))-5000\n",
    "    num_points = 5000\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,2], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,2], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,2], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,2], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = max(len(h_cummean), len(h2_cummean))-5000\n",
    "    num_points = 5000\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,3], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,3], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,3], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,3], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = -5001\n",
    "    num_points = 5000\n",
    "\n",
    "    ga = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    gb = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "\n",
    "    ga.plot(ax=ax[0,4], label=f'training — {len(training_df)}')\n",
    "    gb.plot(ax=ax[0,4], label=f'holdout — {len(holdout_df)}')\n",
    "    ga.diff().plot(ax=ax[1,4], label=f'training — {len(training_df)}')\n",
    "    gb.diff().plot(ax=ax[1,4], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "\n",
    "    ax[0,0].grid(True)\n",
    "    ax[0,0].legend()\n",
    "\n",
    "    ax[1,0].grid(True)\n",
    "    ax[1,0].legend()\n",
    "\n",
    "    ax[0,1].grid(True)\n",
    "    ax[0,1].legend()\n",
    "\n",
    "    ax[1,1].grid(True)\n",
    "    ax[1,1].legend()\n",
    "\n",
    "    ax[0,2].grid(True)\n",
    "    ax[0,2].legend()\n",
    "\n",
    "    ax[1,2].grid(True)\n",
    "    ax[1,2].legend()\n",
    "\n",
    "    ax[0,3].grid(True)\n",
    "    ax[0,3].legend()\n",
    "\n",
    "    ax[1,3].grid(True)\n",
    "    ax[1,3].legend()\n",
    "\n",
    "    ax[0,4].grid(True)\n",
    "    ax[0,4].legend()\n",
    "\n",
    "    ax[1,4].grid(True)\n",
    "    ax[1,4].legend()\n",
    "\n",
    "    # tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "run_num = 3\n",
    "\n",
    "dfrel_basis['wt'] = dfrel_basis['signal_file'].str.split('_').apply(lambda x: x[3])\n",
    "\n",
    "dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "dfrel_basis['prc_tot_resid2'] = (dfrel_basis['resid2']/dfrel_basis['resid2'].sum())\n",
    "dfrel_basis['prc_tot_resid2_wi_trial'] = (dfrel_basis['resid2_wi_trial']/dfrel_basis['resid2_wi_trial'].sum())\n",
    "\n",
    "df_inspect = dfrel_basis\n",
    "training_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == False]\n",
    "holdout_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == True]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "# training_df['prc_tot_resid2'].cumsum().plot(ax=ax)\n",
    "# holdout_df['prc_tot_resid2'].cumsum().plot(ax=ax)\n",
    "\n",
    "training_df.groupby(['wt', 'file_num'])['resid2'].mean().plot(ax=ax, label='training - resid2')\n",
    "holdout_df.groupby(['wt', 'file_num'])['resid2'].mean().plot(ax=ax, label='holdout - resid2')\n",
    "\n",
    "training_df.groupby(['wt', 'file_num'])['resid2_wi_trial'].mean().plot(ax=ax, label='training - wit')\n",
    "holdout_df.groupby(['wt', 'file_num'])['resid2_wi_trial'].mean().plot(ax=ax, label='holdout - wit')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df.groupby(['wt', 'file_num']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['mouse_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_cummean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_cummean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = training_df.copy()\n",
    "tmp_df['1'] = 1\n",
    "h = (tmp_df[['resid2_wi_trial', '1']])#/(tmp_df['resid2_wi_trial'].sum()))\n",
    "# g = h.dropna().sort_values('resid2_wi_trial', ascending=False).cumsum().reset_index(drop=True)\n",
    "g = h.dropna().sort_values('resid2_wi_trial', ascending=False).reset_index(drop=True)\n",
    "# g = g.groupby('1').cumsum()/g.groupby('1').cumcount()\n",
    "# g = g.drop('1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.iloc[:num_points]\n",
    "g.index = g.index/g.index.max()\n",
    "g.plot(ax=ax, label='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df['resid2_wi_trial'].mean(), holdout_df['resid2_wi_trial'].mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2-g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dfrel_basis = dfrel_basis_backup.copy()\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "run_num = 9\n",
    "\n",
    "# for run_num in range(10):\n",
    "dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "\n",
    "\n",
    "dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "# dfrel_basis['resid2_wi_trial_short'] = ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "\n",
    "df_inspect = dfrel_basis\n",
    "# df_inspect = dfrel_basis[~dfrel_basis['file_num'].isin([16, 10, 17, 15, 3, 13, 12, 7])]\n",
    "# df_inspect = hdf[hdf['diffTrialNums'] == 1]\n",
    "# df_inspect = dfrel_basis[dfrel_basis['wi_trial_keep']]\n",
    "\n",
    "training_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == False')\n",
    "holdout_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == True')\n",
    "\n",
    "# print('Num Total', df_inspect.shape[0])\n",
    "# print('Num Holdout', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].sum())\n",
    "# print('Num Nan', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].isna().sum())\n",
    "\n",
    "training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "mean_resids = pd.DataFrame([training_mean_resids.values, holdout_mean_resids.values, (training_mean_resids.values<holdout_mean_resids.values)*1],\n",
    "                           index=['training', 'holdout', 'correct'],\n",
    "                           columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "display(mean_resids)\n",
    "# display('Training', training_df.shape)\n",
    "# display('Holdout', holdout_df.shape)\n",
    "\n",
    "at = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2'].mean().sort_values(ascending=False).head().reset_index()\n",
    "at = at.rename({_:_+'_all_tr' for _ in at.columns}, axis=1)\n",
    "ah = holdout_df.groupby(['file_num', 'nTrial_filenum'])['resid2'].mean().sort_values(ascending=False).head().reset_index()\n",
    "ah = ah.rename({_:_+'_all_ho' for _ in ah.columns}, axis=1)\n",
    "\n",
    "wit = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wit = wit.rename({_:_+'_wi_tr' for _ in wit.columns}, axis=1)\n",
    "wih = holdout_df.groupby(['file_num'])['resid2_wi_trial'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wih = wih.rename({_:_+'_wi_ho' for _ in wih.columns}, axis=1)\n",
    "\n",
    "wits = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial_hard'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wits = wits.rename({_:_+'_wi_tr_hrd' for _ in wits.columns}, axis=1)\n",
    "wihs = holdout_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial_hard'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wihs = wihs.rename({_:_+'_wi_ho_hrd' for _ in wihs.columns}, axis=1)\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_columns', 1000):\n",
    "    display(pd.concat([at, ah, wit, wih, wits, wihs], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inspect[df_inspect['nTrial_filenum'] == 1071]['photometryCenterOutIndex'].plot()\n",
    "b = 'photometrySideOutIndex'\n",
    "a = df_inspect[df_inspect['diffTrialNums'] == 1].groupby('nTrial_filenum')[[b]].sum().sort_values(b, ascending=False).copy()\n",
    "# a\n",
    "a['1'] = 1\n",
    "a.groupby(b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_trial_kwargs = dict(y_col=y_col, pred_col=f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}', holdout_col=f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}', dupe_col='dupe')\n",
    "view_trial(df_inspect, 1071, **view_trial_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf = dfrel_basis.copy()\n",
    "# hdf['nTrial'] = hdf.groupby('file_num')['nTrial'].shift(20)\n",
    "# hdf['nEndTrial'] = hdf.groupby('file_num')['nEndTrial'].shift(-20)\n",
    "# hdf['diffTrialNums'] = hdf['nTrial'] - hdf['nEndTrial']\n",
    "# hdf[hdf['diffTrialNums'] == 1]\n",
    "# ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "# holdout_df.groupby(['nTrial_filenum'])['resid2_wi_trial_short'].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[training_df['has_all_cols']&training_df['wi_trial_keep']].shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((glm.predict(X_train) - y_train)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, training_df[training_df['has_all_cols']&(training_df['wi_trial_keep'])].shape, df_holdout.shape, holdout_df[holdout_df['has_all_cols']&holdout_df['wi_trial_keep']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis_has_all_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr(f'../../data/interim/{data_folder_src}/GLM_SIGNALS_INTERIM_{wt}_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_col_keeps['has_all_cols'][0].sum()\n",
    "\n",
    "dfrel_basis[full_drop_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (~dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'].isna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Training', (~dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum())\n",
    "print('Num Holdouts', (dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum())\n",
    "print('NaN Entries', dfrel_basis['holdout_iXyp=0_irun=0'].isna().sum())\n",
    "\n",
    "print('Total Entries', (~dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum() + (dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum() + dfrel_basis['holdout_iXyp=0_irun=0'].isna().sum())\n",
    "print('Len Entries', len(dfrel_basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(has_all_cols) - has_all_cols.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM_SIGNALS_INTERIM_{wt}_dfrel_ft_setup['nTrial'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial'].nunique()\n",
    "\n",
    "# dfrel_ft_setup['nTrial_filenum'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial_filenum'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial_filenum'].nunique()/dfrel_ft_setup['nTrial_filenum'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfrel_basis_has_all_cols.copy()\n",
    "id_cols=['nTrial_filenum']\n",
    "perc_holdout=pholdout\n",
    "y = None\n",
    "strat_col = None\n",
    "strat_mode = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) > 0\n",
    "\n",
    "for i, idc in enumerate(id_cols):\n",
    "    srs_x_idc_str = X[idc].apply(str)\n",
    "    if i == 0:\n",
    "        bucket_ids = srs_x_idc_str.str.len().apply(str) + ':' + srs_x_idc_str\n",
    "    else:\n",
    "        bucket_ids = bucket_ids + '__' + srs_x_idc_str.str.len().apply(str) + ':' + srs_x_idc_str\n",
    "bucket_ids = bucket_ids.astype(\"category\").cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_ids.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['nTrial_filenum'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(bucket_ids.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_bucket_ids = int(bucket_ids.max() + 1)\n",
    "\n",
    "if strat_col is not None:\n",
    "\n",
    "    strat_df = X[[strat_col]].copy()\n",
    "    strat_df['bucket_id'] = bucket_ids\n",
    "\n",
    "    strat_groups = strat_df[strat_col].unique()\n",
    "    distinct_buckets = [pd.Series(strat_df[strat_df[strat_col] == _]['bucket_id'].unique()) for _ in strat_groups]\n",
    "    bucket_sizes = np.array([len(_) for _ in distinct_buckets])\n",
    "\n",
    "    min_bucket_size = bucket_sizes.min()\n",
    "    bucket_totals = bucket_sizes.sum()\n",
    "\n",
    "    # print(set_sizes)\n",
    "    train_distinct_buckets = []\n",
    "    test_distinct_buckets = []\n",
    "\n",
    "    if strat_mode == 'balanced_train':\n",
    "\n",
    "        num_balanced_train_selection = int(min_bucket_size * (1 - perc_holdout))\n",
    "        for bucket in distinct_buckets:\n",
    "            train_distinct_buckets.append(np.random.choice(bucket, num_balanced_train_selection, replace=False))\n",
    "            test_distinct_buckets.append(bucket[~bucket.isin(train_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    elif strat_mode == 'balanced_test':\n",
    "\n",
    "        num_balanced_test_selection = int(min_bucket_size * perc_holdout)\n",
    "        for bucket in distinct_buckets:\n",
    "            test_distinct_buckets.append(np.random.choice(bucket, num_balanced_test_selection, replace=False))\n",
    "            train_distinct_buckets.append(bucket[~bucket.isin(test_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    elif strat_mode == 'stratify':\n",
    "        for bucket in distinct_buckets:\n",
    "            test_distinct_buckets.append(np.random.choice(bucket, int(len(bucket)*perc_holdout), replace=False))\n",
    "            train_distinct_buckets.append(bucket[~bucket.isin(test_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Invalid strat_mode: {strat_mode}')\n",
    "else:\n",
    "    print('else')\n",
    "    num_buckets_for_test = int(num_bucket_ids * perc_holdout)\n",
    "    test_ids = np.random.choice(num_bucket_ids, size=num_buckets_for_test, replace=False)\n",
    "\n",
    "holdout = bucket_ids.isin(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_buckets_for_test\n",
    "test_ids = np.random.choice(num_bucket_ids, size=num_buckets_for_test, replace=False)\n",
    "len(np.unique(test_ids))\n",
    "bucket_ids[bucket_ids.isin(test_ids)].nunique(), bucket_ids[(~bucket_ids.isin(test_ids))].nunique()\n",
    "5277 + 8069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
