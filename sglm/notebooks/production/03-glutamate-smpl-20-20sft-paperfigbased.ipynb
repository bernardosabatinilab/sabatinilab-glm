{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sglm.models import sglm_cv\n",
    "import itertools\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import setup_model_fit as smf\n",
    "from sglm.models import sglm_cv\n",
    "from sglm import models\n",
    "from sglm.visualization import visualize\n",
    "from sglm.models import train_model\n",
    "from sglm.models import eval\n",
    "from sglm import features\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dfrel_to_ho_set():\n",
    "#     return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from logging.config import _RootLoggerConfiguration\n",
    "\n",
    "def create_folder_if_not_exists(dr):\n",
    "    dr = Path(dr)\n",
    "    constructed_dir = str(Path('/').resolve())\n",
    "    made = False\n",
    "    \n",
    "#     print('constructed_dir', constructed_dir)\n",
    "    for fold in dr.parts:\n",
    "        if len(fold) == 0:\n",
    "            continue\n",
    "        constructed_dir = str((Path(constructed_dir) / fold).resolve())\n",
    "#         print('constructed_dir', constructed_dir)\n",
    "        if os.path.isdir(constructed_dir):\n",
    "            # print(f'Directory already exists:', constructed_dir)\n",
    "            pass\n",
    "        else:\n",
    "            # print(f'Creating directory:', constructed_dir)\n",
    "            os.mkdir(constructed_dir)\n",
    "            made = True\n",
    "    if made:\n",
    "        print(f'Created directory:', constructed_dir)\n",
    "    return\n",
    "\n",
    "# create_folder_if_not_exists((Path.home() / 'Desktop/nada/folder2').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_folders(base_folder, prefix, *args):\n",
    "    for folder in args:\n",
    "        create_folder_if_not_exists(str(Path(base_folder/prefix/folder).resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# From stack overflow\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit)\n",
    "\n",
    "def extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit):\n",
    "    # needed info\n",
    "    # Params: wt_used, signal_files, widest_orders, multifile_fit\n",
    "    # Returns: mouse_names, combo_dfs, combo_fns, X_cols_sftd\n",
    "    \n",
    "    if multifile_fit == 'all':\n",
    "        file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "        print('file_ids', file_ids)\n",
    "        combo_dfs, X_cols_sftd, _ = smf.multi_file_analysis_prep(signal_files, widest_orders, file_ids)\n",
    "        combo_fns = ['_'.join(wt_used).replace('WT', '').replace('S', '')]\n",
    "        mouse_names = combo_fns\n",
    "    elif multifile_fit == 'by_mouse':\n",
    "        combo_dfs = []\n",
    "        X_cols_sftd_lst = []\n",
    "        combo_fns = []\n",
    "        mouse_names_2 = []\n",
    "        for mouse_id in wt_used:\n",
    "            mouse_id_files = [_ for _ in signal_files if mouse_id in _]\n",
    "            file_ids = [Path(_).parts[-1] for _ in mouse_id_files]\n",
    "            mouse_names_2 += [mouse_id]\n",
    "            combo_dfs_tmp, X_cols_sftd_tmp, _ = smf.multi_file_analysis_prep(mouse_id_files, widest_orders, file_ids)\n",
    "            combo_dfs += combo_dfs_tmp\n",
    "            X_cols_sftd_lst.append(X_cols_sftd_tmp)\n",
    "            combo_fns.append(mouse_id)\n",
    "\n",
    "        for xcsl in X_cols_sftd_lst:\n",
    "            if xcsl != X_cols_sftd_lst[0]:\n",
    "                raise ValueError('X_cols_sftd_lst should contain the same elements for every entry')\n",
    "        mouse_names = mouse_names_2\n",
    "\n",
    "        X_cols_sftd = X_cols_sftd_lst[0]\n",
    "\n",
    "    elif multifile_fit == 'single':\n",
    "        file_ids = [Path(_).parts[-1] for _ in signal_files]\n",
    "        combo_dfs, X_cols_sftd, combo_fns = smf.single_file_analysis_prep(signal_files, widest_orders, file_ids)\n",
    "        mouse_names = combo_fns\n",
    "    else:\n",
    "        raise ValueError('multifile_fit must be \"all\", \"single\", or \"by_mouse\"')\n",
    "\n",
    "    return mouse_names, combo_dfs, combo_fns, X_cols_sftd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_rows_with_all_cols(dfrel_basis,\n",
    "                          X_y_pairings,\n",
    "                          X_cols_sftd, \n",
    "                          drop_cols_basis = ['nTrial', 'nTrial_filenum', 'cpn', 'cpx', 'spnnr', 'spxnr', 'spnr', 'spxr',\n",
    "                                             \n",
    "                                             'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "                                             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                                             'photometrySideOutIndex', 'spnnrOff',\n",
    "                                             \n",
    "                                             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                                             'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "                                             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                                             'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "                                             'sl', 'slOff'\n",
    "                                            ]):\n",
    "    full_drop_basis = []\n",
    "    y_col_lst = []\n",
    "    for X_y_dct in X_y_pairings:\n",
    "        full_drop_basis += bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd)\n",
    "        y_col_lst += [X_y_dct['y_col']]\n",
    "    y_col_drop_basis = sorted(list(set(y_col_lst)))\n",
    "    full_drop_basis = sorted(list(set(drop_cols_basis + full_drop_basis + y_col_drop_basis)))\n",
    "\n",
    "    num_cols_na = (dfrel_basis[full_drop_basis].isna().sum(axis=1))\n",
    "    num_y_0 = (dfrel_basis[y_col_drop_basis] == 0).sum(axis=1)\n",
    "    has_all_cols = (num_cols_na == 0)&(num_y_0 == 0)\n",
    "\n",
    "    return has_all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perc_words(signal_df, betas_df, total_col='photometrySideInIndex', words_prefix='photometrySideInIndex', words=['AA', 'Aa', 'aA', 'aa', 'AB', 'Ab', 'aB', 'ab'], perc_suffix='_cnt_tr'):\n",
    "    \n",
    "    tot_trials = signal_df[total_col].sum()\n",
    "    \n",
    "    betas_df[perc_suffix] = tot_trials\n",
    "    betas_df[f'AA{perc_suffix}'] = signal_df[f'{words_prefix}AA'].sum()/tot_trials\n",
    "    betas_df[f'Aa{perc_suffix}'] = signal_df[f'{words_prefix}Aa'].sum()/tot_trials\n",
    "    betas_df[f'aA{perc_suffix}'] = signal_df[f'{words_prefix}aA'].sum()/tot_trials\n",
    "    betas_df[f'aa{perc_suffix}'] = signal_df[f'{words_prefix}aa'].sum()/tot_trials\n",
    "    betas_df[f'AB{perc_suffix}'] = signal_df[f'{words_prefix}AB'].sum()/tot_trials\n",
    "    betas_df[f'Ab{perc_suffix}'] = signal_df[f'{words_prefix}Ab'].sum()/tot_trials\n",
    "    betas_df[f'aB{perc_suffix}'] = signal_df[f'{words_prefix}aB'].sum()/tot_trials\n",
    "    betas_df[f'ab{perc_suffix}'] = signal_df[f'{words_prefix}ab'].sum()/tot_trials\n",
    "    \n",
    "    return betas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = lambda x: str(Path(x).resolve())\n",
    "ps = lambda x: str(Path(x))\n",
    "\n",
    "# base_folder = '/home/josh/github-repos/sabatinilab-glm/sglm/outputs'\n",
    "# base_folder = (Path(r'/Users/Josh/Documents/GitHub/sabatinilab-glm/sglm/outputs').resolve())\n",
    "# base_folder = '/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/outputs2'\n",
    "base_folder = (Path(r'/Users/Josh/Documents/GitHub/sabatinilab-glm/sglm/outputs-old').resolve())\n",
    "base_folder = (Path(base_folder).resolve())\n",
    "\n",
    "all_reconstruct_folder = ps('reconstructs')\n",
    "best_reconstruct_folder = ps('reconstructs')\n",
    "all_coefs_folder = ps('coefs')\n",
    "best_coefs_folder = ps('coefs')\n",
    "mses_folder = ps('mses')\n",
    "\n",
    "neg_order = -20\n",
    "pos_order = 20\n",
    "\n",
    "# neg_order = -20\n",
    "# pos_order = 50\n",
    "\n",
    "# data_folder = 'test'\n",
    "# data_folder = 'Figure_1_2/g1--20_20sft'\n",
    "# data_folder = 'Figure_1_2'\n",
    "# data_folder = 'Figure_3'\n",
    "# data_folder = 'Figure_3-dualhem'\n",
    "# data_folder = 'Figure_4/g1'\n",
    "# data_folder = 'Figure_4/g2'\n",
    "# data_folder = 'Figure_5/g1'\n",
    "# data_folder = 'Figure_5/g2'\n",
    "# data_folder = 'Figure_5/g3'\n",
    "# data_folder = 'Figure_5/g4'\n",
    "# data_folder = 'Figure_5/g5'\n",
    "# data_folder = 'Figure_6/g1'\n",
    "# data_folder = 'Figure_6/g1--20_20sft'\n",
    "\n",
    "\n",
    "# data_folder = 'Figure_1_2/g1--20_20sft'\n",
    "data_folder = 'Figure_7/g1--20_20sft'\n",
    "\n",
    "fix_training = True #False\n",
    "\n",
    "# multifile_fit_list = ['single']\n",
    "# multifile_fit_list = ['by_mouse']\n",
    "multifile_fit_list = ['all']\n",
    "# multifile_fit_list = ['by_mouse', 'all']\n",
    "\n",
    "# base_prefix = f'oall-testhdf-4'\n",
    "# base_prefix = f'oall-testhdf-5-shortkern'\n",
    "# base_prefix = f'new-CO'\n",
    "# base_prefix = f'new-CO-50pholdout'\n",
    "# base_prefix = f'hs2-smpl2-50'\n",
    "# base_prefix = f'glu_run_20220109--20_20sft'\n",
    "\n",
    "base_prefix = f'tet_run_20230403--20_20sft'\n",
    "\n",
    "num_runs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "\n",
    "    log = file if hasattr(file,'write') else sys.stderr\n",
    "    traceback.print_stack(file=log)\n",
    "    log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "\n",
    "warnings.showwarning = warn_with_traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_0-ft\\reconstructs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_0-ft\\coefs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_0-ft\\mses\n",
      "file_ids ['GLM_SIGNALS_INTERIM_S732_06172020.csv', 'GLM_SIGNALS_INTERIM_S732_06212020.csv', 'GLM_SIGNALS_INTERIM_S735_06152020.csv', 'GLM_SIGNALS_INTERIM_S735_06212020.csv', 'GLM_SIGNALS_INTERIM_S736_06172020.csv', 'GLM_SIGNALS_INTERIM_S736_06212020.csv', 'GLM_SIGNALS_INTERIM_S776_06272020.csv', 'GLM_SIGNALS_INTERIM_S776_06292020.csv', 'GLM_SIGNALS_INTERIM_S776_07012020.csv']\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20293930606515867\n",
      "> cv_R2_score: 0.19417328103730414\n",
      "> cv_mean_score: 0.19420023686811771\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.6 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 621.6 MiB\n",
      "                      df_train: 613.1 MiB\n",
      "                     X_holdout: 221.2 MiB\n",
      "                       X_train: 218.1 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "                 dfresids_cols:  320.0 B\n",
      "             kwargs_iterations:  232.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 - Time Passed: 26.256255865097046 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21136304750733567\n",
      "> cv_R2_score: 0.2046096596849466\n",
      "> cv_mean_score: 0.2046547125747637\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.6 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 621.6 MiB\n",
      "                      df_train: 613.1 MiB\n",
      "                     X_holdout: 441.4 MiB\n",
      "                       X_train: 435.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 - Time Passed: 52.280436515808105 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21169757362852143\n",
      "> cv_R2_score: 0.20303416092266569\n",
      "> cv_mean_score: 0.20302491366836956\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.0 MiB\n",
      "                    df_holdout: 614.7 MiB\n",
      "                       X_train: 220.6 MiB\n",
      "                     X_holdout: 218.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__1 - Time Passed: 69.78348064422607 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2224257755176481\n",
      "> cv_R2_score: 0.21011546281883164\n",
      "> cv_mean_score: 0.2101471373847784\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.0 MiB\n",
      "                    df_holdout: 614.7 MiB\n",
      "                       X_train: 440.3 MiB\n",
      "                     X_holdout: 436.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__1 - Time Passed: 96.42190313339233 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20594350909281545\n",
      "> cv_R2_score: 0.20299760426809876\n",
      "> cv_mean_score: 0.20284793000705797\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 618.9 MiB\n",
      "                      df_train: 615.8 MiB\n",
      "                     X_holdout: 220.2 MiB\n",
      "                       X_train: 219.1 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__2 - Time Passed: 113.86932229995728 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21534095523410574\n",
      "> cv_R2_score: 0.20681273752763718\n",
      "> cv_mean_score: 0.20671141606356674\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 618.9 MiB\n",
      "                      df_train: 615.8 MiB\n",
      "                     X_holdout: 439.5 MiB\n",
      "                       X_train: 437.3 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__2 - Time Passed: 139.81442308425903 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2095181844716471\n",
      "> cv_R2_score: 0.20836202396188352\n",
      "> cv_mean_score: 0.20831415294602323\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.2 MiB\n",
      "                    df_holdout: 614.6 MiB\n",
      "                       X_train: 220.6 MiB\n",
      "                     X_holdout: 218.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__3 - Time Passed: 157.18637681007385 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.22195778796639312\n",
      "> cv_R2_score: 0.20988102863808522\n",
      "> cv_mean_score: 0.20972796342815977\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.2 MiB\n",
      "                    df_holdout: 614.6 MiB\n",
      "                       X_train: 440.4 MiB\n",
      "                     X_holdout: 436.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__3 - Time Passed: 183.21493363380432 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20622874257150564\n",
      "> cv_R2_score: 0.20241932255501138\n",
      "> cv_mean_score: 0.2024313470942453\n",
      "Running multi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.5 MiB\n",
      "                    df_holdout: 614.2 MiB\n",
      "                       X_train: 220.8 MiB\n",
      "                     X_holdout: 218.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__4 - Time Passed: 200.6250684261322 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21769502921266776\n",
      "> cv_R2_score: 0.20071556911173816\n",
      "> cv_mean_score: 0.20064027044063382\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 620.5 MiB\n",
      "                    df_holdout: 614.2 MiB\n",
      "                       X_train: 440.7 MiB\n",
      "                     X_holdout: 436.2 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__4 - Time Passed: 227.51767802238464 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2044871524644835\n",
      "> cv_R2_score: 0.1988946618326296\n",
      "> cv_mean_score: 0.19882098006687263\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 619.1 MiB\n",
      "                    df_holdout: 615.6 MiB\n",
      "                       X_train: 220.3 MiB\n",
      "                     X_holdout: 219.0 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__5 - Time Passed: 245.32374238967896 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21450094922212176\n",
      "> cv_R2_score: 0.20614578224764102\n",
      "> cv_mean_score: 0.2059661134288037\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 619.1 MiB\n",
      "                    df_holdout: 615.6 MiB\n",
      "                       X_train: 439.6 MiB\n",
      "                     X_holdout: 437.2 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__5 - Time Passed: 271.6850483417511 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2143008442051874\n",
      "> cv_R2_score: 0.20854238051396268\n",
      "> cv_mean_score: 0.20841656254618054\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.8 MiB\n",
      "                    df_holdout: 612.0 MiB\n",
      "                       X_train: 221.6 MiB\n",
      "                     X_holdout: 217.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__6 - Time Passed: 289.0062475204468 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.22515797019772582\n",
      "> cv_R2_score: 0.2111128983932652\n",
      "> cv_mean_score: 0.21106366100194301\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.8 MiB\n",
      "                    df_holdout: 612.0 MiB\n",
      "                       X_train: 442.2 MiB\n",
      "                     X_holdout: 434.6 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__6 - Time Passed: 315.271368265152 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2098113494532455\n",
      "> cv_R2_score: 0.2077001724430131\n",
      "> cv_mean_score: 0.20767213588336503\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 619.0 MiB\n",
      "                      df_train: 615.7 MiB\n",
      "                     X_holdout: 220.2 MiB\n",
      "                       X_train: 219.1 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__7 - Time Passed: 332.4740147590637 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multiRunning multi\n",
      "\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.22376951790674565\n",
      "> cv_R2_score: 0.21333642726315416\n",
      "> cv_mean_score: 0.21334241623316977\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 619.0 MiB\n",
      "                      df_train: 615.7 MiB\n",
      "                     X_holdout: 439.6 MiB\n",
      "                       X_train: 437.2 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__7 - Time Passed: 358.3538963794708 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20927526025189938\n",
      "> cv_R2_score: 0.20511407320035258\n",
      "> cv_mean_score: 0.20508327438426383\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.5 MiB\n",
      "                    df_holdout: 612.2 MiB\n",
      "                       X_train: 221.5 MiB\n",
      "                     X_holdout: 217.8 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__8 - Time Passed: 376.00687885284424 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.21979175474040824\n",
      "> cv_R2_score: 0.2086003025193971\n",
      "> cv_mean_score: 0.2086348857632898\n",
      "Running multi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.5 MiB\n",
      "                    df_holdout: 612.2 MiB\n",
      "                       X_train: 442.1 MiB\n",
      "                     X_holdout: 434.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__8 - Time Passed: 403.04290556907654 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.20896801323973474\n",
      "> cv_R2_score: 0.19688036345620852\n",
      "> cv_mean_score: 0.19687690703800328\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 618.2 MiB\n",
      "                    df_holdout: 616.6 MiB\n",
      "                       X_train: 219.9 MiB\n",
      "                     X_holdout: 219.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__9 - Time Passed: 420.6589994430542 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2192595617444258\n",
      "> cv_R2_score: 0.20987266721848086\n",
      "> cv_mean_score: 0.20983733257596282\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 618.2 MiB\n",
      "                    df_holdout: 616.6 MiB\n",
      "                       X_train: 439.0 MiB\n",
      "                     X_holdout: 437.8 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_0 gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__9 - Time Passed: 447.4013783931732 s\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_1-ft\\reconstructs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_1-ft\\coefs\n",
      "Created directory: C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old\\Figure_7_g1--20_20sft\\all\\tet_run_20230403--20_20sft_1-ft\\mses\n",
      "file_ids ['GLM_SIGNALS_INTERIM_S732_06172020.csv', 'GLM_SIGNALS_INTERIM_S732_06212020.csv', 'GLM_SIGNALS_INTERIM_S735_06152020.csv', 'GLM_SIGNALS_INTERIM_S735_06212020.csv', 'GLM_SIGNALS_INTERIM_S736_06172020.csv', 'GLM_SIGNALS_INTERIM_S736_06212020.csv', 'GLM_SIGNALS_INTERIM_S776_06272020.csv', 'GLM_SIGNALS_INTERIM_S776_06292020.csv', 'GLM_SIGNALS_INTERIM_S776_07012020.csv']\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2669502773564279\n",
      "> cv_R2_score: 0.26297103620887163\n",
      "> cv_mean_score: 0.2627738079147343\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.6 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 620.0 MiB\n",
      "                      df_train: 614.7 MiB\n",
      "                     X_holdout: 220.6 MiB\n",
      "                       X_train: 218.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "                 dfresids_cols:  320.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 - Time Passed: 477.24319076538086 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2800505278780202\n",
      "> cv_R2_score: 0.2760212509592417\n",
      "> cv_mean_score: 0.27606003364972986\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.6 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 620.0 MiB\n",
      "                      df_train: 614.7 MiB\n",
      "                     X_holdout: 440.3 MiB\n",
      "                       X_train: 436.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 - Time Passed: 503.35275983810425 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26933210158199616\n",
      "> cv_R2_score: 0.2667362414336778\n",
      "> cv_mean_score: 0.2667454970116756\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 618.2 MiB\n",
      "                    df_holdout: 616.5 MiB\n",
      "                       X_train: 219.9 MiB\n",
      "                     X_holdout: 219.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__1 - Time Passed: 520.6960518360138 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2840109025007734\n",
      "> cv_R2_score: 0.27090672728686427\n",
      "> cv_mean_score: 0.27076680337667475\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 618.2 MiB\n",
      "                    df_holdout: 616.5 MiB\n",
      "                       X_train: 439.0 MiB\n",
      "                     X_holdout: 437.8 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  408.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__1 - Time Passed: 547.1270053386688 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.255042967024922\n",
      "> cv_R2_score: 0.2537406163812399\n",
      "> cv_mean_score: 0.2535901921896314\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.7 MiB\n",
      "                    df_holdout: 612.1 MiB\n",
      "                       X_train: 221.5 MiB\n",
      "                     X_holdout: 217.8 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__2 - Time Passed: 564.4697754383087 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2687069868765833\n",
      "> cv_R2_score: 0.2618952033569435\n",
      "> cv_mean_score: 0.2617300557877892\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.7 MiB\n",
      "                    df_holdout: 612.1 MiB\n",
      "                       X_train: 442.2 MiB\n",
      "                     X_holdout: 434.6 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__2 - Time Passed: 590.5202441215515 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2685980816142965\n",
      "> cv_R2_score: 0.26783283436417005\n",
      "> cv_mean_score: 0.2678200661107649\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 617.9 MiB\n",
      "                    df_holdout: 616.8 MiB\n",
      "                       X_train: 219.8 MiB\n",
      "                     X_holdout: 219.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__3 - Time Passed: 607.5466537475586 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "Multirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2837676577983726\n",
      "> cv_R2_score: 0.2741756545846672\n",
      "> cv_mean_score: 0.274128209736415\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 617.9 MiB\n",
      "                    df_holdout: 616.8 MiB\n",
      "                       X_train: 438.8 MiB\n",
      "                     X_holdout: 438.0 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  504.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__3 - Time Passed: 633.2198886871338 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2624916717927766\n",
      "> cv_R2_score: 0.253001017711206\n",
      "> cv_mean_score: 0.2529781478300455\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 621.2 MiB\n",
      "                      df_train: 613.5 MiB\n",
      "                     X_holdout: 221.0 MiB\n",
      "                       X_train: 218.3 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__4 - Time Passed: 650.5239424705505 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2757391985681237\n",
      "> cv_R2_score: 0.26258486137296766\n",
      "> cv_mean_score: 0.2625127483861941\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 621.2 MiB\n",
      "                      df_train: 613.5 MiB\n",
      "                     X_holdout: 441.1 MiB\n",
      "                       X_train: 435.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__4 - Time Passed: 676.7275502681732 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.25372362061847864\n",
      "> cv_R2_score: 0.25337898908959267\n",
      "> cv_mean_score: 0.2534262709929751\n",
      "Running multi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 617.8 MiB\n",
      "                    df_holdout: 616.9 MiB\n",
      "                       X_train: 219.8 MiB\n",
      "                     X_holdout: 219.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__5 - Time Passed: 694.1800904273987 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26701450459114356\n",
      "> cv_R2_score: 0.2594185876182783\n",
      "> cv_mean_score: 0.2595884391590961\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 617.8 MiB\n",
      "                    df_holdout: 616.9 MiB\n",
      "                       X_train: 438.7 MiB\n",
      "                     X_holdout: 438.1 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                 dfresids_cols:  600.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__5 - Time Passed: 720.8197164535522 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2577862181104498\n",
      "> cv_R2_score: 0.25587935671103\n",
      "> cv_mean_score: 0.2559336040205879\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.4 MiB\n",
      "                    df_holdout: 612.3 MiB\n",
      "                       X_train: 221.4 MiB\n",
      "                     X_holdout: 217.9 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__6 - Time Passed: 738.2726964950562 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26924092532449634\n",
      "> cv_R2_score: 0.26918008095086143\n",
      "> cv_mean_score: 0.26918946428559687\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.7 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                      df_train: 622.4 MiB\n",
      "                    df_holdout: 612.3 MiB\n",
      "                       X_train: 442.0 MiB\n",
      "                     X_holdout: 434.8 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__6 - Time Passed: 764.9316787719727 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26164826919412765\n",
      "> cv_R2_score: 0.2529934093853363\n",
      "> cv_mean_score: 0.2530280842444845\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 620.6 MiB\n",
      "                      df_train: 614.2 MiB\n",
      "                     X_holdout: 220.8 MiB\n",
      "                       X_train: 218.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__7 - Time Passed: 782.1973371505737 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.27249262083484443\n",
      "> cv_R2_score: 0.2706737266670113\n",
      "> cv_mean_score: 0.27063137938458504\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 620.6 MiB\n",
      "                      df_train: 614.2 MiB\n",
      "                     X_holdout: 440.7 MiB\n",
      "                       X_train: 436.1 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  696.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__7 - Time Passed: 808.5967681407928 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26572293728570406\n",
      "> cv_R2_score: 0.2599869446015869\n",
      "> cv_mean_score: 0.2600469372940853\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 622.9 MiB\n",
      "                      df_train: 611.8 MiB\n",
      "                     X_holdout: 221.6 MiB\n",
      "                       X_train: 217.7 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__8 - Time Passed: 826.1783769130707 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2764525938148479\n",
      "> cv_R2_score: 0.27441857378462076\n",
      "> cv_mean_score: 0.27423497589692325\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 622.9 MiB\n",
      "                      df_train: 611.8 MiB\n",
      "                     X_holdout: 442.3 MiB\n",
      "                       X_train: 434.5 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__8 - Time Passed: 852.8872699737549 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completed\n",
      "\n",
      "Multirun queue completed\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.26131927883434203\n",
      "> cv_R2_score: 0.2587538750708397\n",
      "> cv_mean_score: 0.2587673011112188\n",
      "Running multi\n",
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 618.1 MiB\n",
      "                      df_train: 616.7 MiB\n",
      "                     X_holdout: 219.9 MiB\n",
      "                       X_train: 219.4 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                      betas_df:  6.1 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                        X_cols:  2.0 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__9 - Time Passed: 870.3879370689392 s\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Running multi\n",
      "Multirun queue completedMultirun queue completedMultirun queue completed\n",
      "\n",
      "\n",
      "{'max_iter': 10000, 'fit_intercept': False, 'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "> cv_mean_score_train: 0.2753583683582533\n",
      "> cv_R2_score: 0.2620387755273531\n",
      "> cv_mean_score: 0.261924741858243\n",
      "Running multi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multirun queue completed\n",
      "Variable Sizes:\n",
      "                   dfrel_basis:  1.8 GiB\n",
      "      dfrel_basis_has_all_cols:  1.6 GiB\n",
      "                    df_holdout: 618.1 MiB\n",
      "                      df_train: 616.7 MiB\n",
      "                     X_holdout: 438.9 MiB\n",
      "                       X_train: 437.9 MiB\n",
      "                       holdout:  2.7 MiB\n",
      "                     y_holdout:  1.8 MiB\n",
      "                       y_train:  1.8 MiB\n",
      "                  has_all_cols: 309.6 KiB\n",
      "                          _i13: 21.6 KiB\n",
      "                   X_cols_sftd:  4.6 KiB\n",
      "                      betas_df:  4.2 KiB\n",
      "                        X_cols:  4.1 KiB\n",
      "                           _i8:  1.9 KiB\n",
      "                           _i9:  1.7 KiB\n",
      "                           _ii:  1.7 KiB\n",
      "                          _i11:  1.7 KiB\n",
      "                          HTML:  1.0 KiB\n",
      "                          _iii: 1023.0 B\n",
      "                          _i10: 1023.0 B\n",
      "                          Path:  904.0 B\n",
      "                           _i5:  897.0 B\n",
      "                 dfresids_cols:  824.0 B\n",
      "                 widest_orders:  640.0 B\n",
      "                           _i3:  613.0 B\n",
      "                            _i:  395.0 B\n",
      "                           _i7:  395.0 B\n",
      "                          _i12:  395.0 B\n",
      "                     dfrr_cols:  344.0 B\n",
      "run_id, subrun_id 732_735_736_776_1 gDAt_1_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__9 - Time Passed: 896.9254724979401 s\n"
     ]
    }
   ],
   "source": [
    "# def func_for_cprofile():\n",
    "ft_str = '-ft' if fix_training else ''\n",
    "\n",
    "if data_folder == 'test':\n",
    "    wt_used = [\n",
    "        'WT63', 'WT64', 'WT53', 'WT69'\n",
    "    ]\n",
    "\n",
    "# elif data_folder == 'Figure_1_2':\n",
    "elif data_folder == 'Figure_1_2/g1--20_20sft':\n",
    "\n",
    "    wt_used = [\n",
    "               'WT63', 'WT64', 'WT65', 'WT66', 'WT67', 'WT68', 'WT69', # DA\n",
    "               'WT57', 'WT58', 'WT59', 'WT60', 'WT61', 'WT53', 'WT55', 'WT56' # ACH\n",
    "               ]\n",
    "\n",
    "elif data_folder == 'Figure_3':\n",
    "    wt_used = ['WT61', 'WT63', 'WT64', 'WT44', 'WT51']\n",
    "elif data_folder == 'Figure_3-dualhem':\n",
    "    wt_used = ['WT63', 'WT64', 'WT65']\n",
    "\n",
    "elif data_folder == 'Figure_4/g1':\n",
    "    wt_used = ['S1233', 'S1234', 'S1260', 'S1246', 'S1248']\n",
    "elif data_folder == 'Figure_4/g2':\n",
    "    wt_used = ['S1194', 'S1195', 'S1214', 'S1258', 'S1259']\n",
    "\n",
    "elif data_folder == 'Figure_5/g1': # Drd2f/f control: S1417, 1419, 1421\n",
    "    # wt_used = ['S1417', 'S1419', 'S1421']\n",
    "    wt_used = ['S1417', 'S1419', 'S1421', 'S1460', 'S1462', 'S1473', 'S1474']\n",
    "elif data_folder == 'Figure_5/g2': # Chat Cre X Drd2f/f : S1416, 1418, 1420, 1422\n",
    "    # wt_used = ['S1416', 'S1418', 'S1420', 'S1422']\n",
    "    wt_used = ['S1416', 'S1418', 'S1420', 'S1459', 'S1461', 'S1470', 'S1471', 'S1472']\n",
    "elif data_folder == 'Figure_5/g3': # Chat Cre control: S1355-1358, S1374, S1376\n",
    "    # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376']\n",
    "    wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "               'S1448', 'S1449', 'S1450', 'S1451']\n",
    "elif data_folder == 'Figure_5/g4': # Chat Cre control: S1399-1401\n",
    "    # wt_used = ['S1399', 'S1400', 'S1401']\n",
    "    wt_used = ['S1399', 'S1400', 'S1401']\n",
    "elif data_folder == 'Figure_5/g5':\n",
    "    # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376', 'S1399', 'S1400', 'S1401']\n",
    "    wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "               'S1448', 'S1449', 'S1450', 'S1451'\n",
    "               'S1399', 'S1400', 'S1401']\n",
    "elif data_folder == 'Figure_5/g6':\n",
    "    wt_used = []\n",
    "elif 'Figure_6/g1' in data_folder:\n",
    "    wt_used = ['S1299', 'S1300', 'S1301', 'S1302']\n",
    "elif 'Figure_7/g1--20_20sft' in data_folder:\n",
    "    wt_used = ['S732', 'S735', 'S736', 'S776',]\n",
    "else:\n",
    "    raise ValueError('Unimplemented figure values.')\n",
    "\n",
    "data_folder_src = data_folder if data_folder != 'test' else 'Figure_1_2'\n",
    "data_folder_join = '_'.join(Path(data_folder).parts)\n",
    "\n",
    "\n",
    "### Backwards Selection\n",
    "X_y_pairings_lst = []\n",
    "\n",
    "# X_y_pairings_lst += [[\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "# #                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndex':(0,0),\n",
    "#                 'photometrySideInIndexr':(0,0),                \n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gGLUr',\n",
    "#      'name': 'base_simple'\n",
    "#      },\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "# #                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndexAA':(0,0),\n",
    "#                 'photometrySideInIndexAa':(0,0),\n",
    "#                 'photometrySideInIndexaA':(0,0),\n",
    "#                 'photometrySideInIndexaa':(0,0),\n",
    "#                 'photometrySideInIndexAB':(0,0),\n",
    "#                 'photometrySideInIndexAb':(0,0),\n",
    "#                 'photometrySideInIndexaB':(0,0),\n",
    "#                 'photometrySideInIndexab':(0,0),\n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gGLUr',\n",
    "#      'name': 'base_words'},\n",
    "\n",
    "# ]]\n",
    "\n",
    "# X_y_pairings_lst += [[\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "#                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndex':(0,0),\n",
    "#                 'photometrySideInIndexr':(0,0),                \n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gACH',\n",
    "#      'name': 'base_simple'\n",
    "#      },\n",
    "# #     {'X_cols': {\n",
    "# #                 'photometryCenterInIndex':(0,0),\n",
    "# #                 'photometryCenterOutIndex':(0,0),\n",
    "# #                 'photometrySideInIndexAA':(0,0),\n",
    "# #                 'photometrySideInIndexAa':(0,0),\n",
    "# #                 'photometrySideInIndexaA':(0,0),\n",
    "# #                 'photometrySideInIndexaa':(0,0),\n",
    "# #                 'photometrySideInIndexAB':(0,0),\n",
    "# #                 'photometrySideInIndexAb':(0,0),\n",
    "# #                 'photometrySideInIndexaB':(0,0),\n",
    "# #                 'photometrySideInIndexab':(0,0),\n",
    "# #                 'photometrySideOutIndex':(0,0),\n",
    "# #                 'sl': (0,0),\n",
    "# #                 'spnnrOff': (0,0),\n",
    "# #                },\n",
    "# #      'y_col': 'gACH',\n",
    "# #      'name': 'base_words'},\n",
    "\n",
    "# ]]\n",
    "\n",
    "# X_y_pairings_lst += [[\n",
    "\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "#                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndex':(0,0),\n",
    "#                 'photometrySideInIndexr':(0,0),                \n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'rDA',\n",
    "#      'name': 'base_simple'\n",
    "#      },\n",
    "# #     {'X_cols': {\n",
    "# #                 'photometryCenterInIndex':(0,0),\n",
    "# #                 'photometryCenterOutIndex':(0,0),\n",
    "# #                 'photometrySideInIndexAA':(0,0),\n",
    "# #                 'photometrySideInIndexAa':(0,0),\n",
    "# #                 'photometrySideInIndexaA':(0,0),\n",
    "# #                 'photometrySideInIndexaa':(0,0),\n",
    "# #                 'photometrySideInIndexAB':(0,0),\n",
    "# #                 'photometrySideInIndexAb':(0,0),\n",
    "# #                 'photometrySideInIndexaB':(0,0),\n",
    "# #                 'photometrySideInIndexab':(0,0),\n",
    "# #                 'photometrySideOutIndex':(0,0),\n",
    "# #                 'sl': (0,0),\n",
    "# #                 'spnnrOff': (0,0),\n",
    "# #                },\n",
    "# #      'y_col': 'rDA',\n",
    "# #      'name': 'base_words'},\n",
    "\n",
    "# ]]\n",
    "\n",
    "# X_y_pairings_lst += [[\n",
    "\n",
    "#     {'X_cols': {\n",
    "#                 'photometryCenterInIndex':(0,0),\n",
    "#                 'photometryCenterOutIndex':(0,0),\n",
    "#                 'photometrySideInIndex':(0,0),\n",
    "#                 'photometrySideInIndexr':(0,0),                \n",
    "#                 'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "#                 'spnnrOff': (0,0),\n",
    "#                },\n",
    "#      'y_col': 'gDA',\n",
    "#      'name': 'base_simple'\n",
    "#      },\n",
    "# #     {'X_cols': {\n",
    "# #                 'photometryCenterInIndex':(0,0),\n",
    "# #                 'photometryCenterOutIndex':(0,0),\n",
    "# #                 'photometrySideInIndexAA':(0,0),\n",
    "# #                 'photometrySideInIndexAa':(0,0),\n",
    "# #                 'photometrySideInIndexaA':(0,0),\n",
    "# #                 'photometrySideInIndexaa':(0,0),\n",
    "# #                 'photometrySideInIndexAB':(0,0),\n",
    "# #                 'photometrySideInIndexAb':(0,0),\n",
    "# #                 'photometrySideInIndexaB':(0,0),\n",
    "# #                 'photometrySideInIndexab':(0,0),\n",
    "# #                 'photometrySideOutIndex':(0,0),\n",
    "# #                 'sl': (0,0),\n",
    "# #                 'spnnrOff': (0,0),\n",
    "# #                },\n",
    "# #      'y_col': 'gDA',\n",
    "# #      'name': 'base_words'},\n",
    "\n",
    "# ]]\n",
    "\n",
    "X_y_pairings_lst += [[\n",
    "\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),                \n",
    "                'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDAc',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDAc',\n",
    "     'name': 'base_words'},\n",
    "\n",
    "]]\n",
    "\n",
    "X_y_pairings_lst += [[\n",
    "\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndex':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),                \n",
    "                'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDAt',\n",
    "     'name': 'base_simple'\n",
    "     },\n",
    "    {'X_cols': {\n",
    "                'photometryCenterInIndex':(0,0),\n",
    "                'photometryCenterOutIndex':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                'photometrySideOutIndex':(0,0),\n",
    "#                 'sl': (0,0),\n",
    "                'spnnrOff': (0,0),\n",
    "               },\n",
    "     'y_col': 'gDAt',\n",
    "     'name': 'base_words'},\n",
    "\n",
    "]]\n",
    "\n",
    "\n",
    "plot_width = 2\n",
    "max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "plot_rows_lst = [_//plot_width + (_%plot_width > 0)*1 for _ in max_cols_len_lst]\n",
    "\n",
    "\n",
    "dfrr_cols = ['signal_file', 'file_num', 'nTrial', 'nTrial_filenum', 'nEndTrial', 'wi_trial_keep',\n",
    "             'nTrial_hard', 'nEndTrial_hard', 'diffTrialNums_hard', 'wi_trial_keep_hard',\n",
    "             'has_all_cols', 'gDA', 'gACH', 'rDA', 'gDAc', 'gDAt', #'gGLUr', 'gGLUl',\n",
    "             'diffTrialNums', 'dupe',\n",
    "             'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "             'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "             'photometrySideOutIndex', 'spnnrOff', 'sl',\n",
    "\n",
    "             'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "             'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "             'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "             'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "]\n",
    "\n",
    "score_method = 'r2'\n",
    "\n",
    "# Select hyper parameters for GLM to use for model selection\n",
    "# Step 1: Create a dictionary of lists for these relevant keywords...\n",
    "kwargs_iterations = {\n",
    "    # 'alpha': [0],\n",
    "    # 'l1_ratio': [0],\n",
    "\n",
    "#     'alpha': [0.0, 0.01, 0.1, 1.0],\n",
    "#     'l1_ratio': [0.0, 0.01, 0.1, 1.0],\n",
    "#     'alpha': [0.0, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0],\n",
    "    'alpha': [0.0],\n",
    "    'l1_ratio': [0.0],\n",
    "}\n",
    "\n",
    "# Step 2: Create a dictionary for the fixed keyword arguments that do not require iteration...\n",
    "kwargs_fixed = {\n",
    "    'max_iter': 10000,\n",
    "    'fit_intercept': False\n",
    "}\n",
    "\n",
    "folds = 10\n",
    "pholdout = 0.5\n",
    "pgss = 0.2\n",
    "\n",
    "# Step 3: Generate iterable list of keyword sets for possible combinations\n",
    "glm_kwarg_lst = sglm_cv.generate_mult_params(kwargs_iterations, kwargs_fixed)\n",
    "\n",
    "\n",
    "multi_start = time.time()\n",
    "for iXyp, X_y_pairings in enumerate(X_y_pairings_lst):\n",
    "\n",
    "    widest_orders = smf.xy_pairs_to_widest_orders([{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "                                                    'y_col': _['y_col']} for _ in X_y_pairings])\n",
    "    max_cols_len = max_cols_len_lst[iXyp]\n",
    "    plot_rows = plot_rows_lst[iXyp]\n",
    "\n",
    "    for multifile_fit in multifile_fit_list:\n",
    "        prefix = f'{data_folder_join}/{multifile_fit}/{base_prefix}_{iXyp}{ft_str}'\n",
    "        create_all_folders(base_folder, prefix,\n",
    "                        all_reconstruct_folder,\n",
    "                        best_reconstruct_folder,\n",
    "                        all_coefs_folder,\n",
    "                        best_coefs_folder,\n",
    "                        mses_folder)\n",
    "\n",
    "        # Load Signal Data\n",
    "        signal_files = []\n",
    "        mouse_names = []\n",
    "        for wt in wt_used:\n",
    "            addl_sig_files = glob.glob(pr(f'../../data/interim-old/{data_folder_src}/GLM_SIGNALS_INTERIM_{wt}_*'))\n",
    "            signal_files += addl_sig_files\n",
    "            mouse_names += [wt] * len(addl_sig_files)\n",
    "\n",
    "        mouse_names, combo_dfs, combo_fns, X_cols_sftd = extract_multifiles(wt_used, signal_files, widest_orders, multifile_fit)\n",
    "\n",
    "        start = time.time()\n",
    "        results_dict = {}\n",
    "\n",
    "        for file_num in range(len(combo_fns)):\n",
    "            # Load Table Data\n",
    "            dfrel_basis = combo_dfs[file_num].reset_index(drop=False).copy()\n",
    "            \n",
    "            dfrel_basis['nTrial_hard'] = dfrel_basis.groupby('file_num')['nTrial'].shift(20)\n",
    "            dfrel_basis['nEndTrial_hard'] = dfrel_basis.groupby('file_num')['nEndTrial'].shift(-20)\n",
    "            dfrel_basis['diffTrialNums_hard'] = dfrel_basis['nTrial_hard'] - dfrel_basis['nEndTrial_hard']\n",
    "            dfrel_basis['wi_trial_keep_hard'] = (dfrel_basis['diffTrialNums_hard'] == 1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            fn = Path(combo_fns[file_num].split('.')[0]).parts[-1]\n",
    "            mouse_id = mouse_names[file_num]\n",
    "            dfresids_cols = np.copy(dfrr_cols).tolist()\n",
    "            run_id = f'{fn}_{iXyp}'            \n",
    "\n",
    "            has_all_cols = id_rows_with_all_cols(dfrel_basis, X_y_pairings, X_cols_sftd)\n",
    "            if has_all_cols.sum() == 0:\n",
    "                print(f'No datapoints found for non-NaN dropcols & non-zero ycols for fixed_training: {prefix}_{fn}')\n",
    "                continue\n",
    "            \n",
    "            dfrel_basis['has_all_cols'] = has_all_cols\n",
    "            dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_{run_id}.h5'), key='dfrel_basis', index=True,)\n",
    "            \n",
    "            dfrel_basis_has_all_cols = dfrel_basis[has_all_cols]\n",
    "\n",
    "            for irun in range(num_runs):\n",
    "                holdout = models.split_data.holdout_split_by_trial_id(dfrel_basis_has_all_cols,\n",
    "                                                                    id_cols=['nTrial_filenum'],\n",
    "                                                                    perc_holdout=pholdout)\n",
    "                dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'] = holdout\n",
    "                dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'].astype(float)\n",
    "\n",
    "                for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "\n",
    "                    for glm_kwargs in glm_kwarg_lst:\n",
    "                        print(glm_kwargs)\n",
    "                        hyp_str = '__'.join([''.join([str(__) for __ in _]) for _ in glm_kwargs.items()]).replace('.', '____')\n",
    "                        \n",
    "\n",
    "                        X_cols = bf.col_shift_bounds_dict_to_col_list(X_y_dct['X_cols'], X_cols_sftd)\n",
    "                        y_col = X_y_dct['y_col']\n",
    "                        name = X_y_dct['name']\n",
    "                        \n",
    "                        subrun_id = f'{y_col}_{iXyp}_{iXyd}_{name}_{hyp_str}_run_num__{irun}'\n",
    "    #                     pred_col_name = f'y={y_col}_irun={irun}_iXyd={iXyd}_name={name}'\n",
    "\n",
    "                        pred_col_name = subrun_id\n",
    "\n",
    "\n",
    "                        if not fix_training:\n",
    "                            holdout = models.split_data.holdout_split_by_trial_id(dfrel_basis_has_all_cols, id_cols=['nTrial_filenum'], perc_holdout=pholdout)\n",
    "    #                         dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'] = holdout\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = holdout\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = dfrel_basis[f'holdout_{pred_col_name}'].astype(float)\n",
    "                        else:\n",
    "    #                         dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}']\n",
    "                            dfrel_basis[f'holdout_{pred_col_name}'] = dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}'].astype(float)\n",
    "                            \n",
    "                        if (~dfrel_basis[f'holdout_{pred_col_name}'].isna()).sum() == 0:\n",
    "                            print(f'No datapoints found for non-NaN dropcols & non-zero ycols for run id: {run_id}, {subrun_id}.')\n",
    "                            continue\n",
    "\n",
    "                        df_train = dfrel_basis_has_all_cols[(~holdout)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "                        df_holdout = dfrel_basis_has_all_cols[(holdout)&(dfrel_basis_has_all_cols['wi_trial_keep'])]\n",
    "\n",
    "                        #TODO: JZ - CHANGE BACK TO WI_TRIAL_KEEP    \n",
    "                        # df_train = dfrel_basis_has_all_cols[(~holdout)&(dfrel_basis_has_all_cols['wi_trial_keep_hard'])]\n",
    "                        # df_holdout = dfrel_basis_has_all_cols[(holdout)&(dfrel_basis_has_all_cols['wi_trial_keep_hard'])]\n",
    "                        \n",
    "                        X_train, y_train, X_holdout, y_holdout = df_train[X_cols], df_train[y_col], df_holdout[X_cols], df_holdout[y_col]\n",
    "\n",
    "                        kfold_cv_idx = models.split_data.cv_idx_by_trial_id(df_train, trial_id_columns=['nTrial_filenum'], num_folds=folds, test_size=pgss)\n",
    "                        \n",
    "                        # best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_train, y_train, kfold_cv_idx, glm_kwarg_lst, model_type='Normal',\n",
    "                        #                                                                                             verbose=0, score_method=score_method)\n",
    "                        best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_train, y_train, kfold_cv_idx, [glm_kwargs], model_type='Normal',\n",
    "                                                                                                                    verbose=0, score_method=score_method)\n",
    "                        \n",
    "\n",
    "                        print('Variable Sizes:')\n",
    "                        for vname, size in sorted(((vname, sys.getsizeof(value)) for vname, value in locals().items()),\n",
    "                                                key= lambda x: -x[1])[:30]:\n",
    "                            print(\"{:>30}: {:>8}\".format(vname, sizeof_fmt(size)))\n",
    "\n",
    "                        glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_train, y_train, X_holdout, y_holdout, best_params)\n",
    "\n",
    "                        betas_df = pd.DataFrame(np.concatenate([np.array([glm.intercept_]), glm.coef_], axis=0).reshape(1,-1),\n",
    "                                    index=[run_id], columns=['int']+X_cols)\n",
    "                        betas_df['mouse_id'] = mouse_id\n",
    "                        betas_df['channel_name'] = f'{y_col}_{iXyd}_run_num={irun}'\n",
    "                        betas_df['name'] = name\n",
    "\n",
    "                        # Only get R^2 values if only a single model fit\n",
    "                        assert len(cv_results['full_cv_results']) == 1\n",
    "                        # TODO: JZ -- IMPLEMENT VERSION FOR MULTIPLE HYPERPARAMETER SWEEPS\n",
    "                        assert holdout_neg_mse_score == glm.neg_mse_score(X_holdout, y_holdout)\n",
    "\n",
    "                        betas_df[['mse_tr', 'mse_cv', 'mse_te']] = [[-glm.neg_mse_score(X_train, y_train), cv_results['full_cv_results'][0]['cv_mse_score'], -glm.neg_mse_score(X_holdout, y_holdout)]]\n",
    "                        betas_df[['r2_tr', 'r2_cv', 'r2_te']] = [[glm.r2_score(X_train, y_train), cv_results['full_cv_results'][0]['cv_R2_score'], glm.r2_score(X_holdout, y_holdout)]]\n",
    "\n",
    "                        multi_end = time.time()\n",
    "                        time_passed = str(multi_end - multi_start) + ' s'\n",
    "                        betas_df['timestamp'] = time_passed\n",
    "                        print('run_id, subrun_id', run_id, subrun_id, f'- Time Passed: {time_passed}')\n",
    "\n",
    "                        betas_df = betas_df.set_index(['mouse_id', 'channel_name', 'name', 'timestamp', 'mse_tr', 'mse_cv', 'mse_te', 'r2_tr', 'r2_cv', 'r2_te'], append=True)\n",
    "\n",
    "                        word_perc_kwargs = dict(total_col='photometrySideInIndex', words_prefix='photometrySideInIndex', words=['AA', 'Aa', 'aA', 'aa', 'AB', 'Ab', 'aB', 'ab'])\n",
    "                        betas_df = get_perc_words(df_train, betas_df, perc_suffix='_cnt_tr',  **word_perc_kwargs)\n",
    "                        betas_df = get_perc_words(df_holdout, betas_df, perc_suffix='_cnt_ho', **word_perc_kwargs)\n",
    "\n",
    "                        betas_df.to_hdf(pr(f'{base_folder}/{prefix}/{best_coefs_folder}/{run_id}_{hyp_str}_best_coeffs.h5'), key=subrun_id, index=True)\n",
    "\n",
    "                        dfrel_basis['pred_'+pred_col_name] = pd.Series(glm.predict(dfrel_basis_has_all_cols[X_cols]),\n",
    "                                                                                    index=dfrel_basis_has_all_cols.index)\n",
    "                        dfrel_basis['predALL_'+pred_col_name] = glm.predict(dfrel_basis[X_cols])\n",
    "\n",
    "                        subset_dfresids_cols = [f'holdout_{pred_col_name}', 'pred_'+pred_col_name, 'predALL_'+pred_col_name]\n",
    "                        dfresids_cols += subset_dfresids_cols\n",
    "    #                     dfresids_cols += [f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}', 'pred_'+pred_col_name, 'predALL_'+pred_col_name]\n",
    "                        \n",
    "    #                     display(dfrel_basis)\n",
    "                        dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True)[subset_dfresids_cols].to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_{run_id}.h5'), key=subrun_id, index=True,)\n",
    "    #                     break\n",
    "    #             dfrel_basis[dfresids_cols].set_index(['nTrial_filenum'], append=True).to_hdf(pr(f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_fn={fn}_iXyp={iXyp}_all.h5'), key='df', index=True,)\n",
    "    #                 break\n",
    "    #             break\n",
    "    #         break\n",
    "    #     break\n",
    "    # return\n",
    "\n",
    "    # import cProfile\n",
    "    # cprof = cProfile.run('func_for_cprofile()', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Josh\\\\Documents\\\\GitHub\\\\sabatinilab-glm\\\\sglm\\\\outputs-old/Figure_7_g1--20_20sft/all/tet_run_20230403--20_20sft_1-ft/reconstructs/best_resids_732_735_736_776_1.h5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{base_folder}/{prefix}/{best_reconstruct_folder}/best_resids_{run_id}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcombo_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\generic.py:11069\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  11049\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11050\u001b[0m     _num_doc,\n\u001b[0;32m  11051\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the sum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11067\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11068\u001b[0m ):\n\u001b[1;32m> 11069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m  11070\u001b[0m         \u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11071\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\generic.py:10789\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  10780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[0;32m  10781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10782\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  10788\u001b[0m ):\n\u001b[1;32m> 10789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_count_stat_function(\n\u001b[0;32m  10790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnansum, axis, skipna, level, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  10791\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\generic.py:10771\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m  10755\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  10756\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  10757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10760\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  10761\u001b[0m     )\n\u001b[0;32m  10762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  10763\u001b[0m         name,\n\u001b[0;32m  10764\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10768\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m  10769\u001b[0m     )\n\u001b[1;32m> 10771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10774\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10778\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\frame.py:10020\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10016\u001b[0m ignore_failures \u001b[38;5;241m=\u001b[39m numeric_only \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m  10018\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10019\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10020\u001b[0m res, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_failures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10021\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1389\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m   1387\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1389\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1392\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:139\u001b[0m, in \u001b[0;36mmaybe_split.<locals>.newfunc\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(meth)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnewfunc\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m meth(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;66;03m# Split and operate column-by-column\u001b[39;00m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_and_operate(meth, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1907\u001b[0m, in \u001b[0;36mObjectBlock.reduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1907\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1908\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\frame.py:9992\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m   9990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   9991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 9992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\nanops.py:410\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 410\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    413\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\nanops.py:483\u001b[0m, in \u001b[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001b[1;34m(values, axis, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         results \u001b[38;5;241m=\u001b[39m [func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrs]\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(results)\n\u001b[1;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(values, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sglm\\lib\\site-packages\\pandas\\core\\nanops.py:623\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count, mask)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_timedelta64_dtype(dtype):\n\u001b[0;32m    621\u001b[0m     dtype_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m--> 623\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _maybe_null_out(the_sum, axis, mask, values\u001b[38;5;241m.\u001b[39mshape, min_count\u001b[38;5;241m=\u001b[39mmin_count)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m the_sum\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout.sum(), (~holdout.isna()).sum() - holdout.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis.columns[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis_backup_og = dfrel_basis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_if_has_val(check_srs, x_srs, y_srs, label='label', ax=None):\n",
    "    if check_srs.abs().sum() > 0:\n",
    "        ax.plot(x_srs, y_srs, label=label)\n",
    "\n",
    "def view_trial(df, nTrial, y_col='gACH', pred_col='pred', holdout_col='holdout', dupe_col='dupe', wi_trial_keep_col='wi_trial_keep_hard'):\n",
    "    if nTrial:\n",
    "        df = df[df['nTrial_filenum'] == nTrial]\n",
    "    \n",
    "    fig,axes = plt.subplots(4,1,figsize=(30,10))\n",
    "    fig.set_facecolor('w')\n",
    "    \n",
    "#     fig.suptitle(f'MSE -- Total: {}')\n",
    "    \n",
    "    tax = axes[0]\n",
    "    tax.grid(True)\n",
    "    bax = axes[1]\n",
    "    bax.grid(True)\n",
    "    bbax = axes[2]\n",
    "    bbax.grid(True)\n",
    "    bbbax = axes[3]\n",
    "    bbbax.grid(True)\n",
    "    \n",
    "    show_if_has_val(df['photometryCenterInIndex'], df.index, df['photometryCenterInIndex']+2, label='CI', ax=tax)\n",
    "    show_if_has_val(df['photometryCenterOutIndex'], df.index, df['photometryCenterOutIndex']+2, label='CO', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndex'], df.index, df['photometrySideInIndex']+2, label='SI', ax=tax)\n",
    "    show_if_has_val(df['photometrySideOutIndex'], df.index, df['photometrySideOutIndex']+2, label='SO', ax=tax)\n",
    "    tax.plot(df.index, df[holdout_col]*1, label='isHoldout')\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexr'], df.index, df['photometrySideInIndexr']*1+4, label='SIr', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexnr'], df.index, df['photometrySideInIndexnr']*1+4, label='SInr', ax=tax)\n",
    "    show_if_has_val(df['spnnrOff'], df.index, df['spnnrOff']*1+4, label='spnnrOff', ax=tax)\n",
    "    show_if_has_val(df['sl'], df.index, df['sl']*1+4, label='SL', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexAA'], df.index, df['photometrySideInIndexAA']*1+6, label='AA', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexAa'], df.index, df['photometrySideInIndexAa']*1+6, label='Aa', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaA'], df.index, df['photometrySideInIndexaA']*1+6, label='aA', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaa'], df.index, df['photometrySideInIndexaa']*1+6, label='aa', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df['photometrySideInIndexAB'], df.index, df['photometrySideInIndexAB']*1+6, label='AB', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexAb'], df.index, df['photometrySideInIndexAb']*1+6, label='Ab', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexaB'], df.index, df['photometrySideInIndexaB']*1+6, label='aB', ax=tax)\n",
    "    show_if_has_val(df['photometrySideInIndexab'], df.index, df['photometrySideInIndexab']*1+6, label='ab', ax=tax)\n",
    "    \n",
    "    show_if_has_val(df[dupe_col], df.index, df[dupe_col]*1+8, label='isDupe', ax=tax)\n",
    "    show_if_has_val(df[wi_trial_keep_col], df.index, df[wi_trial_keep_col]*1+8, label='isInTrial', ax=tax)\n",
    "    \n",
    "    tax.legend()\n",
    "    \n",
    "    bax.plot(df.index, df[y_col], label=f'True - {y_col}')\n",
    "    bax.plot(df.index, df[pred_col], label=f'Pred - {y_col}')\n",
    "    \n",
    "    bax.legend()\n",
    "    \n",
    "    bbax.plot(df.index, (df[y_col] - df[pred_col])**2, label='Resid^2')\n",
    "    bbax.legend()\n",
    "    \n",
    "    bbbax.plot(df.index, ((df[y_col] - df[pred_col])**2).cumsum(), label='Cumulative Resid^2')\n",
    "    bbbax.plot(df.index, ((df[y_col] - df[pred_col])**2 * df['wi_trial_keep']).cumsum(), label='Cumulative Resid^2 -- Within Trial')\n",
    "    bbbax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lst = []\n",
    "# with pd.HDFStore(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs\\fig1\\all\\oall-testhdf-4_0-ft\\reconstructs\\best\\best_resids_63_64_65_66_67_68_69_57_58_59_60_61_53_55_56_0.h5') as hdf:\n",
    "#     print(hdf.keys())\n",
    "#     for key in hdf.keys():\n",
    "#         df_lst.append(pd.read_hdf(hdf, key=key))\n",
    "# #     df_reader = hdf.select('my_table_id', chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfrel_basis = df_lst[-2]\n",
    "# dfrel_basis = dfrel_basis_backup_og.copy()\n",
    "dfrel_basis = dfrel_basis_backup_og[~dfrel_basis_backup_og['dupe']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "# dfrel_basis = dfrel_basis_backup.copy()\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "tot_rns = 50\n",
    "# for run_num in trange(4, 5):\n",
    "for run_num in trange(tot_rns):\n",
    "    # for run_num in range(10):\n",
    "    dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "    dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "    dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "    # dfrel_basis['resid2_wi_trial_short'] = ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "\n",
    "    df_inspect = dfrel_basis\n",
    "    # df_inspect = dfrel_basis[~dfrel_basis['file_num'].isin([16, 10, 17, 15, 3, 13, 12, 7])]\n",
    "    # df_inspect = hdf[hdf['diffTrialNums'] == 1]\n",
    "    # df_inspect = dfrel_basis[dfrel_basis['wi_trial_keep']]\n",
    "\n",
    "    training_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == False')\n",
    "    holdout_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == True')\n",
    "\n",
    "    # print('Num Total', df_inspect.shape[0])\n",
    "    # print('Num Holdout', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].sum())\n",
    "    # print('Num Nan', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].isna().sum())\n",
    "\n",
    "    training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    addl_resids = pd.DataFrame([(training_mean_resids.values<holdout_mean_resids.values)*1],\n",
    "                                index=['correct'],\n",
    "                                columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "    if run_num == 0:\n",
    "        mean_resids = addl_resids\n",
    "    else:\n",
    "        mean_resids += addl_resids\n",
    "    display(addl_resids)\n",
    "display(mean_resids/(run_num+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "# run_num = 50\n",
    "\n",
    "dfrel_basis['wt'] = dfrel_basis['signal_file'].str.split('_').apply(lambda x: x[3])\n",
    "\n",
    "for run_num in trange(tot_rns):\n",
    "    dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "    dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "    dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "    dfrel_basis['prc_tot_resid2'] = (dfrel_basis['resid2']/dfrel_basis['resid2'].sum())\n",
    "    dfrel_basis['prc_tot_resid2_wi_trial'] = (dfrel_basis['resid2_wi_trial']/dfrel_basis['resid2_wi_trial'].sum())\n",
    "\n",
    "    df_inspect = dfrel_basis\n",
    "    df_inspect = dfrel_basis[dfrel_basis['resid2'] < 30]\n",
    "    training_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == False]\n",
    "    holdout_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == True]\n",
    "\n",
    "    training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "    mean_resids = pd.DataFrame([training_mean_resids.values,\n",
    "                                holdout_mean_resids.values,\n",
    "                                (training_mean_resids.values<holdout_mean_resids.values)*1\n",
    "                                ],\n",
    "                                index=['training', 'holdout', 'correct'],\n",
    "                                columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "    display(mean_resids)\n",
    "    print('tr', len(training_df), 'ho', len(holdout_df))\n",
    "\n",
    "    # resids = mean_resids['resid2_wi_trial'].to_list()\n",
    "\n",
    "    base_resid2_col = 'resid2_wi_trial'\n",
    "\n",
    "    resid_vals = '_'.join(['='.join([str(__) for __ in _]) for _ in list(zip(mean_resids.index, np.round(mean_resids[base_resid2_col], 3)))])\n",
    "\n",
    "    # tmp_df = training_df.copy()\n",
    "    tr_cc = np.arange((~training_df[base_resid2_col].isna()).sum())+1\n",
    "    ho_cc = np.arange((~holdout_df[base_resid2_col].isna()).sum())+1\n",
    "\n",
    "    h = training_df[base_resid2_col].dropna().sort_values(ascending=False).reset_index(drop=True).cumsum().copy()\n",
    "    h2 = holdout_df[base_resid2_col].dropna().sort_values(ascending=False).reset_index(drop=True).cumsum().copy()\n",
    "\n",
    "    h_cummean = h/tr_cc\n",
    "    h2_cummean = h2/ho_cc\n",
    "\n",
    "\n",
    "    start_loc = 0\n",
    "    num_points = -1\n",
    "\n",
    "    fig,ax=plt.subplots(2,5,figsize=(40,10))\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    fig.suptitle(resid_vals)\n",
    "    g1.plot(ax=ax[0,0], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,0], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,0], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,0], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = 0\n",
    "    num_points = 100\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,1], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,1], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,1], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,1], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = min(len(h_cummean), len(h2_cummean))-5000\n",
    "    num_points = 5000\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,2], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,2], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,2], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,2], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = max(len(h_cummean), len(h2_cummean))-5000\n",
    "    num_points = 5000\n",
    "\n",
    "    g1 = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    g2 = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    \n",
    "    g1.plot(ax=ax[0,3], label=f'training — {len(training_df)}')\n",
    "    g2.plot(ax=ax[0,3], label=f'holdout — {len(holdout_df)}')\n",
    "    g1.diff().plot(ax=ax[1,3], label=f'training — {len(training_df)}')\n",
    "    g2.diff().plot(ax=ax[1,3], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "    start_loc = -5001\n",
    "    num_points = 5000\n",
    "\n",
    "    ga = h_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "    gb = h2_cummean.iloc[start_loc:(start_loc+num_points)].reset_index(drop=True)\n",
    "\n",
    "    ga.plot(ax=ax[0,4], label=f'training — {len(training_df)}')\n",
    "    gb.plot(ax=ax[0,4], label=f'holdout — {len(holdout_df)}')\n",
    "    ga.diff().plot(ax=ax[1,4], label=f'training — {len(training_df)}')\n",
    "    gb.diff().plot(ax=ax[1,4], label=f'holdout — {len(holdout_df)}')\n",
    "\n",
    "\n",
    "    ax[0,0].grid(True)\n",
    "    ax[0,0].legend()\n",
    "\n",
    "    ax[1,0].grid(True)\n",
    "    ax[1,0].legend()\n",
    "\n",
    "    ax[0,1].grid(True)\n",
    "    ax[0,1].legend()\n",
    "\n",
    "    ax[1,1].grid(True)\n",
    "    ax[1,1].legend()\n",
    "\n",
    "    ax[0,2].grid(True)\n",
    "    ax[0,2].legend()\n",
    "\n",
    "    ax[1,2].grid(True)\n",
    "    ax[1,2].legend()\n",
    "\n",
    "    ax[0,3].grid(True)\n",
    "    ax[0,3].legend()\n",
    "\n",
    "    ax[1,3].grid(True)\n",
    "    ax[1,3].legend()\n",
    "\n",
    "    ax[0,4].grid(True)\n",
    "    ax[0,4].legend()\n",
    "\n",
    "    ax[1,4].grid(True)\n",
    "    ax[1,4].legend()\n",
    "\n",
    "    # tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "run_num = 3\n",
    "\n",
    "dfrel_basis['wt'] = dfrel_basis['signal_file'].str.split('_').apply(lambda x: x[3])\n",
    "\n",
    "dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "dfrel_basis['prc_tot_resid2'] = (dfrel_basis['resid2']/dfrel_basis['resid2'].sum())\n",
    "dfrel_basis['prc_tot_resid2_wi_trial'] = (dfrel_basis['resid2_wi_trial']/dfrel_basis['resid2_wi_trial'].sum())\n",
    "\n",
    "df_inspect = dfrel_basis\n",
    "training_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == False]\n",
    "holdout_df = df_inspect[df_inspect[f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'] == True]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "# training_df['prc_tot_resid2'].cumsum().plot(ax=ax)\n",
    "# holdout_df['prc_tot_resid2'].cumsum().plot(ax=ax)\n",
    "\n",
    "training_df.groupby(['wt', 'file_num'])['resid2'].mean().plot(ax=ax, label='training - resid2')\n",
    "holdout_df.groupby(['wt', 'file_num'])['resid2'].mean().plot(ax=ax, label='holdout - resid2')\n",
    "\n",
    "training_df.groupby(['wt', 'file_num'])['resid2_wi_trial'].mean().plot(ax=ax, label='training - wit')\n",
    "holdout_df.groupby(['wt', 'file_num'])['resid2_wi_trial'].mean().plot(ax=ax, label='holdout - wit')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df.groupby(['wt', 'file_num']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['mouse_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_cummean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_cummean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = training_df.copy()\n",
    "tmp_df['1'] = 1\n",
    "h = (tmp_df[['resid2_wi_trial', '1']])#/(tmp_df['resid2_wi_trial'].sum()))\n",
    "# g = h.dropna().sort_values('resid2_wi_trial', ascending=False).cumsum().reset_index(drop=True)\n",
    "g = h.dropna().sort_values('resid2_wi_trial', ascending=False).reset_index(drop=True)\n",
    "# g = g.groupby('1').cumsum()/g.groupby('1').cumcount()\n",
    "# g = g.drop('1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.iloc[:num_points]\n",
    "g.index = g.index/g.index.max()\n",
    "g.plot(ax=ax, label='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df['resid2_wi_trial'].mean(), holdout_df['resid2_wi_trial'].mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2-g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dfrel_basis = dfrel_basis_backup.copy()\n",
    "y_col = 'gACH'\n",
    "Xyd, Xyp = 0, 0\n",
    "run_num = 9\n",
    "\n",
    "# for run_num in range(10):\n",
    "dfrel_basis['resid2'] = (dfrel_basis[y_col] - dfrel_basis[f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}'])**2\n",
    "dfrel_basis['resid2_wi_trial'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep'].replace(False, np.nan))\n",
    "\n",
    "\n",
    "dfrel_basis['resid2_wi_trial_hard'] = dfrel_basis['resid2']*(dfrel_basis['wi_trial_keep_hard'].replace(False, np.nan))\n",
    "\n",
    "# dfrel_basis['resid2_wi_trial_short'] = ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "\n",
    "df_inspect = dfrel_basis\n",
    "# df_inspect = dfrel_basis[~dfrel_basis['file_num'].isin([16, 10, 17, 15, 3, 13, 12, 7])]\n",
    "# df_inspect = hdf[hdf['diffTrialNums'] == 1]\n",
    "# df_inspect = dfrel_basis[dfrel_basis['wi_trial_keep']]\n",
    "\n",
    "training_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == False')\n",
    "holdout_df = df_inspect.query(f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num} == True')\n",
    "\n",
    "# print('Num Total', df_inspect.shape[0])\n",
    "# print('Num Holdout', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].sum())\n",
    "# print('Num Nan', df_inspect['holdout_gACH_0_0_base_simple_run_num__0'].isna().sum())\n",
    "\n",
    "training_mean_resids = (training_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "holdout_mean_resids = (holdout_df[['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard']]).mean()\n",
    "mean_resids = pd.DataFrame([training_mean_resids.values, holdout_mean_resids.values, (training_mean_resids.values<holdout_mean_resids.values)*1],\n",
    "                           index=['training', 'holdout', 'correct'],\n",
    "                           columns=['resid2', 'resid2_wi_trial', 'resid2_wi_trial_hard'])\n",
    "display(mean_resids)\n",
    "# display('Training', training_df.shape)\n",
    "# display('Holdout', holdout_df.shape)\n",
    "\n",
    "at = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2'].mean().sort_values(ascending=False).head().reset_index()\n",
    "at = at.rename({_:_+'_all_tr' for _ in at.columns}, axis=1)\n",
    "ah = holdout_df.groupby(['file_num', 'nTrial_filenum'])['resid2'].mean().sort_values(ascending=False).head().reset_index()\n",
    "ah = ah.rename({_:_+'_all_ho' for _ in ah.columns}, axis=1)\n",
    "\n",
    "wit = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wit = wit.rename({_:_+'_wi_tr' for _ in wit.columns}, axis=1)\n",
    "wih = holdout_df.groupby(['file_num'])['resid2_wi_trial'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wih = wih.rename({_:_+'_wi_ho' for _ in wih.columns}, axis=1)\n",
    "\n",
    "wits = training_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial_hard'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wits = wits.rename({_:_+'_wi_tr_hrd' for _ in wits.columns}, axis=1)\n",
    "wihs = holdout_df.groupby(['file_num', 'nTrial_filenum'])['resid2_wi_trial_hard'].mean().sort_values(ascending=False).head().reset_index()\n",
    "wihs = wihs.rename({_:_+'_wi_ho_hrd' for _ in wihs.columns}, axis=1)\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_columns', 1000):\n",
    "    display(pd.concat([at, ah, wit, wih, wits, wihs], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inspect[df_inspect['nTrial_filenum'] == 1071]['photometryCenterOutIndex'].plot()\n",
    "b = 'photometrySideOutIndex'\n",
    "a = df_inspect[df_inspect['diffTrialNums'] == 1].groupby('nTrial_filenum')[[b]].sum().sort_values(b, ascending=False).copy()\n",
    "# a\n",
    "a['1'] = 1\n",
    "a.groupby(b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_trial_kwargs = dict(y_col=y_col, pred_col=f'pred_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}', holdout_col=f'holdout_{y_col}_{Xyd}_{Xyp}_base_simple_run_num__{run_num}', dupe_col='dupe')\n",
    "view_trial(df_inspect, 1071, **view_trial_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf = dfrel_basis.copy()\n",
    "# hdf['nTrial'] = hdf.groupby('file_num')['nTrial'].shift(20)\n",
    "# hdf['nEndTrial'] = hdf.groupby('file_num')['nEndTrial'].shift(-20)\n",
    "# hdf['diffTrialNums'] = hdf['nTrial'] - hdf['nEndTrial']\n",
    "# hdf[hdf['diffTrialNums'] == 1]\n",
    "# ((((dfrel_basis['photometryCenterInIndex'].cumsum() - dfrel_basis['photometrySideOutIndex'].cumsum())==1).replace(False, np.nan))*dfrel_basis['resid2'])\n",
    "# holdout_df.groupby(['nTrial_filenum'])['resid2_wi_trial_short'].mean().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[training_df['has_all_cols']&training_df['wi_trial_keep']].shape, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((glm.predict(X_train) - y_train)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, training_df[training_df['has_all_cols']&(training_df['wi_trial_keep'])].shape, df_holdout.shape, holdout_df[holdout_df['has_all_cols']&holdout_df['wi_trial_keep']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrel_basis_has_all_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr(f'../../data/interim/{data_folder_src}/GLM_SIGNALS_INTERIM_{wt}_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_col_keeps['has_all_cols'][0].sum()\n",
    "\n",
    "dfrel_basis[full_drop_basis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (~dfrel_basis[f'holdout_iXyp={iXyp}_irun={irun}_iXyd={iXyd}'].isna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Training', (~dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum())\n",
    "print('Num Holdouts', (dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum())\n",
    "print('NaN Entries', dfrel_basis['holdout_iXyp=0_irun=0'].isna().sum())\n",
    "\n",
    "print('Total Entries', (~dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum() + (dfrel_basis['holdout_iXyp=0_irun=0'].dropna().astype(bool)).sum() + dfrel_basis['holdout_iXyp=0_irun=0'].isna().sum())\n",
    "print('Len Entries', len(dfrel_basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(has_all_cols) - has_all_cols.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM_SIGNALS_INTERIM_{wt}_dfrel_ft_setup['nTrial'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial'].nunique()\n",
    "\n",
    "# dfrel_ft_setup['nTrial_filenum'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial_filenum'].nunique()\n",
    "\n",
    "# dfrel_ft_holdout['nTrial_filenum'].nunique()/dfrel_ft_setup['nTrial_filenum'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfrel_basis_has_all_cols.copy()\n",
    "id_cols=['nTrial_filenum']\n",
    "perc_holdout=pholdout\n",
    "y = None\n",
    "strat_col = None\n",
    "strat_mode = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) > 0\n",
    "\n",
    "for i, idc in enumerate(id_cols):\n",
    "    srs_x_idc_str = X[idc].apply(str)\n",
    "    if i == 0:\n",
    "        bucket_ids = srs_x_idc_str.str.len().apply(str) + ':' + srs_x_idc_str\n",
    "    else:\n",
    "        bucket_ids = bucket_ids + '__' + srs_x_idc_str.str.len().apply(str) + ':' + srs_x_idc_str\n",
    "bucket_ids = bucket_ids.astype(\"category\").cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_ids.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['nTrial_filenum'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(bucket_ids.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_bucket_ids = int(bucket_ids.max() + 1)\n",
    "\n",
    "if strat_col is not None:\n",
    "\n",
    "    strat_df = X[[strat_col]].copy()\n",
    "    strat_df['bucket_id'] = bucket_ids\n",
    "\n",
    "    strat_groups = strat_df[strat_col].unique()\n",
    "    distinct_buckets = [pd.Series(strat_df[strat_df[strat_col] == _]['bucket_id'].unique()) for _ in strat_groups]\n",
    "    bucket_sizes = np.array([len(_) for _ in distinct_buckets])\n",
    "\n",
    "    min_bucket_size = bucket_sizes.min()\n",
    "    bucket_totals = bucket_sizes.sum()\n",
    "\n",
    "    # print(set_sizes)\n",
    "    train_distinct_buckets = []\n",
    "    test_distinct_buckets = []\n",
    "\n",
    "    if strat_mode == 'balanced_train':\n",
    "\n",
    "        num_balanced_train_selection = int(min_bucket_size * (1 - perc_holdout))\n",
    "        for bucket in distinct_buckets:\n",
    "            train_distinct_buckets.append(np.random.choice(bucket, num_balanced_train_selection, replace=False))\n",
    "            test_distinct_buckets.append(bucket[~bucket.isin(train_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    elif strat_mode == 'balanced_test':\n",
    "\n",
    "        num_balanced_test_selection = int(min_bucket_size * perc_holdout)\n",
    "        for bucket in distinct_buckets:\n",
    "            test_distinct_buckets.append(np.random.choice(bucket, num_balanced_test_selection, replace=False))\n",
    "            train_distinct_buckets.append(bucket[~bucket.isin(test_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    elif strat_mode == 'stratify':\n",
    "        for bucket in distinct_buckets:\n",
    "            test_distinct_buckets.append(np.random.choice(bucket, int(len(bucket)*perc_holdout), replace=False))\n",
    "            train_distinct_buckets.append(bucket[~bucket.isin(test_distinct_buckets[-1])])\n",
    "        test_ids = np.concatenate(test_distinct_buckets)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Invalid strat_mode: {strat_mode}')\n",
    "else:\n",
    "    print('else')\n",
    "    num_buckets_for_test = int(num_bucket_ids * perc_holdout)\n",
    "    test_ids = np.random.choice(num_bucket_ids, size=num_buckets_for_test, replace=False)\n",
    "\n",
    "holdout = bucket_ids.isin(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_buckets_for_test\n",
    "test_ids = np.random.choice(num_bucket_ids, size=num_buckets_for_test, replace=False)\n",
    "len(np.unique(test_ids))\n",
    "bucket_ids[bucket_ids.isin(test_ids)].nunique(), bucket_ids[(~bucket_ids.isin(test_ids))].nunique()\n",
    "5277 + 8069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
