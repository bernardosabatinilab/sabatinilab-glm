{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sglm.models import sglm\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "\n",
    "import itertools\n",
    "\n",
    "signal_files = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Figure 1: Single side recording\n",
    "\n",
    "y_col_lst_all = ['gACH', 'rDA', 'gDA', 'Ch5', 'Ch6', 'GP_1', 'GP_2', 'GP_5', 'GP_6', 'SGP_1', 'SGP_2', 'SGP_5', 'SGP_6']\n",
    "\n",
    "# # # Load Signal Data\n",
    "\n",
    "# # signal_files = glob.glob(f'../../data/raw/GLM_SIGNALS_WT61_*')\n",
    "# # signal_files += glob.glob(f'../../data/raw/GLM_SIGNALS_WT63_*')\n",
    "# # signal_files += glob.glob(f'../../data/raw/GLM_SIGNALS_WT64_*')\n",
    "\n",
    "# # ignore_files = [\n",
    "# #                 'WT61_10152021',\n",
    "# #                 'WT61_10082021'\n",
    "# #                 ]\n",
    "# # for ign in ignore_files:\n",
    "# #     signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "# # table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "# # channel_definitions = {\n",
    "# #         ('WT61',): {'Ch1': 'gACH', 'Ch2': 'rDA'},\n",
    "# #         ('WT64',): {'Ch1': 'gACH', 'Ch2': 'empty'},\n",
    "# #         ('WT63',): {'Ch1': 'gDA', 'Ch2': 'empty'},\n",
    "# #     }\n",
    "\n",
    "# group_1_mice = ['WT63', 'WT64', 'WT65']\n",
    "# group_1_sess = ['11082021', '11102021', '11122021', '11182021']\n",
    "# group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# group_2_mice = ['WT66', 'WT67', 'WT68', 'WT69']\n",
    "# group_2_sess = ['12132021', '12152021', '12172021', '12192021']\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# group_3_mice = ['WT58', 'WT60', 'WT61']\n",
    "# group_3_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# group_4_mice = ['WT53', 'WT54', 'WT55', 'WT56']\n",
    "# group_4_sess = ['09012021', '09032021', '09062021']\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = ['WT57', 'WT59']\n",
    "# group_5_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "# group_6_mice = ['WT62']\n",
    "# group_6_sess = ['11082021', '11102021', '11122021', '11182021']\n",
    "# group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "# channel_definitions = {}\n",
    "# # channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA', 'Ch5': 'gACH'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_4_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH'} for file_combo in group_5_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig_1_signal_files_setup = group_1_combo + group_2_combo + group_3_combo + group_4_combo + group_5_combo + group_6_combo\n",
    "\n",
    "# for f in fig_1_signal_files_setup:\n",
    "#     glob_file = glob.glob(f'../../data/raw/fig1/GLM_SIGNALS_{f}*')\n",
    "#     if len(glob_file) != 1:\n",
    "#         print('Missing file!!! ', f)\n",
    "#     signal_files += glob_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file!!!  WT61_03162021\n",
      "Missing file!!!  WT61_03192021\n",
      "Missing file!!!  WT61_03232021\n",
      "Missing file!!!  WT61_03262021\n",
      "Missing file!!!  WT61_07282021\n",
      "Missing file!!!  WT61_07302021\n",
      "Missing file!!!  WT61_08012021\n",
      "Missing file!!!  WT61_08042021\n",
      "Missing file!!!  WT61_08062021\n",
      "Missing file!!!  WT61_08102021\n",
      "Missing file!!!  WT61_11082021\n",
      "Missing file!!!  WT61_11102021\n",
      "Missing file!!!  WT61_11122021\n",
      "Missing file!!!  WT61_11162021\n",
      "Missing file!!!  WT61_11182021\n",
      "Missing file!!!  WT63_03162021\n",
      "Missing file!!!  WT63_03192021\n",
      "Missing file!!!  WT63_03232021\n",
      "Missing file!!!  WT63_03262021\n",
      "Missing file!!!  WT63_07282021\n",
      "Missing file!!!  WT63_07302021\n",
      "Missing file!!!  WT63_08012021\n",
      "Missing file!!!  WT63_08042021\n",
      "Missing file!!!  WT63_08062021\n",
      "Missing file!!!  WT63_08102021\n",
      "Missing file!!!  WT63_10042021\n",
      "Missing file!!!  WT63_10082021\n",
      "Missing file!!!  WT63_10112021\n",
      "Missing file!!!  WT63_10132021\n",
      "Missing file!!!  WT63_10182021\n",
      "Missing file!!!  WT64_03162021\n",
      "Missing file!!!  WT64_03192021\n",
      "Missing file!!!  WT64_03232021\n",
      "Missing file!!!  WT64_03262021\n",
      "Missing file!!!  WT64_07282021\n",
      "Missing file!!!  WT64_07302021\n",
      "Missing file!!!  WT64_08012021\n",
      "Missing file!!!  WT64_08042021\n",
      "Missing file!!!  WT64_08062021\n",
      "Missing file!!!  WT64_08102021\n",
      "Missing file!!!  WT64_10042021\n",
      "Missing file!!!  WT64_10082021\n",
      "Missing file!!!  WT64_10112021\n",
      "Missing file!!!  WT64_10132021\n",
      "Missing file!!!  WT64_10182021\n",
      "Missing file!!!  WT44_07282021\n",
      "Missing file!!!  WT44_07302021\n",
      "Missing file!!!  WT44_08012021\n",
      "Missing file!!!  WT44_08042021\n",
      "Missing file!!!  WT44_08062021\n",
      "Missing file!!!  WT44_08102021\n",
      "Missing file!!!  WT44_10042021\n",
      "Missing file!!!  WT44_10082021\n",
      "Missing file!!!  WT44_10112021\n",
      "Missing file!!!  WT44_10132021\n",
      "Missing file!!!  WT44_10182021\n",
      "Missing file!!!  WT44_11082021\n",
      "Missing file!!!  WT44_11102021\n",
      "Missing file!!!  WT44_11122021\n",
      "Missing file!!!  WT44_11162021\n",
      "Missing file!!!  WT44_11182021\n",
      "Missing file!!!  WT51_03162021\n",
      "Missing file!!!  WT51_03192021\n",
      "Missing file!!!  WT51_03232021\n",
      "Missing file!!!  WT51_03262021\n",
      "Missing file!!!  WT51_10042021\n",
      "Missing file!!!  WT51_10082021\n",
      "Missing file!!!  WT51_10112021\n",
      "Missing file!!!  WT51_10132021\n",
      "Missing file!!!  WT51_10182021\n",
      "Missing file!!!  WT51_11082021\n",
      "Missing file!!!  WT51_11102021\n",
      "Missing file!!!  WT51_11122021\n",
      "Missing file!!!  WT51_11162021\n",
      "Missing file!!!  WT51_11182021\n"
     ]
    }
   ],
   "source": [
    "### Figure 2: Dual side recording\n",
    "\n",
    "# 'WT61', 'WT63', 'WT64', '', 'WT44', 'WT51' # Excluding 'WT43\n",
    "\n",
    "# ['03162021','03192021','03232021','03262021','07282021','07302021','08012021', '08042021', '08062021', '08102021', '10042021',\n",
    "# '10082021', '10112021', '10132021', '10182021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "\n",
    "\n",
    "group_1_mice = ['WT61', 'WT63', 'WT64', 'WT44', 'WT51']\n",
    "group_1_sess = ['03162021','03192021','03232021','03262021','07282021','07302021','08012021', '08042021', '08062021', '08102021', '10042021',\n",
    "                '10082021', '10112021', '10132021', '10182021', '11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "# group_2_mice = ['WT66', 'WT67', 'WT68', 'WT69']\n",
    "# group_2_sess = ['12132021', '12152021', '12172021', '12192021']\n",
    "# group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "# group_3_mice = ['WT58', 'WT60', 'WT61']\n",
    "# group_3_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "# group_4_mice = ['WT53', 'WT54', 'WT55', 'WT56']\n",
    "# group_4_sess = ['09012021', '09032021', '09062021']\n",
    "# group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "# group_5_mice = ['WT61']\n",
    "# group_5_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "# group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "group_6_mice = ['WT43']\n",
    "group_6_sess = []\n",
    "group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "channel_definitions = {}\n",
    "# channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_1_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_2_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_3_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_4_combo})\n",
    "# channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_5_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gACH', 'Ch6': 'rDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "fig_2_signal_files_setup = group_1_combo #+ group_2_combo + group_3_combo + group_4_combo + group_5_combo + group_6_combo\n",
    "for f in fig_2_signal_files_setup:\n",
    "    glob_file = glob.glob(f'../../data/raw/fig2/GLM_SIGNALS_{f}*')\n",
    "    if len(glob_file) != 1:\n",
    "        print('Missing file!!! ', f)\n",
    "    signal_files += glob_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WT61_03162021',)\n",
      "('WT61_03192021',)\n",
      "('WT61_03232021',)\n",
      "('WT61_03262021',)\n",
      "('WT61_07282021',)\n",
      "('WT61_07302021',)\n",
      "('WT61_08012021',)\n",
      "('WT61_08042021',)\n",
      "('WT61_08062021',)\n",
      "('WT61_08102021',)\n",
      "('WT61_10042021',)\n",
      "> GLM_SIGNALS_WT61_10042021.txt\n",
      "('WT61_10082021',)\n",
      "('WT61_10112021',)\n",
      "> GLM_SIGNALS_WT61_10112021.txt\n",
      "('WT61_10132021',)\n",
      "> GLM_SIGNALS_WT61_10132021.txt\n",
      "('WT61_10182021',)\n",
      "> GLM_SIGNALS_WT61_10182021.txt\n",
      "('WT61_11082021',)\n",
      "('WT61_11102021',)\n",
      "('WT61_11122021',)\n",
      "('WT61_11162021',)\n",
      "('WT61_11182021',)\n",
      "('WT63_03162021',)\n",
      "('WT63_03192021',)\n",
      "('WT63_03232021',)\n",
      "('WT63_03262021',)\n",
      "('WT63_07282021',)\n",
      "('WT63_07302021',)\n",
      "('WT63_08012021',)\n",
      "('WT63_08042021',)\n",
      "('WT63_08062021',)\n",
      "('WT63_08102021',)\n",
      "('WT63_10042021',)\n",
      "('WT63_10082021',)\n",
      "('WT63_10112021',)\n",
      "('WT63_10132021',)\n",
      "('WT63_10182021',)\n",
      "('WT63_11082021',)\n",
      "> GLM_SIGNALS_WT63_11082021.txt\n",
      "('WT63_11102021',)\n",
      "> GLM_SIGNALS_WT63_11102021.txt\n",
      "('WT63_11122021',)\n",
      "> GLM_SIGNALS_WT63_11122021.txt\n",
      "('WT63_11162021',)\n",
      "> GLM_SIGNALS_WT63_11162021.txt\n",
      "('WT63_11182021',)\n",
      "> GLM_SIGNALS_WT63_11182021.txt\n",
      "('WT64_03162021',)\n",
      "('WT64_03192021',)\n",
      "('WT64_03232021',)\n",
      "('WT64_03262021',)\n",
      "('WT64_07282021',)\n",
      "('WT64_07302021',)\n",
      "('WT64_08012021',)\n",
      "('WT64_08042021',)\n",
      "('WT64_08062021',)\n",
      "('WT64_08102021',)\n",
      "('WT64_10042021',)\n",
      "('WT64_10082021',)\n",
      "('WT64_10112021',)\n",
      "('WT64_10132021',)\n",
      "('WT64_10182021',)\n",
      "('WT64_11082021',)\n",
      "> GLM_SIGNALS_WT64_11082021.txt\n",
      "('WT64_11102021',)\n",
      "> GLM_SIGNALS_WT64_11102021.txt\n",
      "('WT64_11122021',)\n",
      "> GLM_SIGNALS_WT64_11122021.txt\n",
      "('WT64_11162021',)\n",
      "> GLM_SIGNALS_WT64_11162021.txt\n",
      "('WT64_11182021',)\n",
      "> GLM_SIGNALS_WT64_11182021.txt\n",
      "('WT44_03162021',)\n",
      "> GLM_SIGNALS_WT44_03162021.txt\n",
      "('WT44_03192021',)\n",
      "> GLM_SIGNALS_WT44_03192021.txt\n",
      "('WT44_03232021',)\n",
      "> GLM_SIGNALS_WT44_03232021.txt\n",
      "('WT44_03262021',)\n",
      "> GLM_SIGNALS_WT44_03262021.txt\n",
      "('WT44_07282021',)\n",
      "('WT44_07302021',)\n",
      "('WT44_08012021',)\n",
      "('WT44_08042021',)\n",
      "('WT44_08062021',)\n",
      "('WT44_08102021',)\n",
      "('WT44_10042021',)\n",
      "('WT44_10082021',)\n",
      "('WT44_10112021',)\n",
      "('WT44_10132021',)\n",
      "('WT44_10182021',)\n",
      "('WT44_11082021',)\n",
      "('WT44_11102021',)\n",
      "('WT44_11122021',)\n",
      "('WT44_11162021',)\n",
      "('WT44_11182021',)\n",
      "('WT51_03162021',)\n",
      "('WT51_03192021',)\n",
      "('WT51_03232021',)\n",
      "('WT51_03262021',)\n",
      "('WT51_07282021',)\n",
      "> GLM_SIGNALS_WT51_07282021.txt\n",
      "('WT51_07302021',)\n",
      "> GLM_SIGNALS_WT51_07302021.txt\n",
      "('WT51_08012021',)\n",
      "> GLM_SIGNALS_WT51_08012021.txt\n",
      "('WT51_08042021',)\n",
      "> GLM_SIGNALS_WT51_08042021.txt\n",
      "('WT51_08062021',)\n",
      "> GLM_SIGNALS_WT51_08062021.txt\n",
      "('WT51_08102021',)\n",
      "> GLM_SIGNALS_WT51_08102021.txt\n",
      "('WT51_10042021',)\n",
      "('WT51_10082021',)\n",
      "('WT51_10112021',)\n",
      "('WT51_10132021',)\n",
      "('WT51_10182021',)\n",
      "('WT51_11082021',)\n",
      "('WT51_11102021',)\n",
      "('WT51_11122021',)\n",
      "('WT51_11162021',)\n",
      "('WT51_11182021',)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196e9b47a9dd4deabfa7f7f45bbbb09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "# of iterations 0 — Final max amount of duplicated Center Out Indices: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_files = [\n",
    "                'WT61_10152021',\n",
    "                'WT61_10082021'\n",
    "                ]\n",
    "for ign in ignore_files:\n",
    "    signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "\n",
    "channel_assignments = bf.get_rename_columns_by_file(signal_files, channel_definitions)\n",
    "\n",
    "for file_num in trange(len(signal_files)):\n",
    "\n",
    "    ## Load Table Data\n",
    "    # signal_fn = signal_files[0]\n",
    "    # table_fn = table_files[0]\n",
    "\n",
    "    signal_path = signal_files[file_num]\n",
    "    table_path = table_files[file_num]\n",
    "\n",
    "    signal_fn = signal_files[file_num].split('/')[-1]\n",
    "    table_fn = table_files[file_num].split('/')[-1]\n",
    "\n",
    "    signal_filename_out = signal_fn.replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_filename_out = table_fn.replace('GLM_TABLE', 'GLM_TABLE_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "    # signal_path_out = f'../../data/interim/{signal_filename_out}'\n",
    "    # table_path_out = f'../../data/interim/{table_filename_out}'\n",
    "\n",
    "    signal_path_out = signal_path.replace(r'/raw/', r'/interim/').replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_path_out = table_path.replace(r'/raw/', r'/interim/').replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "\n",
    "    signal_df = pd.read_csv(signal_path)\n",
    "    table_df = pd.read_csv(table_path)\n",
    "\n",
    "    signal_df, table_df = gsd.generate_signal_df(signal_path,\n",
    "                                            table_path,\n",
    "                                            # signal_filename_out=f'../../data/interim/{signal_filename_out}',\n",
    "                                            # table_filename_out=f'../../data/interim/{table_filename_out}'\n",
    "                                            )\n",
    "\n",
    "    signal_df = signal_df[signal_df['nTrial'] > 0].fillna(0)\n",
    "\n",
    "    # Break down Preprocess Lynne into component parts\n",
    "\n",
    "    # Rename Columns\n",
    "    signal_df = bf.rename_consistent_columns(signal_df)\n",
    "\n",
    "    for y_col in y_col_lst_all:\n",
    "        if y_col not in signal_df.columns:\n",
    "            signal_df[y_col] = np.nan\n",
    "            continue\n",
    "\n",
    "    # print(channel_assignments.keys())\n",
    "    # print(signal_fn)\n",
    "    if signal_fn in channel_assignments:\n",
    "        signal_df = signal_df.rename(channel_assignments[signal_fn], axis=1)\n",
    "\n",
    "    ## Set Full Trial Reward Flags\n",
    "    signal_df['r_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexr'].transform(np.sum) > 0) * 1.0\n",
    "    signal_df['nr_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexnr'].transform(np.sum) > 0) * 1.0\n",
    "\n",
    "    ## Define Side Rewarded / Unrewarded Flags\n",
    "    signal_df = bf.set_port_entry_exit_rewarded_unrewarded_indicators(signal_df)\n",
    "\n",
    "    ## Define Side Agnostic Events\n",
    "    signal_df = bf.define_side_agnostic_events(signal_df)\n",
    "\n",
    "    # print('Percent of Data in ITI:', (df['nTrial'] == df['nEndTrial']).mean())\n",
    "\n",
    "    signal_df['spnrOff'] = ((signal_df['spnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    signal_df['spxrOff'] = ((signal_df['spxr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "    spnnrOff_a = ((signal_df['spnnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    spxnrOff_a = ((signal_df['spxnr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "\n",
    "    # If we have something listed as a rewarded \"off\" side entry labeled in the table as a side exit... it means it was a fast \"out-in\".\n",
    "    # The latter \"in\" should be considered an unrewarded side port \"off\" entry.\n",
    "    dualism_exen = ((signal_df['spnrOff'] == 1)&(signal_df['photometrySideOutIndex'] == 1)).astype(int)\n",
    "\n",
    "    # Unrewarded side port entries should be the combination of those simply identified by checking spnnr & the table labels +\n",
    "    # the dualism defined immediately prior. Then those dualism examples should be remoed from the \"off\" rewarded entries.\n",
    "    signal_df['spnnrOff'] = spnnrOff_a + dualism_exen\n",
    "    signal_df['spnrOff'] = signal_df['spnrOff'] - dualism_exen\n",
    "\n",
    "    signal_df['spxnrOff'] = spxnrOff_a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    signal_df['cpnOff'] = ((signal_df['cpn'] == 1)&(signal_df['photometryCenterInIndex'] != 1)).astype(int)\n",
    "    signal_df['cpxOff'] = ((signal_df['cpx'] == 1)&(signal_df['photometryCenterOutIndex'] != 1)).astype(int)\n",
    "    # spnnrOff_a = ((signal_df['cpnOff'] == 1)&(signal_df['photometryCenterInIndex'] != 1)).astype(int)\n",
    "    # spxnrOff_a = ((signal_df['cpxOff'] == 1)&(signal_df['photometryCenterOutIndex'] != 1)).astype(int)\n",
    "\n",
    "    # # If we have something listed as a rewarded \"off\" side entry labeled in the table as a side exit... it means it was a fast \"out-in\".\n",
    "    # # The latter \"in\" should be considered an unrewarded side port \"off\" entry.\n",
    "    # dualism_exen = ((signal_df['cpnOff'] == 1)&(signal_df['photometryCenterOutIndex'] == 1)).astype(int)\n",
    "\n",
    "    # # Unrewarded side port entries should be the combination of those simply identified by checking spnnr & the table labels +\n",
    "    # # the dualism defined immediately prior. Then those dualism examples should be remoed from the \"off\" rewarded entries.\n",
    "    # signal_df['spnnrOff'] = spnnrOff_a + dualism_exen\n",
    "    # signal_df['spnrOff'] = signal_df['spnrOff'] - dualism_exen\n",
    "\n",
    "    # signal_df['spxnrOff'] = spxnrOff_a\n",
    "\n",
    "\n",
    "    if signal_path_out:\n",
    "        signal_df.to_csv(signal_path_out, index_label='index')\n",
    "    if table_path_out:\n",
    "        table_df.to_csv(table_path_out, index_label='index')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['spnnr'] = ((df['spnnr'] == 1)&(df['photometrySideInIndex'] != 1)).astype(int)\n",
    "# # df['spxnr'] = ((df['spxnr'] == 1)&(df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "\n",
    "# X_cols = [_ for _ in X_cols_all if _ not in left_out]\n",
    "\n",
    "# if len(leave_one_out_list) > 1:\n",
    "#     run_id = f'{prefix}_{fn}_{y_col}_drop={\"_\".join(left_out)}'\n",
    "# else:\n",
    "#     run_id = f'{prefix}_{fn}_{y_col}'\n",
    "\n",
    "# dfrel = df.copy()\n",
    "\n",
    "# dfrel, X_cols_sftd = lpp.timeshift_vals(dfrel, X_cols, neg_order=neg_order, pos_order=pos_order)\n",
    "\n",
    "# dfrel_setup, dfrel_holdout = holdout_splits(dfrel,\n",
    "#                                             id_cols=['nTrial'],\n",
    "#                                             perc_holdout=pholdout)\n",
    "# dfrel_setup, dfrel_holdout = dfrel_setup.copy(), dfrel_holdout.copy()\n",
    "\n",
    "# kfold_cv_idx = sglm_ez.cv_idx_by_trial_id(dfrel_setup,\n",
    "#                                           trial_id_columns=['nTrial'],\n",
    "#                                           num_folds=folds,\n",
    "#                                           test_size=pgss)\n",
    "\n",
    "# prediction_X_cols = [_ for _ in X_cols if _ not in ['nTrial']]\n",
    "# prediction_X_cols_sftd = [_ for _ in X_cols_sftd if _ not in ['nTrial']]\n",
    "\n",
    "# X_setup = get_x(dfrel_setup, prediction_X_cols_sftd, keep_rows=None)\n",
    "# y_setup = get_y(dfrel_setup, y_col, keep_rows=None)\n",
    "# X_setup_noiti = get_x(dfrel_setup, prediction_X_cols_sftd, keep_rows=dfrel_setup['wi_trial_keep'])\n",
    "# y_setup_noiti = get_y(dfrel_setup, y_col, keep_rows=dfrel_setup['wi_trial_keep'])\n",
    "# best_score, best_score_std, best_params, best_model, cv_results = sglm_ez.simple_cv_fit(X_setup, y_setup, kfold_cv_idx, glm_kwarg_lst, model_type='Normal', verbose=0, score_method=score_method)\n",
    "\n",
    "# sglm_ez.print_best_model_info(X_setup, best_score, best_params, best_model, start)\n",
    "\n",
    "# X_holdout_witi = get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=None)\n",
    "# y_holdout_witi = get_y(dfrel_holdout, y_col, keep_rows=None)\n",
    "# X_holdout_noiti = get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=dfrel_holdout['wi_trial_keep'])\n",
    "# y_holdout_noiti = get_y(dfrel_holdout, y_col, keep_rows=dfrel_holdout['wi_trial_keep'])\n",
    "# glm, holdout_score, holdout_neg_mse_score = sglm_ez.training_fit_holdout_score(X_setup, y_setup, X_holdout_noiti, y_holdout_noiti, best_params)\n",
    "\n",
    "# dfrel['pred'] = glm.predict(dfrel[prediction_X_cols_sftd])\n",
    "# dfrel_setup['pred'] = glm.predict(dfrel_setup[prediction_X_cols_sftd])\n",
    "# dfrel_holdout['pred'] = glm.predict(dfrel_holdout[prediction_X_cols_sftd])\n",
    "\n",
    "# # Collect\n",
    "# results_dict[f'{run_id}'] = {'holdout_score':holdout_score,\n",
    "#                             'holdout_neg_mse_score':holdout_neg_mse_score,\n",
    "#                             'best_score':best_score,\n",
    "#                             'best_params':best_params,\n",
    "#                             'all_models':sorted([(_['cv_R2_score'],\n",
    "#                                                     _['cv_mse_score'],\n",
    "#                                                     sglm_ez.calc_l1(_['cv_coefs']),\n",
    "#                                                     sglm_ez.calc_l2(_['cv_coefs']),\n",
    "#                                                     _['glm_kwargs']) for _ in cv_results['full_cv_results']], key=lambda x: -x[0])\n",
    "#                             }\n",
    "\n",
    "# X_cols_plot = prediction_X_cols\n",
    "# X_cols_sftd_plot = prediction_X_cols_sftd\n",
    "\n",
    "# # print('X_setup.columns', list(X_setup.columns), len(list(X_setup.columns)))\n",
    "# # print('X_setup_noiti.columns', list(X_setup_noiti.columns), len(list(X_setup_noiti.columns)))\n",
    "# # print('X_holdout_witi.columns', list(X_holdout_witi.columns), len(list(X_holdout_witi.columns)))\n",
    "# # print('X_holdout_noiti.columns', list(X_holdout_noiti.columns), len(list(X_holdout_noiti.columns)))\n",
    "\n",
    "\n",
    "# holdout_score_rnd = np.round(holdout_score, 4)\n",
    "# best_beta_fn = f'{best_coeffs_folder}/{run_id}_best_{all_betas_basename}_R2_{holdout_score_rnd}.png'\n",
    "# splt.plot_all_beta_coefs(glm.coef_, X_cols_plot,\n",
    "#                                 X_cols_sftd_plot,\n",
    "#                                 plot_width=4,\n",
    "#                                 # plot_width=2,\n",
    "#                                 y_lims=(-2.5, 2.5),\n",
    "#                                 # filename=f'{fn}_coeffs.png',\n",
    "#                                 binsize=54,\n",
    "#                                 filename=best_beta_fn,\n",
    "#                                 plot_name=f'Best Coeffs - {run_id} — {best_params}'\n",
    "#                                 )\n",
    "\n",
    "# best_beta_fn = f'{best_reconstruct_folder}/{run_id}_best_{avg_reconstruct_basename}_R2_{holdout_score_rnd}.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# splt.plot_avg_reconstructions_v2(dfrel_holdout,\n",
    "# # splt.plot_avg_reconstructions_v2(dfrel,\n",
    "#                             channel=y_col,\n",
    "#                             binsize = 54,\n",
    "#                             plot_width=4,\n",
    "#                             min_time = -20,\n",
    "#                             max_time = 30,\n",
    "#                             min_signal = -3.0,\n",
    "#                             max_signal = 3.0,\n",
    "#                             file_name=best_beta_fn,\n",
    "#                             title=f'Best Average Reconstruction - {run_id} — {best_params}'\n",
    "#                             )\n",
    "\n",
    "# for fitted_model_dict in (cv_results['full_cv_results']):\n",
    "#     fitted_model = fitted_model_dict['model']\n",
    "#     kwarg_info = \"_\".join([f\"{_k}_{fitted_model_dict['glm_kwargs'][_k]}\" for _k in fitted_model_dict[\"glm_kwargs\"]])\n",
    "\n",
    "#     model_coef = fitted_model.coef_\n",
    "#     model_intercept = fitted_model.intercept_\n",
    "\n",
    "#     std_name = f'{run_id}_{kwarg_info}'\n",
    "#     np.save(f'{all_models_folder}/coeffs/{std_name}_{model_c_basename}.npy', model_coef)\n",
    "#     np.save(f'{all_models_folder}/intercepts/{std_name}_{model_i_basename}.npy', model_intercept)\n",
    "    \n",
    "#     tmp_holdout_score = fitted_model.r2_score(X_holdout_noiti, y_holdout_noiti)\n",
    "\n",
    "#     glmsave.append_fit_results(y_col, fitted_model_dict[\"glm_kwargs\"], glm_model=fitted_model, dropped_cols=left_out,\n",
    "#                             scores={\n",
    "#                                 'tr_witi':fitted_model.r2_score(X_setup, y_setup),\n",
    "#                                 'tr_noiti':fitted_model.r2_score(X_setup_noiti, y_setup_noiti),\n",
    "#                                 'gss_witi':fitted_model_dict['cv_R2_score'],\n",
    "#                                 'gss_noiti':None,\n",
    "#                                 'holdout_witi':fitted_model.r2_score(X_holdout_witi, y_holdout_witi),\n",
    "#                                 'holdout_noiti':fitted_model.r2_score(X_holdout_noiti, y_holdout_noiti)\n",
    "#                             },\n",
    "#                             gssids=kfold_cv_idx)\n",
    "\n",
    "#     tmp = dfrel_holdout.set_index('nTrial').copy()\n",
    "#     tmp['pred'] = fitted_model.predict(get_x(dfrel_holdout, prediction_X_cols_sftd, keep_rows=None))\n",
    "#     tmp = lpp.get_first_entry_time(tmp)\n",
    "#     tmp_y = get_y(dfrel_holdout, y_col, keep_rows=None).copy()\n",
    "#     tmp_y.index = tmp.index\n",
    "#     tmp[y_holdout_noiti.name] = tmp_y\n",
    "\n",
    "#     tmp.to_csv(f'{all_data_folder}/{std_name}_{tmp_data_basename}.csv')\n",
    "\n",
    "#     holdout_score_rnd = np.round(tmp_holdout_score, 4)\n",
    "\n",
    "\n",
    "#     splt.plot_all_beta_coefs(fitted_model.coef_, X_cols_plot,\n",
    "#                                     X_cols_sftd_plot,\n",
    "#                                     plot_width=4,\n",
    "#                                     y_lims=(-3.0, 3.0),\n",
    "#                                     # filename=f'{fn}_coeffs.png',\n",
    "#                                     binsize=54,\n",
    "#                                     filename=f'{all_coeffs_folder}/{std_name}_{all_betas_basename}_R2_{holdout_score_rnd}.png',\n",
    "#                                     plot_name=f'Coeffs by Timeshift - {run_id} — {kwarg_info}'\n",
    "#                                     # plot_name=f'{fn} — {y_col} — {kwarg_info}'\n",
    "#                                     )\n",
    "    \n",
    "#     plt.close('all')\n",
    "# plt.close('all')\n",
    "\n",
    "\n",
    "# glmsave.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = df[['nTrial', 'r_trial', 'nr_trial', 'photometrySideInIndexr', 'photometrySideInIndexnr', 'photometryCenterInIndex']]\n",
    "# t.loc[2295:2345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03162021',\n",
       " '03192021',\n",
       " '03232021',\n",
       " '03262021',\n",
       " '07282021',\n",
       " '07302021',\n",
       " '08012021',\n",
       " '08042021',\n",
       " '08062021',\n",
       " '08102021',\n",
       " '10042021',\n",
       " '10082021',\n",
       " '10112021',\n",
       " '10132021',\n",
       " '10182021',\n",
       " '11082021',\n",
       " '11102021',\n",
       " '11122021',\n",
       " '11162021',\n",
       " '11182021']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set([_.split('_')[-1].split('.')[0] for _ in glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw/fig2/*')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
