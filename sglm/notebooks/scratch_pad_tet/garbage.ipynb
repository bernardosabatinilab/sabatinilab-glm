{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.helpers import filehelpers as fh, dfhelpers as dfh\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_keys = list({\n",
    "                'gACH':(0,0),\n",
    "                'rDA':(0,0),\n",
    "                'gDA':(0,0),\n",
    "                'photometrySideInIndexr':(0,0),\n",
    "                'photometrySideInIndexnr':(0,0),\n",
    "                'photometrySideInIndexAA':(0,0),\n",
    "                'photometrySideInIndexAa':(0,0),\n",
    "                'photometrySideInIndexaA':(0,0),\n",
    "                'photometrySideInIndexaa':(0,0),\n",
    "                'photometrySideInIndexAB':(0,0),\n",
    "                'photometrySideInIndexAb':(0,0),\n",
    "                'photometrySideInIndexaB':(0,0),\n",
    "                'photometrySideInIndexab':(0,0),\n",
    "                }.keys())\n",
    "shortened_keys = [dfh.shorten_col_name(_) for _ in base_keys]\n",
    "\n",
    "all_alignment_cols = [\n",
    "#                         'SIAA', 'SIAa', 'SIaA', 'SIaa',\n",
    "                        'SIAB',# 'SIAb', 'SIaB', 'SIab',\n",
    "#                         'SIr', 'SInr', \n",
    "                     ]\n",
    "# base_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_list(event_srs, event_col, keep_srs):\n",
    "    \n",
    "    keep_eg_lst = []\n",
    "    delta_keep_eg_lst = []\n",
    "\n",
    "    rdc = []\n",
    "    entry_num = np.arange(len(event_srs))\n",
    "    event = np.where(event_srs.values == 1)\n",
    "    assert len(event) == 1\n",
    "    event = event[0]\n",
    "    \n",
    "    for iev, ev in enumerate(event):\n",
    "        delta = entry_num - ev\n",
    "        keep_eg = (delta >= -40)&(delta <= 100)&keep_srs\n",
    "        delta_keep_eg = delta[keep_eg]\n",
    "        keep_eg_lst.append(keep_eg)\n",
    "        delta_keep_eg_lst.append(delta_keep_eg)\n",
    "\n",
    "    return keep_eg_lst, delta_keep_eg_lst\n",
    "\n",
    "# full_df = h5_lst[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fig_folder ('Figure_7_g1--20_20sft', 'tet_run_20230403--20_20sft_0-ft')\n",
      "gDAc_0_0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 SIAB\n",
      "0_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0\n",
      "Pulling delta list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d18f42265184849a82019a4e83a52b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys dict_keys(['true', 'pred'])\n",
      "gDAc_0_1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 SIAB\n",
      "1_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0\n",
      "Pulling delta list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a361e4a0a3a144ce91e2aa1da8d4b7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys dict_keys(['true', 'pred'])\n",
      "gDAt_0_2_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 SIAB\n",
      "2_base_simple_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0\n",
      "Pulling delta list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af3a5d6b71d410e8d00b957adfd4ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys dict_keys(['true', 'pred'])\n",
      "gDAt_0_3_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0_run_num__0 SIAB\n",
      "3_base_words_max_iter10000__fit_interceptFalse__alpha0____0__l1_ratio0____0\n",
      "Pulling delta list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3ceeba3fd1479391e5c1b0ce0ac1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys dict_keys(['true', 'pred'])\n",
      "fig_folder ('Figure_7_g1--20_20sft', 'tet_run_20230403--20_20sft_1-ft')\n"
     ]
    }
   ],
   "source": [
    "# base_location = Path(r'/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/outputs')\n",
    "base_location = Path(r'C:\\Users\\Josh\\Documents\\GitHub\\sabatinilab-glm\\sglm\\outputs-old')\n",
    "\n",
    "# fig_folder_lst = [('Figure_1_2', 'f1*-ft'),\n",
    "#                   ('Figure_3',   'f3*-ft'),\n",
    "#                   ('Figure_4_g1',   'f4*-ft'),\n",
    "#                   ('Figure_4_g2',   'f4*-ft'),\n",
    "#                   ('Figure_5_g1',   'f5*-ft'),\n",
    "#                   ('Figure_5_g2',   'f5*-ft'),\n",
    "#                   ('Figure_5_g5',   'f5*-ft'),\n",
    "#                  ]\n",
    "fig_folder_lst = [#('Figure_1_2', 'f1-n*-ft'),\n",
    "#                   ('Figure_3',   'f3*-ft'),\n",
    "#                   ('Figure_4_g1',   'f4*-ft'),\n",
    "#                   ('Figure_4_g2',   'f4*-ft'),\n",
    "#                   ('Figure_5_g1',   'f5*-ft'),\n",
    "#                   ('Figure_5_g2',   'f5*-ft'),\n",
    "#                   ('Figure_5_g5',   'f5*-ft'),\n",
    "#                   ('Figure_6_g1',   'glu*-ft'),\n",
    "#                     ('Figure_6_g1', 'glu_run_20221202-30sft-reduc_0-ft')\n",
    "#                     ('Figure_6_g1-20sft', 'glu_run_20221212-20sft-paperfig_0-ft')\n",
    "#                     ('Figure_6_g1-50sft', 'glu_run_20221213-50sft-paperfig_0-ft')\n",
    "#                     ('Figure_6_g1--20_20sft', 'glu_run_20220109--20_20sft_0-ft')\n",
    "                    ('Figure_7_g1--20_20sft', 'tet_run_20230403--20_20sft_0-ft'),\n",
    "                    ('Figure_7_g1--20_20sft', 'tet_run_20230403--20_20sft_1-ft')\n",
    "                 ]\n",
    "\n",
    "for fig_folder in fig_folder_lst:\n",
    "    print('fig_folder', fig_folder)\n",
    "    \n",
    "    load_folder = base_location / Path(fig_folder[0])\n",
    "    # load_folder = base_location / Path(r'tmp')\n",
    "    h5_recons_locations = str((load_folder / Path('all') / Path(fig_folder[1]) / Path(r'reconstructs\\best_resids_*.h5')).resolve())\n",
    "    \n",
    "#     print(h5_recons_locations)\n",
    "    \n",
    "#     load_folder = base_location / Path(r'Figure_1_2')\n",
    "#     # load_folder = base_location / Path(r'tmp')\n",
    "#     h5_recons_locations = str((load_folder / Path(r'all\\f1*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # h5_recons_locations = str((load_folder / Path(r'all/f1*-ft/reconstructs/best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_3')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f3*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_4_g1')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_4_g2')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f4*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g1')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\reconstructs\\best_resids_*.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g2')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "#     # load_folder = base_location / Path(r'Figure_5_g5')\n",
    "#     # h5_beta_locations = str((load_folder / Path(r'all\\f5*-ft\\coefs\\*_best_coeffs.h5')).resolve())\n",
    "\n",
    "#     out_folder = base_location / Path(r'final_outputs_rev-msesplt')\n",
    "#     out_folder = base_location / Path(r'final_outputs_rev-reconsplt')\n",
    "    out_folder = base_location / Path(r'final_outputs_old-reconsplt-paperfig')\n",
    "\n",
    "    out_loc = str((out_folder).resolve())\n",
    "    h5_recons_locations = glob.glob(h5_recons_locations)\n",
    "\n",
    "    fh.create_folder_if_not_exists(out_loc)\n",
    "    \n",
    "    h5_lst = defaultdict(dict)\n",
    "#     run_id_dct = defaultdict(dict)\n",
    "\n",
    "\n",
    "    for ih5, h5_coef_fn in enumerate(h5_recons_locations):\n",
    "        h5f = pd.HDFStore(h5_coef_fn)\n",
    "        h5fk = h5f.keys()\n",
    "        for ik, key in enumerate(h5fk):\n",
    "            key = key.replace('/', '')\n",
    "            resp = key.split('_')[0]\n",
    "            model_version = '_'.join(key.split('_')[3:]).split('_run_num')[0]\n",
    "            \n",
    "\n",
    "            if 'run_num' in key and 'run_num__0' not in key: #and 'run_num__1' not in key:\n",
    "                continue\n",
    "            if 'base_simple' not in model_version and 'base_words' not in model_version and '_to_' not in model_version and 'basis' not in key:\n",
    "                continue\n",
    "            \n",
    "#             print('model_version', model_version)\n",
    "            \n",
    "#             print(key, model_version)\n",
    "#             print(f'ih5, ik, model_version, key, h5_coef_fn - {ih5}, {ik}, {model_version}, {key}, {h5_coef_fn}')\n",
    "\n",
    "            y_col = key.split('_')[0].replace(r'/', r'')\n",
    "            \n",
    "            h5_df = pd.read_hdf(h5f, key)\n",
    "\n",
    "            h5_df.columns = [dfh.shorten_col_name(_) for _ in h5_df.columns]\n",
    "\n",
    "            if 'dfrel_basis' != key.replace('/', ''):\n",
    "                h5_df.columns = [_.split('_')[0] for _ in h5_df.columns]\n",
    "                h5_df['true'] = h5_lst[ih5]['dfrel'][y_col]\n",
    "\n",
    "                h5_df['file_num'] = h5_lst[ih5]['dfrel']['file_num']\n",
    "\n",
    "                h5_df['dupe'] = h5_lst[ih5]['dfrel']['dupe']\n",
    "                h5_df['wi_trial_keep'] = h5_lst[ih5]['dfrel']['wi_trial_keep']\n",
    "\n",
    "                h5_lst[ih5][key] = h5_df\n",
    "            else:\n",
    "                h5_lst[ih5]['dfrel'] = h5_df\n",
    "\n",
    "#     for k in h5_lst:\n",
    "#         for kk in h5_lst[k]:\n",
    "#             print(k, kk)\n",
    "\n",
    "\n",
    "\n",
    "    for ih5 in h5_lst:\n",
    "#     for y_col in ['gACH', 'rDA', 'gDA']:\n",
    "#             fig,axes = plt.subplots(5,2,figsize=(10,30))\n",
    "\n",
    "        for key in h5_lst[ih5]:\n",
    "#         for y_col in ['gACH', 'rDA', 'gDA']:\n",
    "#         for ih5 in h5_lst:\n",
    "            if key == 'dfrel':\n",
    "                continue\n",
    "            \n",
    "            mse_ac = {}\n",
    "            combo_rdc = {}\n",
    "            for iac, alignment_col in enumerate(all_alignment_cols):\n",
    "    #                 ic, ir = iac%2, iac//2\n",
    "    #                 ax = axes[ir, ic]\n",
    "\n",
    "                \n",
    "                resp = key.split('_')[0].replace('/', '')\n",
    "                model_version = '_'.join(key.split('_')[2:]).split('_run_num')[0]\n",
    "                model_version = model_version.replace('5_base_words_gDA_to_gACH', '5_base_words_rDA_to_gACH')\n",
    "                print(key, alignment_col)\n",
    "                print(model_version)\n",
    "#                 break\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "                y_col = key.split('_')[0].replace(r'/', r'')\n",
    "                \n",
    "                dupe = h5_lst[ih5]['dfrel']['dupe']\n",
    "                dfrel_basis = h5_lst[ih5]['dfrel'].loc[~dupe]\n",
    "                dfrel_basis_run = h5_lst[ih5][key].loc[~dupe]\n",
    "\n",
    "                print('Pulling delta list')\n",
    "                keep_rows, assoc_deltas = get_delta_list(dfrel_basis[alignment_col], alignment_col, ((dfrel_basis_run['holdout']==1)).astype(bool))\n",
    "                rdc_lst = defaultdict(list)\n",
    "                for entry_num in trange(len(keep_rows)):\n",
    "                    keep_row_single = keep_rows[entry_num]\n",
    "                    deltas = assoc_deltas[entry_num]\n",
    "                    rdc_df = dfrel_basis_run.loc[keep_row_single].set_index(deltas)\n",
    "\n",
    "                    if rdc_df['file_num'].nunique() > 1:\n",
    "                        continue\n",
    "\n",
    "                    reconstruction_data_list = []\n",
    "\n",
    "                    for bootstrap_col in ['true', 'pred']:\n",
    "                        rdc_lst[bootstrap_col].append(rdc_df[[bootstrap_col]])\n",
    "\n",
    "                print('keys', rdc_lst.keys())\n",
    "                \n",
    "                \n",
    "                \n",
    "                t, p = pd.concat(rdc_lst['true'], axis=1).sort_index(), pd.concat(rdc_lst['pred'], axis=1).sort_index()\n",
    "                dffsq = np.square(t.values - p.values)\n",
    "                mse_ac[alignment_col] = np.sum(dffsq[np.where(~np.isnan(dffsq))])/np.sum(~np.isnan(dffsq))\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal_file           GLM_SIGNALS_INTERIM_S732_06172020.csvGLM_SIGNA...\n",
       "file_num                                                           6500\n",
       "nTrial                                                           143156\n",
       "nEndTrial                                                        141908\n",
       "wi_trial_keep                                                      1248\n",
       "nTrial_hard                                                    143156.0\n",
       "nEndTrial_hard                                                 141909.0\n",
       "diffTrialNums_hard                                               1247.0\n",
       "wi_trial_keep_hard                                                 1247\n",
       "has_all_cols                                                       1248\n",
       "gDA                                                                 0.0\n",
       "gACH                                                                0.0\n",
       "rDA                                                                 0.0\n",
       "gDAc                                                         571.233202\n",
       "gDAt                                                         622.451245\n",
       "diffTrialNums                                                    1248.0\n",
       "dupe                                                                  0\n",
       "CI                                                                  0.0\n",
       "CO                                                                  2.0\n",
       "SIr                                                                24.0\n",
       "SInr                                                                0.0\n",
       "SO                                                                  1.0\n",
       "spnnrOff                                                              0\n",
       "sl                                                                    0\n",
       "SIAA                                                                0.0\n",
       "SIAa                                                                0.0\n",
       "SIaA                                                                0.0\n",
       "SIaa                                                                0.0\n",
       "SIAB                                                               24.0\n",
       "SIAb                                                                0.0\n",
       "SIaB                                                                0.0\n",
       "SIab                                                                0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrel_basis[np.sum([dfrel_basis['SIAB'].shift(shift) == 1 for shift in range(-16,36)],axis=0) > 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
