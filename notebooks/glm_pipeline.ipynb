{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import fit_glm_helpers as fgh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Inputted data should conform to the following conventions:\n",
    "\n",
    "### Session ID\n",
    "* Must be a unique string file identifier that will represent the combined version of the signal and behavior files\n",
    "\n",
    "### Signal File\n",
    "* Each file should represent a single recording with a constant sampling rate\n",
    "* Each row in the file should represent a single timestamp within a given recording (must be in chronological order)\n",
    "\n",
    "Example:\n",
    "| id_timestamp | identifier_1 | predictor_1 | predictor_2 | response_1 | response_2 |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 0 | 0 | 0 | 1 | 0.3 |\n",
    "| 1 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 2 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| 3 | 0 | 1 | 0 | 1 | 0.3 |\n",
    "| 4 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 5 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| 6 | 1 | 0 | 0 | 0 | 1.4 |\n",
    "| 7 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| 8 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 9 | 1 | 0 | 0 | 1 | 2.3 |\n",
    "| 10 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 11 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| 12 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 13 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| 14 | 0 | 0 | 1 | 0 | 1.4 |\n",
    "| 15 | 0 | 0 | 0 | 0 | 2.3 |\n",
    "| 16 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| 17 | 0 | 0 | 0 | 0 | 2.3 |\n",
    "| 18 | 0 | 1 | 0 | 0 | 1.4 |\n",
    "| 19 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "\n",
    "### Trial File (Optional)\n",
    "* Each file should represent a single recording with a constant sampling rate\n",
    "* Each row must represent a unique trial in chronological order, but does not need to start from zero\n",
    "\n",
    "Columns (Alignment Columns + Information Columns):\n",
    "* Alignment Columns: Contains the indices (in the signal table) at which the event in question occurs\n",
    "* Information Columns: Contains information associated with the given trial\n",
    "\n",
    "Example:\n",
    "| id_trial | centerInIndex (Alignment) | centerOutIndex (Alignment) | sideInIndex (Alignment) | sideOutIndex (Alignment) | hasAllData (Information) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| trial_0 | 12 | 13 | 17 | 18 | 0 |\n",
    "| trial_1 | 20 | 22 | 23 | 25 | 1 |\n",
    "| trial_0 | 27 | 28 | 31 | 35 | 1 |\n",
    "| trial_2 | 50 | 54 | 57 | 60 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = Path('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/data/old-data-version/raw-new/Figure_1_2')\n",
    "dir_output = Path('/Users/josh/Desktop/example_output_folder')\n",
    "\n",
    "lst_dict_inputdata = [\n",
    "    {'session_id': 'WT63_11082021',\n",
    "    'filepath_signal': dir_data / Path('GLM_SIGNALS_WT63_11082021.txt'),\n",
    "    'filepath_trial': dir_data / Path('GLM_TABLE_WT63_11082021.txt'),\n",
    "    'bool_trialTable_matlab_indexed': True,\n",
    "    'columnName_trialTable_trialId': None,\n",
    "    'columnRenames_signal': {'Ch1': 'gDA', 'Ch5': 'gACH'},\n",
    "    'columnRenames_trial': None},\n",
    "]\n",
    "\n",
    "dir_output.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnName_alignment_trial_start = 'photometryCenterInIndex'\n",
    "columnName_alignment_trial_end = 'photometrySideOutIndex'\n",
    "\n",
    "# Note: Alignment values of 0 for Matlab-indexed trial tables will be treated as \"no-data\" values\n",
    "# and and -1 for Python-indexed trial tables. Matlab-indexed trial tables should only have values\n",
    "# >= 0 in and >= -1 in Python.\n",
    "lst_strColumns_alignment = [\n",
    "    'photometryCenterInIndex',\n",
    "    'photometryCenterOutIndex',\n",
    "    'photometrySideInIndex',\n",
    "    'photometrySideOutIndex',\n",
    "]\n",
    "\n",
    "lst_strColumns_information = [\n",
    "    'nTrial_raw', 'hasAllPhotometryData',\n",
    "    'wasRewarded', 'word',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_drop_zeroAlignments = True\n",
    "\n",
    "trialSignalAligned_agg = fgh.TrialSignalAlignerAggregator()\n",
    "\n",
    "for dict_inputdata in lst_dict_inputdata:\n",
    "    # Load data\n",
    "    trial = fgh.TrialPreprocessor(pd.read_csv(dict_inputdata['filepath_trial']))\n",
    "    signal = fgh.SignalPreprocessor(pd.read_csv(dict_inputdata['filepath_signal']))\n",
    "\n",
    "    # Preprocess trial table\n",
    "    trial.preprocess();\n",
    "    signal.preprocess();\n",
    "\n",
    "    # Trial / signal alignment\n",
    "    trialSignalAligned = fgh.TrialSignalAligner(trial, signal)\n",
    "    trialSignalAligned.align();\n",
    "    trialSignalAligned.trialstamp();\n",
    "    trialSignalAligned.timestamp();\n",
    "\n",
    "    # Aggregate\n",
    "    trialSignalAligned_agg.add(trialSignalAligned);\n",
    "\n",
    "trialSignalAligned_agg.combine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction dataframe X, prediction dataframe y\n",
    "predictors = ['predictor_1', 'predictor_2']\n",
    "response = 'y'\n",
    "trialSignalAligned_agg.generate_Xy(predictors, response);\n",
    "\n",
    "# Unroll specified X columns into onehot representations\n",
    "trialSignalAligned_agg.unroll_X_columns(['predictor_1', 'predictor_2']);\n",
    "\n",
    "# Timeshift X columns\n",
    "trialSignalAligned_agg.timeshift_X_columns(['predictor_1', 'predictor_2'], shift_amt=1);\n",
    "\n",
    "# Split train/validation/test sets\n",
    "trialSignalAligned_agg.split_train_validation_test();\n",
    "\n",
    "# Fit GLM\n",
    "glm = fgh.GLM(trialSignalAligned_agg);\n",
    "glm.fit_GLM();\n",
    "glm.generate_GLM_summary();\n",
    "glm.plot_GLM_summary();\n",
    "\n",
    "# Generate predictions for train/validation/test sets. Evaluate predictions on train/validation/test sets.\n",
    "glm.generate_predictions();\n",
    "glm.evaluate_predictions();\n",
    "glm.generate_prediction_plots();\n",
    "\n",
    "# Save preprocessing parameters\n",
    "trial.save_preprocessing_info(dir_output / Path('trial_preprocessing_info.json'));\n",
    "signal.save_preprocessing_info(dir_output / Path('signal_preprocessing_info.json'));\n",
    "\n",
    "# Save alignment parameters\n",
    "trialSignalAligned.save_alignment_info(dir_output / Path('alignment_info.json'));\n",
    "\n",
    "# Save aggregation parameters\n",
    "trialSignalAligned_agg.save_aggregation_info(dir_output / Path('aggregation_info.json'));\n",
    "\n",
    "# Save GLM parameters\n",
    "glm.save_GLM_info(dir_output / Path('glm_info.json'));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
