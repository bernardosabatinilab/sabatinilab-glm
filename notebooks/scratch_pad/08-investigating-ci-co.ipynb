{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sglm.models import sglm\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "\n",
    "import itertools\n",
    "\n",
    "signal_files = []\n",
    "out_files = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_col_lst_all = ['gACH', 'rDA', 'gDA',              \n",
    "                 'gACH_flx_drd', 'rDA_flx_drd', 'gDA_flx_drd',\n",
    "                 'gACH_flx_cht', 'rDA_flx_cht', 'gDA_flx_cht',\n",
    "                 'gACH_flx_drdcht', 'rDA_flx_drdcht', 'gDA_flx_drdcht',\n",
    "                 'Ch5', 'Ch6', 'GP_1', 'GP_2', 'GP_5', 'GP_6', 'SGP_1', 'SGP_2', 'SGP_5', 'SGP_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from logging.config import _RootLoggerConfiguration\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_folder_if_not_exists(dr):\n",
    "    dr = Path(dr)\n",
    "    constructed_dir = str(Path('/').resolve())\n",
    "    made = False\n",
    "    \n",
    "    for fold in dr.parts:\n",
    "        if len(fold) == 0:\n",
    "            continue\n",
    "        constructed_dir = str((Path(constructed_dir) / fold).resolve())\n",
    "#         print('constructed_dir', constructed_dir)\n",
    "        if os.path.isdir(constructed_dir):\n",
    "            # print(f'Directory already exists:', constructed_dir)\n",
    "            pass\n",
    "        else:\n",
    "            # print(f'Creating directory:', constructed_dir)\n",
    "            os.mkdir(constructed_dir)\n",
    "            made = True\n",
    "    if made:\n",
    "        print(f'Created directory:', constructed_dir)\n",
    "    return\n",
    "\n",
    "# create_folder_if_not_exists((Path.home() / 'Desktop/nada/folder2').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file!!!  WT63_11082021\n",
      "Missing file!!!  WT56_09062021\n",
      "Missing file!!!  WT59_10062021\n"
     ]
    }
   ],
   "source": [
    "# ### Figure 1: Single side recording\n",
    "figure = 'fig1'\n",
    "\n",
    "# # Load Signal Data\n",
    "\n",
    "# signal_files = glob.glob(f'../../data/raw/GLM_SIGNALS_WT61_*')\n",
    "# signal_files += glob.glob(f'../../data/raw/GLM_SIGNALS_WT63_*')\n",
    "# signal_files += glob.glob(f'../../data/raw/GLM_SIGNALS_WT64_*')\n",
    "\n",
    "ignore_files = [\n",
    "                'WT61_10152021',\n",
    "                'WT61_10082021'\n",
    "                ]\n",
    "# for ign in ignore_files:\n",
    "#     signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "# table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "# channel_definitions = {\n",
    "#         ('WT61',): {'Ch1': 'gACH', 'Ch2': 'rDA'},\n",
    "#         ('WT64',): {'Ch1': 'gACH', 'Ch2': 'empty'},\n",
    "#         ('WT63',): {'Ch1': 'gDA', 'Ch2': 'empty'},\n",
    "#     }\n",
    "\n",
    "group_1_mice = ['WT63', 'WT64', 'WT65']\n",
    "# group_1_sess = ['11082021', '11102021', '11122021', '11182021']\n",
    "group_1_sess = ['11082021', '11102021', '11122021', '11162021', '11182021']\n",
    "group_1_combo = ['_'.join(_) for _ in list(itertools.product(group_1_mice, group_1_sess))]\n",
    "\n",
    "group_2_mice = ['WT66', 'WT67', 'WT68', 'WT69']\n",
    "group_2_sess = ['12132021', '12152021', '12172021', '12192021']\n",
    "group_2_combo = ['_'.join(_) for _ in list(itertools.product(group_2_mice, group_2_sess))]\n",
    "\n",
    "group_3_mice = ['WT58', 'WT60', 'WT61']\n",
    "group_3_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "group_3_combo = ['_'.join(_) for _ in list(itertools.product(group_3_mice, group_3_sess))]\n",
    "\n",
    "group_4_mice = ['WT53', 'WT54', 'WT55', 'WT56']\n",
    "group_4_sess = ['09012021', '09032021', '09062021']\n",
    "group_4_combo = ['_'.join(_) for _ in list(itertools.product(group_4_mice, group_4_sess))]\n",
    "\n",
    "group_5_mice = ['WT57', 'WT59']\n",
    "group_5_sess = ['10042021', '10062021', '10082021', '10112021', '10132021', '10152021']\n",
    "group_5_combo = ['_'.join(_) for _ in list(itertools.product(group_5_mice, group_5_sess))]\n",
    "\n",
    "group_6_mice = []#['WT62']\n",
    "group_6_sess = []#['11082021', '11102021', '11122021', '11182021']\n",
    "group_6_combo = ['_'.join(_) for _ in list(itertools.product(group_6_mice, group_6_sess))]\n",
    "\n",
    "\n",
    "channel_definitions = {}\n",
    "# channel_definitions = {(file_combo,): {'Ch1': 'gACH', 'Ch2': 'rDA'} for file_combo in group_1_combo}\n",
    "channel_definitions.update({(file_combo,): {'Ch1': 'gDA', 'Ch5': 'gACH'} for file_combo in group_1_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_2_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_3_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch1': 'gACH'} for file_combo in group_4_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch5': 'gACH'} for file_combo in group_5_combo})\n",
    "channel_definitions.update({(file_combo,): {'Ch1': 'gDA'} for file_combo in group_6_combo})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_1_signal_files_setup = group_1_combo + group_2_combo + group_3_combo + group_4_combo + group_5_combo + group_6_combo\n",
    "\n",
    "for f in fig_1_signal_files_setup:\n",
    "    glob_file = glob.glob(str(Path(f'../../data/raw/{figure}/GLM_SIGNALS_{f}*').resolve()))\n",
    "    if len(glob_file) != 1:\n",
    "        print('Missing file!!! ', f)\n",
    "    signal_files += glob_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WT63_11082021',)\n",
      "('WT63_11102021',)\n",
      "> GLM_SIGNALS_WT63_11102021.txt\n",
      "('WT63_11122021',)\n",
      "> GLM_SIGNALS_WT63_11122021.txt\n",
      "('WT63_11162021',)\n",
      "> GLM_SIGNALS_WT63_11162021.txt\n",
      "('WT63_11182021',)\n",
      "> GLM_SIGNALS_WT63_11182021.txt\n",
      "('WT64_11082021',)\n",
      "> GLM_SIGNALS_WT64_11082021.txt\n",
      "('WT64_11102021',)\n",
      "> GLM_SIGNALS_WT64_11102021.txt\n",
      "('WT64_11122021',)\n",
      "> GLM_SIGNALS_WT64_11122021.txt\n",
      "('WT64_11162021',)\n",
      "> GLM_SIGNALS_WT64_11162021.txt\n",
      "('WT64_11182021',)\n",
      "> GLM_SIGNALS_WT64_11182021.txt\n",
      "('WT65_11082021',)\n",
      "> GLM_SIGNALS_WT65_11082021.txt\n",
      "('WT65_11102021',)\n",
      "> GLM_SIGNALS_WT65_11102021.txt\n",
      "('WT65_11122021',)\n",
      "> GLM_SIGNALS_WT65_11122021.txt\n",
      "('WT65_11162021',)\n",
      "> GLM_SIGNALS_WT65_11162021.txt\n",
      "('WT65_11182021',)\n",
      "> GLM_SIGNALS_WT65_11182021.txt\n",
      "('WT66_12132021',)\n",
      "> GLM_SIGNALS_WT66_12132021.txt\n",
      "('WT66_12152021',)\n",
      "> GLM_SIGNALS_WT66_12152021.txt\n",
      "('WT66_12172021',)\n",
      "> GLM_SIGNALS_WT66_12172021.txt\n",
      "('WT66_12192021',)\n",
      "> GLM_SIGNALS_WT66_12192021.txt\n",
      "('WT67_12132021',)\n",
      "> GLM_SIGNALS_WT67_12132021.txt\n",
      "('WT67_12152021',)\n",
      "> GLM_SIGNALS_WT67_12152021.txt\n",
      "('WT67_12172021',)\n",
      "> GLM_SIGNALS_WT67_12172021.txt\n",
      "('WT67_12192021',)\n",
      "> GLM_SIGNALS_WT67_12192021.txt\n",
      "('WT68_12132021',)\n",
      "> GLM_SIGNALS_WT68_12132021.txt\n",
      "('WT68_12152021',)\n",
      "> GLM_SIGNALS_WT68_12152021.txt\n",
      "('WT68_12172021',)\n",
      "> GLM_SIGNALS_WT68_12172021.txt\n",
      "('WT68_12192021',)\n",
      "> GLM_SIGNALS_WT68_12192021.txt\n",
      "('WT69_12132021',)\n",
      "> GLM_SIGNALS_WT69_12132021.txt\n",
      "('WT69_12152021',)\n",
      "> GLM_SIGNALS_WT69_12152021.txt\n",
      "('WT69_12172021',)\n",
      "> GLM_SIGNALS_WT69_12172021.txt\n",
      "('WT69_12192021',)\n",
      "> GLM_SIGNALS_WT69_12192021.txt\n",
      "('WT58_10042021',)\n",
      "> GLM_SIGNALS_WT58_10042021.txt\n",
      "('WT58_10062021',)\n",
      "> GLM_SIGNALS_WT58_10062021.txt\n",
      "('WT58_10082021',)\n",
      "> GLM_SIGNALS_WT58_10082021.txt\n",
      "('WT58_10112021',)\n",
      "> GLM_SIGNALS_WT58_10112021.txt\n",
      "('WT58_10132021',)\n",
      "> GLM_SIGNALS_WT58_10132021.txt\n",
      "('WT58_10152021',)\n",
      "> GLM_SIGNALS_WT58_10152021.txt\n",
      "('WT60_10042021',)\n",
      "> GLM_SIGNALS_WT60_10042021.txt\n",
      "('WT60_10062021',)\n",
      "> GLM_SIGNALS_WT60_10062021.txt\n",
      "('WT60_10082021',)\n",
      "> GLM_SIGNALS_WT60_10082021.txt\n",
      "('WT60_10112021',)\n",
      "> GLM_SIGNALS_WT60_10112021.txt\n",
      "('WT60_10132021',)\n",
      "> GLM_SIGNALS_WT60_10132021.txt\n",
      "('WT60_10152021',)\n",
      "> GLM_SIGNALS_WT60_10152021.txt\n",
      "('WT61_10042021',)\n",
      "> GLM_SIGNALS_WT61_10042021.txt\n",
      "('WT61_10062021',)\n",
      "> GLM_SIGNALS_WT61_10062021.txt\n",
      "('WT61_10082021',)\n",
      "('WT61_10112021',)\n",
      "> GLM_SIGNALS_WT61_10112021.txt\n",
      "('WT61_10132021',)\n",
      "> GLM_SIGNALS_WT61_10132021.txt\n",
      "('WT61_10152021',)\n",
      "('WT53_09012021',)\n",
      "> GLM_SIGNALS_WT53_09012021.txt\n",
      "('WT53_09032021',)\n",
      "> GLM_SIGNALS_WT53_09032021.txt\n",
      "('WT53_09062021',)\n",
      "> GLM_SIGNALS_WT53_09062021.txt\n",
      "('WT54_09012021',)\n",
      "> GLM_SIGNALS_WT54_09012021.txt\n",
      "('WT54_09032021',)\n",
      "> GLM_SIGNALS_WT54_09032021.txt\n",
      "('WT54_09062021',)\n",
      "> GLM_SIGNALS_WT54_09062021.txt\n",
      "('WT55_09012021',)\n",
      "> GLM_SIGNALS_WT55_09012021.txt\n",
      "('WT55_09032021',)\n",
      "> GLM_SIGNALS_WT55_09032021.txt\n",
      "('WT55_09062021',)\n",
      "> GLM_SIGNALS_WT55_09062021.txt\n",
      "('WT56_09012021',)\n",
      "> GLM_SIGNALS_WT56_09012021.txt\n",
      "('WT56_09032021',)\n",
      "> GLM_SIGNALS_WT56_09032021.txt\n",
      "('WT56_09062021',)\n",
      "('WT57_10042021',)\n",
      "> GLM_SIGNALS_WT57_10042021.txt\n",
      "('WT57_10062021',)\n",
      "> GLM_SIGNALS_WT57_10062021.txt\n",
      "('WT57_10082021',)\n",
      "> GLM_SIGNALS_WT57_10082021.txt\n",
      "('WT57_10112021',)\n",
      "> GLM_SIGNALS_WT57_10112021.txt\n",
      "('WT57_10132021',)\n",
      "> GLM_SIGNALS_WT57_10132021.txt\n",
      "('WT57_10152021',)\n",
      "> GLM_SIGNALS_WT57_10152021.txt\n",
      "('WT59_10042021',)\n",
      "> GLM_SIGNALS_WT59_10042021.txt\n",
      "('WT59_10062021',)\n",
      "('WT59_10082021',)\n",
      "> GLM_SIGNALS_WT59_10082021.txt\n",
      "('WT59_10112021',)\n",
      "> GLM_SIGNALS_WT59_10112021.txt\n",
      "('WT59_10132021',)\n",
      "> GLM_SIGNALS_WT59_10132021.txt\n",
      "('WT59_10152021',)\n",
      "> GLM_SIGNALS_WT59_10152021.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe02922dcb44afe98b5a306a1986dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=68.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw/fig1/GLM_SIGNALS_WT63_11102021.txt\n",
      "/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim/fig1/GLM_SIGNALS_INTERIM_WT65_11102021.csv photometryCenterOutIndex 55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ign in ignore_files:\n",
    "    signal_files = [_ for _ in signal_files if ign not in _]\n",
    "\n",
    "table_files = [_.replace('GLM_SIGNALS', 'GLM_TABLE') for _ in signal_files]\n",
    "\n",
    "\n",
    "channel_assignments = bf.get_rename_columns_by_file(signal_files, channel_definitions)\n",
    "\n",
    "for file_num in trange(len(signal_files)):\n",
    "\n",
    "    ## Load Table Data\n",
    "    # signal_fn = signal_files[0]\n",
    "    # table_fn = table_files[0]\n",
    "\n",
    "    signal_path = signal_files[file_num]\n",
    "    table_path = table_files[file_num]\n",
    "\n",
    "    signal_fn = Path(signal_files[file_num]).parts[-1]\n",
    "    table_fn = Path(table_files[file_num]).parts[-1]\n",
    "\n",
    "    signal_filename_out = signal_fn.replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_filename_out = table_fn.replace('GLM_TABLE', 'GLM_TABLE_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "    # signal_path_out = f'../../data/interim/{signal_filename_out}'\n",
    "    # table_path_out = f'../../data/interim/{table_filename_out}'\n",
    "\n",
    "    signal_path_out = signal_path.replace(r'raw', r'interim2').replace('GLM_SIGNALS', 'GLM_SIGNALS_INTERIM').replace('txt', 'csv')\n",
    "    table_path_out = table_path.replace(r'raw', r'interim2').replace('GLM_TABLE', 'GLM_TABLE_INTERIM').replace('txt', 'csv')\n",
    "\n",
    "    \n",
    "    if out_files is not None and signal_path in out_files:\n",
    "        signal_path_out = signal_path_out.replace(*out_files[signal_path])\n",
    "        table_path_out = table_path_out.replace(*out_files[signal_path])\n",
    "\n",
    "    create_folder_if_not_exists(str(Path('/'.join(Path(signal_path_out).parts[:-1])).resolve()))\n",
    "    create_folder_if_not_exists(str(Path('/'.join(Path(table_path_out).parts[:-1])).resolve()))\n",
    "    \n",
    "    signal_df = pd.read_csv(signal_path)\n",
    "    table_df = pd.read_csv(table_path)\n",
    "\n",
    "    # Check for multiple copies of the same sideIn\n",
    "    eq = table_df['photometrySideInIndex'].dropna()\n",
    "    eq = eq[eq != 0]\n",
    "    if len(eq) != eq.nunique():\n",
    "        print(len(eq))\n",
    "        print(eq.nunique())\n",
    "        display(eq)\n",
    "        print(f'Error: Multiple side ins with the same timestamp detected for {signal_path}. Continuing...')\n",
    "        continue\n",
    "\n",
    "    print(signal_path)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    signal_filename = signal_path\n",
    "    table_filename = table_path\n",
    "    table_index_columns = ['photometryCenterInIndex',\n",
    "                            'photometryCenterOutIndex',\n",
    "                            'photometrySideInIndex',\n",
    "                            'photometrySideOutIndex',\n",
    "                            'photometryFirstLickIndex'\n",
    "                            ]\n",
    "    basis_Aa_cols = ['AA', 'Aa', 'aA', 'aa', 'AB', 'Ab', 'aB', 'ab']\n",
    "    trial_bounds_before_center_in = -20\n",
    "    trial_bounds_after_side_out = 20\n",
    "\n",
    "\n",
    "    # Load Signal Data\n",
    "    signal_df = pd.read_csv(signal_filename)\n",
    "\n",
    "    # Load Table Data\n",
    "    table_df = pd.read_csv(table_filename)\n",
    "    df_t2 = table_df.copy()\n",
    "\n",
    "    # Generate Ab Labels\n",
    "    df_t = gsd.generate_Ab_labels(table_df)\n",
    "    assert np.all(df_t['label'].dropna() == df_t['word'].dropna())\n",
    "    # print(df_t[['label', 'word']])\n",
    "\n",
    "    # Convert Ab Labels to Indicator Variables\n",
    "    ab_dummies = pd.get_dummies(df_t['label'])\n",
    "    for basis_col in basis_Aa_cols:\n",
    "        if basis_col not in ab_dummies.columns:\n",
    "            df_t[basis_col] = 0\n",
    "    df_t[ab_dummies.columns] = ab_dummies\n",
    "\n",
    "    # Convert MATLAB 1 indexing to python 0 indexing\n",
    "    df_t[table_index_columns] = gsd.matlab_indexing_to_python(df_t[table_index_columns])\n",
    "\n",
    "    # Replace center outs that got transferred to the next timestep to be equal to center in value\n",
    "    # df_t = replace_missed_center_out_indexes(df_t, verbose=1)\n",
    "    df_t = df_t.copy()\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        num_inx_vals = df_t[df_t['photometryCenterOutIndex'] > 0].groupby('photometryCenterOutIndex')['hasAllPhotometryData'].count()\n",
    "        # print(_, num_inx_vals.max())\n",
    "        if num_inx_vals.max() == 1:\n",
    "            break\n",
    "        duplicated_CO_inx = df_t['photometryCenterOutIndex'] == df_t['photometryCenterOutIndex'].shift(-1)\n",
    "        df_t.loc[duplicated_CO_inx, 'photometryCenterOutIndex'] = df_t.loc[duplicated_CO_inx, 'photometryCenterInIndex']\n",
    "\n",
    "        if max_num_duplications and i > max_num_duplications:\n",
    "            break\n",
    "        i += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    # \n",
    "    for col in table_index_columns:\n",
    "        df_t_tmp = df_t[gsd.get_is_relevant_trial(df_t['hasAllPhotometryData'], df_t[col])].copy()\n",
    "        assert len([_ for _ in df_t_tmp.columns if col == _]) == 1, f\"Error: Duplicate entries for {col}\"\n",
    "        assert signal_df.index.nunique() == len(signal_df.index), f\"Error: Duplicate entries in signal_df.index\"\n",
    "        # assert signal_df.index.nunique() == len(signal_df.index), f\"Error: Duplicate entries in signal_df.index\"\n",
    "\n",
    "        # print(col)\n",
    "        # print('>', (df_t_tmp.set_index(col)['wasRewarded'] == df_t_tmp.set_index(col)['wasRewarded']*1).index)\n",
    "        # print('> len', len(signal_df.index))\n",
    "        # print('> nunique', signal_df.index.nunique())\n",
    "        # print('> len b', len((df_t_tmp.set_index(col)['wasRewarded'] == df_t_tmp.set_index(col)['wasRewarded']*1).index))\n",
    "        # print('> nu b', )\n",
    "\n",
    "        # stop_flg = False\n",
    "\n",
    "        # eq = (df_t_tmp.set_index(col)['wasRewarded'] == df_t_tmp.set_index(col)['wasRewarded']*1)\n",
    "        # for e in eq.index:\n",
    "        #     if len(eq.loc[[e]]) > 1:\n",
    "        #         display(eq.loc[e])\n",
    "        #         stop_flg = True\n",
    "\n",
    "        # If it's not nan and it shows up in the table set it to 1 in signal df, else 0.\n",
    "        signal_df[col] = (df_t_tmp.set_index(col)['wasRewarded'] == df_t_tmp.set_index(col)['wasRewarded'])*1\n",
    "\n",
    "        # Set r to if it was rewarded.\n",
    "        signal_df[f'{col}r'] = df_t_tmp.set_index(col)['wasRewarded']\n",
    "\n",
    "        # Set nr to 1 - r\n",
    "        signal_df[f'{col}nr'] = (1 - signal_df[f'{col}r'])\n",
    "\n",
    "        # Set side in / side out word values in signal to associated values in table. Else 0 if not in table.\n",
    "        if col in ['photometrySideInIndex', 'photometrySideOutIndex']: #, 'photometryCenterInIndex']:\n",
    "            for basis in basis_Aa_cols:\n",
    "                signal_df[col+basis] = df_t_tmp.set_index(col)[basis].fillna(0)\n",
    "    \n",
    "    # Trial number is the number of Center In values that have been observed shifted backwards by trial_bounds_before_center_in\n",
    "    signal_df['nTrial'] = gsd.get_trial_start(signal_df['photometryCenterInIndex']).cumsum()\n",
    "    # Trial end number is the number of Side Out values that have been observed shifted forwards by trial_bounds_after_side_out\n",
    "    signal_df['nEndTrial'] = gsd.get_trial_end(signal_df['photometrySideOutIndex']).cumsum()\n",
    "    # Difference between these two is used to indicate trial overlaps by time shifts\n",
    "    signal_df['diffTrialNums'] = signal_df['nTrial'] - signal_df['nEndTrial']\n",
    "    signal_df['dupe'] = False\n",
    "\n",
    "    signal_df['wi_trial_keep'] = gsd.get_is_not_iti(signal_df)\n",
    "\n",
    "\n",
    "    signal_df = signal_df[signal_df['nTrial'] > 0].fillna(0)\n",
    "\n",
    "    # # Break down Preprocess Lynne into component parts\n",
    "\n",
    "    # # Rename Columns\n",
    "    # signal_df = bf.rename_consistent_columns(signal_df)\n",
    "    \n",
    "    # # print(channel_assignments.keys())\n",
    "    # # print(signal_fn)\n",
    "    # if signal_fn in channel_assignments:\n",
    "    #     signal_df = signal_df.rename(channel_assignments[signal_fn], axis=1)\n",
    "\n",
    "    # for y_col in y_col_lst_all:\n",
    "    #     if y_col not in signal_df.columns:\n",
    "    #         signal_df[y_col] = np.nan\n",
    "    #         continue\n",
    "    \n",
    "    \n",
    "    # ## Set Full Trial Reward Flags\n",
    "    # signal_df['r_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexr'].transform(np.sum) > 0) * 1.0\n",
    "    # signal_df['nr_trial'] = (signal_df.groupby('nTrial')['photometrySideInIndexnr'].transform(np.sum) > 0) * 1.0\n",
    "\n",
    "    # ## Define Side Rewarded / Unrewarded Flags\n",
    "    # signal_df = bf.set_port_entry_exit_rewarded_unrewarded_indicators(signal_df)\n",
    "\n",
    "    # ## Define Side Agnostic Events\n",
    "    # signal_df = bf.define_side_agnostic_events(signal_df)\n",
    "\n",
    "    # # print('Percent of Data in ITI:', (df['nTrial'] == df['nEndTrial']).mean())\n",
    "\n",
    "    # signal_df['spnrOff'] = ((signal_df['spnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    # signal_df['spxrOff'] = ((signal_df['spxr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "    # spnnrOff_a = ((signal_df['spnnr'] == 1)&(signal_df['photometrySideInIndex'] != 1)).astype(int)\n",
    "    # spxnrOff_a = ((signal_df['spxnr'] == 1)&(signal_df['photometrySideOutIndex'] != 1)).astype(int)\n",
    "\n",
    "    # # If we have something listed as a rewarded \"off\" side entry labeled in the table as a side exit... it means it was a fast \"out-in\".\n",
    "    # # The latter \"in\" should be considered an unrewarded side port \"off\" entry.\n",
    "    # dualism_exen = ((signal_df['spnrOff'] == 1)&(signal_df['photometrySideOutIndex'] == 1)).astype(int)\n",
    "\n",
    "    # # Unrewarded side port entries should be the combination of those simply identified by checking spnnr & the table labels +\n",
    "    # # the dualism defined immediately prior. Then those dualism examples should be remoed from the \"off\" rewarded entries.\n",
    "    # signal_df['spnnrOff'] = spnnrOff_a + dualism_exen\n",
    "    # signal_df['spnrOff'] = signal_df['spnrOff'] - dualism_exen\n",
    "\n",
    "    # signal_df['spxnrOff'] = spxnrOff_a\n",
    "\n",
    "    \n",
    "\n",
    "    # signal_df['slOff'] = signal_df['sl'] * signal_df['nr_trial']\n",
    "    # signal_df['slOn'] = signal_df['sl'] - signal_df['slOff']\n",
    "\n",
    "\n",
    "    \n",
    "    # signal_df['cpnOff'] = ((signal_df['cpn'] == 1)&(signal_df['photometryCenterInIndex'] != 1)).astype(int)\n",
    "    # signal_df['cpxOff'] = ((signal_df['cpx'] == 1)&(signal_df['photometryCenterOutIndex'] != 1)).astype(int)\n",
    "    \n",
    "    # # if (df_t['photometryCenterInIndex'] > df_t['photometryCenterOutIndex']).sum() > 0:\n",
    "    # #     break\n",
    "\n",
    "    # # import glob\n",
    "    # # for csv in glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim/fig1/GLM_SIGNALS_INTERIM_*.csv'):\n",
    "    df = signal_df.copy()\n",
    "    df = df[~df['dupe']]\n",
    "    df['nTrial_hard'] = df['photometryCenterInIndex'].cumsum()\n",
    "    df['nEndTrial_hard'] = df['photometrySideOutIndex'].cumsum().shift(1)\n",
    "    df['diffTrialNums_hard'] = df['nTrial_hard'] - df['nEndTrial_hard']\n",
    "    \n",
    "    for col in ['photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "                'photometrySideInIndex', 'photometrySideOutIndex',\n",
    "                'photometrySideInIndexr', 'photometrySideOutIndexr',\n",
    "\n",
    "                'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "                'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "                ]:\n",
    "\n",
    "        sm = df[(df['diffTrialNums_hard'] == 1)].groupby('nTrial_hard')[[col]].sum()\n",
    "        sm = sm[sm[col] > 1]\n",
    "\n",
    "        lsm = len(sm)\n",
    "        if lsm > 0:\n",
    "            print(csv, col, len(sm))\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t3 = df_t.copy()\n",
    "# num_inx_vals = df_t3[df_t3['photometryCenterOutIndex'] > 0].groupby('photometryCenterOutIndex')['hasAllPhotometryData'].count()\n",
    "# # print(_, num_inx_vals.max())\n",
    "# # if num_inx_vals.max() == 1:\n",
    "# #     break\n",
    "# duplicated_CO_inx = (df_t3['photometryCenterOutIndex'] > df_t3['photometryCenterOutIndex'].shift(-1))&(df_t3['photometryCenterOutIndex'].shift(-1) > 0)&(df_t3['photometryCenterOutIndex'] > 0)\n",
    "# df_t3.loc[duplicated_CO_inx, 'photometryCenterOutIndex'] = df_t3.loc[duplicated_CO_inx, 'photometryCenterInIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hasAllPhotometryData</th>\n",
       "      <th>photometryCenterInIndex</th>\n",
       "      <th>photometryCenterOutIndex</th>\n",
       "      <th>photometrySideInIndex</th>\n",
       "      <th>photometrySideOutIndex</th>\n",
       "      <th>photometryFirstLickIndex</th>\n",
       "      <th>choseLeft</th>\n",
       "      <th>choseRight</th>\n",
       "      <th>leftRewardProb</th>\n",
       "      <th>rightRewardProb</th>\n",
       "      <th>wasRewarded</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1631</td>\n",
       "      <td>1718</td>\n",
       "      <td>1650</td>\n",
       "      <td>1692</td>\n",
       "      <td>1653</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1717</td>\n",
       "      <td>1734</td>\n",
       "      <td>1775</td>\n",
       "      <td>1737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hasAllPhotometryData  photometryCenterInIndex  photometryCenterOutIndex  \\\n",
       "17                     1                     1631                      1718   \n",
       "18                     1                     1717                      1717   \n",
       "\n",
       "    photometrySideInIndex  photometrySideOutIndex  photometryFirstLickIndex  \\\n",
       "17                   1650                    1692                      1653   \n",
       "18                   1734                    1775                      1737   \n",
       "\n",
       "    choseLeft  choseRight  leftRewardProb  rightRewardProb  wasRewarded word  \n",
       "17          1           0            0.85             0.15            1   AA  \n",
       "18          1           0            0.85             0.15            1   AA  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_t2[df_t2['photometryCenterOutIndex'].between(1240,1250)]\n",
    "# df_t2[df_t2['photometryCenterOutIndex'].between(1710,1720)]\n",
    "df_t2[df_t2['photometryCenterOutIndex'].between(1710,1720)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photometryCenterInIndex</th>\n",
       "      <th>photometryCenterInIndexr</th>\n",
       "      <th>photometryCenterInIndexnr</th>\n",
       "      <th>photometryCenterOutIndex</th>\n",
       "      <th>photometryCenterOutIndexr</th>\n",
       "      <th>photometryCenterOutIndexnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      photometryCenterInIndex  photometryCenterInIndexr  \\\n",
       "1716                      1.0                       1.0   \n",
       "1717                      0.0                       0.0   \n",
       "1718                      0.0                       0.0   \n",
       "1719                      0.0                       0.0   \n",
       "1720                      0.0                       0.0   \n",
       "...                       ...                       ...   \n",
       "1831                      0.0                       0.0   \n",
       "1832                      0.0                       0.0   \n",
       "1833                      0.0                       0.0   \n",
       "1834                      0.0                       0.0   \n",
       "1835                      0.0                       0.0   \n",
       "\n",
       "      photometryCenterInIndexnr  photometryCenterOutIndex  \\\n",
       "1716                        0.0                       1.0   \n",
       "1717                        0.0                       1.0   \n",
       "1718                        0.0                       0.0   \n",
       "1719                        0.0                       0.0   \n",
       "1720                        0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "1831                        0.0                       0.0   \n",
       "1832                        0.0                       0.0   \n",
       "1833                        0.0                       0.0   \n",
       "1834                        0.0                       0.0   \n",
       "1835                        0.0                       0.0   \n",
       "\n",
       "      photometryCenterOutIndexr  photometryCenterOutIndexnr  \n",
       "1716                        1.0                         0.0  \n",
       "1717                        1.0                         0.0  \n",
       "1718                        0.0                         0.0  \n",
       "1719                        0.0                         0.0  \n",
       "1720                        0.0                         0.0  \n",
       "...                         ...                         ...  \n",
       "1831                        0.0                         0.0  \n",
       "1832                        0.0                         0.0  \n",
       "1833                        0.0                         0.0  \n",
       "1834                        0.0                         0.0  \n",
       "1835                        0.0                         0.0  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['nTrial_hard']==2][[_ for _ in df.columns if 'Center' in _]]\n",
    "df[df['nTrial_hard']==8][[_ for _ in df.columns if 'Center' in _]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim/fig1/GLM_SIGNALS_INTERIM_WT65_11102021.csv photometryCenterOutIndex 55\n",
      "             photometryCenterOutIndex\n",
      "nTrial_hard                          \n",
      "2.0                               2.0\n",
      "8.0                               2.0\n",
      "11.0                              2.0\n",
      "17.0                              2.0\n",
      "20.0                              2.0\n",
      "25.0                              2.0\n",
      "28.0                              2.0\n",
      "32.0                              2.0\n",
      "34.0                              2.0\n",
      "41.0                              2.0\n",
      "45.0                              2.0\n",
      "55.0                              2.0\n",
      "64.0                              2.0\n",
      "78.0                              2.0\n",
      "83.0                              2.0\n",
      "89.0                              2.0\n",
      "100.0                             2.0\n",
      "111.0                             2.0\n",
      "123.0                             2.0\n",
      "126.0                             2.0\n",
      "136.0                             2.0\n",
      "149.0                             2.0\n",
      "157.0                             2.0\n",
      "164.0                             2.0\n",
      "168.0                             2.0\n",
      "171.0                             2.0\n",
      "178.0                             2.0\n",
      "181.0                             2.0\n",
      "186.0                             2.0\n",
      "193.0                             2.0\n",
      "200.0                             2.0\n",
      "213.0                             2.0\n",
      "221.0                             2.0\n",
      "232.0                             2.0\n",
      "236.0                             2.0\n",
      "239.0                             2.0\n",
      "247.0                             2.0\n",
      "250.0                             2.0\n",
      "255.0                             2.0\n",
      "269.0                             2.0\n",
      "282.0                             2.0\n",
      "285.0                             2.0\n",
      "290.0                             2.0\n",
      "294.0                             2.0\n",
      "296.0                             2.0\n",
      "304.0                             2.0\n",
      "306.0                             2.0\n",
      "323.0                             2.0\n",
      "332.0                             2.0\n",
      "334.0                             2.0\n",
      "337.0                             2.0\n",
      "342.0                             2.0\n",
      "344.0                             2.0\n",
      "348.0                             2.0\n",
      "365.0                             2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in ['photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "            'photometrySideInIndex', 'photometrySideOutIndex',\n",
    "            'photometrySideInIndexr', 'photometrySideOutIndexr',\n",
    "\n",
    "            'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "            'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "            'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "            'photometrySideInIndexaB', 'photometrySideInIndexab',]:\n",
    "\n",
    "    sm = df[(df['diffTrialNums_hard'] == 1)].groupby('nTrial_hard')[[col]].sum()\n",
    "    sm = sm[sm[col] > 1]\n",
    "\n",
    "    lsm = len(sm)\n",
    "    if lsm > 0:\n",
    "        print(csv, col, len(sm))\n",
    "        print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import glob\n",
    "#     # for csv in glob.glob('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/interim/fig1/GLM_SIGNALS_INTERIM_*.csv'):\n",
    "#     df = pd.read_csv(csv)\n",
    "#     df = df[~df['dupe']]\n",
    "#     df['nTrial_hard'] = df['photometryCenterInIndex'].cumsum()\n",
    "#     df['nEndTrial_hard'] = df['photometrySideOutIndex'].cumsum().shift(1)\n",
    "#     df['diffTrialNums_hard'] = df['nTrial_hard'] - df['nEndTrial_hard']\n",
    "    \n",
    "#     for col in ['photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "#                 'photometrySideInIndex', 'photometrySideOutIndex',\n",
    "#                 'photometrySideInIndexr', 'photometrySideOutIndexr',\n",
    "\n",
    "#                 'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "#                 'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "#                 'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "#                 'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "#                 ]:\n",
    "\n",
    "#         sm = df[(df['diffTrialNums_hard'] == 1)].groupby('nTrial_hard')[[col]].sum()\n",
    "#         sm = sm[sm[col] > 1]\n",
    "\n",
    "#         lsm = len(sm)\n",
    "#         if lsm > 0:\n",
    "#             print(csv, col, len(sm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('/Users/josh/Documents/Harvard/GLM/sabatinilab-glm/sglm/data/raw/fig1/GLM_TABLE_WT63_11102021.txt')\n",
    "# tmp = (df['photometryCenterOutIndex'] > 0)&((df['photometryCenterOutIndex'] >= df['photometryCenterOutIndex'].shift(-1))|(df['photometryCenterOutIndex'].shift(1) >= df['photometryCenterOutIndex']))\n",
    "# inx = tmp[tmp].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(list(inx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', 1000):\n",
    "#     df.loc[inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('nEndTrial_hard')['photometryCenterInIndex'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    16125\n",
       "0.0     6145\n",
       "2.0     4083\n",
       "Name: diffTrialNums, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['diffTrialNums'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
